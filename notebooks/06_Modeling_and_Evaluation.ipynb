{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdc52235-bab6-44c3-8021-d41adedaf652",
   "metadata": {},
   "source": [
    "# Zomato Bangalore Restaurants: 06 - Modeling & Evaluation\n",
    "\n",
    "**Author:** Puneet Kumar Mishra\n",
    "**Date:** 17-09-2025\n",
    "\n",
    "## 1. Objective\n",
    "\n",
    "This is the final and culminating notebook of the Zomato Restaurant Rating Prediction project. After extensive data cleaning, preparation, and feature engineering across multiple, specialized notebooks, we have arrived at the modeling stage.\n",
    "\n",
    "The primary goal of this notebook is to leverage our rich, processed datasets to **build, train, and evaluate a suite of machine learning models** to accurately predict restaurant ratings.\n",
    "\n",
    "### The Strategic Workflow:\n",
    "\n",
    "1.  **Data Consolidation:** We will load our three specialized, processed datasets (Tabular, Geospatial, and NLP) and merge them into a single, ultimate \"master feature table.\"\n",
    "2.  **Final Feature Selection:** We will perform a final, data-driven feature selection process using model-based techniques (like Random Forest Importance) to select the most powerful predictors for our final model.\n",
    "3.  **Preprocessing Pipeline Construction:** We will build a robust `scikit-learn` `ColumnTransformer` and `Pipeline`. This will encapsulate our entire preprocessing recipe (transformations, scaling, encoding) and prevent data leakage, ensuring a reproducible and scientifically valid modeling process.\n",
    "4.  **Model Training & Hyperparameter Tuning:** We will train and evaluate a range of models, from simple baselines to state-of-the-art gradient boosting machines like XGBoost and LightGBM.\n",
    "5.  **Final Evaluation:** We will perform a comprehensive evaluation of our best model on a held-out test set, analyzing its performance using key regression metrics and visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd6dc503-2cbf-434c-92ad-74a632d064ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-19T16:37:27.533597Z",
     "iopub.status.busy": "2025-09-19T16:37:27.533358Z",
     "iopub.status.idle": "2025-09-19T16:37:34.064672Z",
     "shell.execute_reply": "2025-09-19T16:37:34.063830Z",
     "shell.execute_reply.started": "2025-09-19T16:37:27.533579Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-19 22:07:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m✅ All libraries imported and configurations set successfully!\u001b[0m\n",
      "\u001b[32m2025-09-19 22:07:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- Loading all processed feature sets ---\u001b[0m\n",
      "\u001b[32m2025-09-19 22:07:34\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mAll three feature sets loaded successfully.\u001b[0m\n",
      "\u001b[32m2025-09-19 22:07:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mTabular Shape: (45187, 15)\u001b[0m\n",
      "\u001b[32m2025-09-19 22:07:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mGeo Shape:     (45187, 13)\u001b[0m\n",
      "\u001b[32m2025-09-19 22:07:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mNLP Shape:     (45187, 86)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# --- 1. CORE LIBRARIES ---\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "# --- 2. DATA HANDLING & ANALYSIS ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- 3. PREPROCESSING & MODELING ---\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PowerTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# --- 4. EVALUATION ---\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# --- 5. UTILITIES ---\n",
    "from loguru import logger\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ===================================================================\n",
    "#                      CONFIGURATION\n",
    "# ===================================================================\n",
    "# (Your standard, excellent configuration settings)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "# ... etc. ...\n",
    "logger.remove()\n",
    "logger.add(sys.stdout, colorize=True,\n",
    "    format=(\n",
    "        \"<green>{time:YYYY-MM-DD HH:mm:ss}</green> | \"\n",
    "        \"<level>{level: <8}</level> | \"\n",
    "        \"<level>{message}</level>\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "logger.info(\"✅ All libraries imported and configurations set successfully!\")\n",
    "\n",
    "# --- Load All Processed Datasets ---\n",
    "logger.info(\"--- Loading all processed feature sets ---\")\n",
    "try:\n",
    "    df_tabular = pd.read_parquet(\"../data/processed/zomato_eda_tabular.parquet\")\n",
    "    df_geo = pd.read_parquet(\"../data/processed/zomato_geo_features_final.parquet\")\n",
    "    df_nlp = pd.read_parquet(\"../data/processed/zomato_nlp_features_final.parquet\")\n",
    "    \n",
    "    logger.success(\"All three feature sets loaded successfully.\")\n",
    "    logger.info(f\"Tabular Shape: {df_tabular.shape}\")\n",
    "    logger.info(f\"Geo Shape:     {df_geo.shape}\")\n",
    "    logger.info(f\"NLP Shape:     {df_nlp.shape}\")\n",
    "except FileNotFoundError as e:\n",
    "    logger.error(f\"FATAL: Could not load a required data file. Please ensure all previous notebooks have been run. Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb66adc5-aac5-413e-a6e3-4510a9ba67a9",
   "metadata": {},
   "source": [
    "## 2. Data Consolidation: The Grand Merge\n",
    "\n",
    "Our first action is to combine our specialized datasets into a single, master DataFrame. We will use the primary key we established (`name` and `address`) to perform a series of `merge` operations.\n",
    "\n",
    "This will create a single, wide DataFrame containing all the structured, geospatial, and NLP features we have painstakingly engineered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec2b136e-4187-4075-96a7-23d62f21c589",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-19T16:38:00.740230Z",
     "iopub.status.busy": "2025-09-19T16:38:00.739978Z",
     "iopub.status.idle": "2025-09-19T16:38:00.985214Z",
     "shell.execute_reply": "2025-09-19T16:38:00.984522Z",
     "shell.execute_reply.started": "2025-09-19T16:38:00.740213Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-19 22:08:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- Starting the DIRECT CONCATENATION Grand Merge ---\u001b[0m\n",
      "\u001b[32m2025-09-19 22:08:00\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mVerification successful: All DataFrames are perfectly aligned by index.\u001b[0m\n",
      "\u001b[32m2025-09-19 22:08:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mConcatenating Geo and NLP features...\u001b[0m\n",
      "\u001b[32m2025-09-19 22:08:00\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mThe Grand Merge via direct concatenation is complete.\u001b[0m\n",
      "\u001b[32m2025-09-19 22:08:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mFinal master DataFrame shape: (45187, 104)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>online_order</th>\n",
       "      <th>book_table</th>\n",
       "      <th>rate</th>\n",
       "      <th>votes</th>\n",
       "      <th>location</th>\n",
       "      <th>rest_type</th>\n",
       "      <th>dish_liked</th>\n",
       "      <th>cuisines</th>\n",
       "      <th>listed_in_type</th>\n",
       "      <th>listed_in_city</th>\n",
       "      <th>cost_for_two</th>\n",
       "      <th>cost_log</th>\n",
       "      <th>votes_log</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>location_cluster</th>\n",
       "      <th>cluster_name</th>\n",
       "      <th>dist_from_airport_km</th>\n",
       "      <th>dist_from_city_center_mg_road_km</th>\n",
       "      <th>dist_from_tech_park_electronic_city_km</th>\n",
       "      <th>dist_from_tech_park_manyata_km</th>\n",
       "      <th>reviews_list</th>\n",
       "      <th>menu_item</th>\n",
       "      <th>full_review_text</th>\n",
       "      <th>review_count</th>\n",
       "      <th>total_review_length</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>text_for_sentiment</th>\n",
       "      <th>text_for_topics</th>\n",
       "      <th>sentiment_textblob</th>\n",
       "      <th>sentiment_vader</th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>topic_8</th>\n",
       "      <th>topic_9</th>\n",
       "      <th>transformer_sentiment</th>\n",
       "      <th>menu_item_vec_0</th>\n",
       "      <th>menu_item_vec_1</th>\n",
       "      <th>menu_item_vec_2</th>\n",
       "      <th>menu_item_vec_3</th>\n",
       "      <th>menu_item_vec_4</th>\n",
       "      <th>menu_item_vec_5</th>\n",
       "      <th>menu_item_vec_6</th>\n",
       "      <th>menu_item_vec_7</th>\n",
       "      <th>menu_item_vec_8</th>\n",
       "      <th>menu_item_vec_9</th>\n",
       "      <th>menu_item_vec_10</th>\n",
       "      <th>menu_item_vec_11</th>\n",
       "      <th>menu_item_vec_12</th>\n",
       "      <th>menu_item_vec_13</th>\n",
       "      <th>menu_item_vec_14</th>\n",
       "      <th>menu_item_vec_15</th>\n",
       "      <th>menu_item_vec_16</th>\n",
       "      <th>menu_item_vec_17</th>\n",
       "      <th>menu_item_vec_18</th>\n",
       "      <th>menu_item_vec_19</th>\n",
       "      <th>cuisines_vec_0</th>\n",
       "      <th>cuisines_vec_1</th>\n",
       "      <th>cuisines_vec_2</th>\n",
       "      <th>cuisines_vec_3</th>\n",
       "      <th>cuisines_vec_4</th>\n",
       "      <th>cuisines_vec_5</th>\n",
       "      <th>cuisines_vec_6</th>\n",
       "      <th>cuisines_vec_7</th>\n",
       "      <th>cuisines_vec_8</th>\n",
       "      <th>cuisines_vec_9</th>\n",
       "      <th>cuisines_vec_10</th>\n",
       "      <th>cuisines_vec_11</th>\n",
       "      <th>cuisines_vec_12</th>\n",
       "      <th>cuisines_vec_13</th>\n",
       "      <th>cuisines_vec_14</th>\n",
       "      <th>cuisines_vec_15</th>\n",
       "      <th>cuisines_vec_16</th>\n",
       "      <th>cuisines_vec_17</th>\n",
       "      <th>cuisines_vec_18</th>\n",
       "      <th>cuisines_vec_19</th>\n",
       "      <th>dish_liked_vec_0</th>\n",
       "      <th>dish_liked_vec_1</th>\n",
       "      <th>dish_liked_vec_2</th>\n",
       "      <th>dish_liked_vec_3</th>\n",
       "      <th>dish_liked_vec_4</th>\n",
       "      <th>dish_liked_vec_5</th>\n",
       "      <th>dish_liked_vec_6</th>\n",
       "      <th>dish_liked_vec_7</th>\n",
       "      <th>dish_liked_vec_8</th>\n",
       "      <th>dish_liked_vec_9</th>\n",
       "      <th>dish_liked_vec_10</th>\n",
       "      <th>dish_liked_vec_11</th>\n",
       "      <th>dish_liked_vec_12</th>\n",
       "      <th>dish_liked_vec_13</th>\n",
       "      <th>dish_liked_vec_14</th>\n",
       "      <th>dish_liked_vec_15</th>\n",
       "      <th>dish_liked_vec_16</th>\n",
       "      <th>dish_liked_vec_17</th>\n",
       "      <th>dish_liked_vec_18</th>\n",
       "      <th>dish_liked_vec_19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jalsa</td>\n",
       "      <td>942, 21st Main Road, 2nd Stage, Banashankari, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.1</td>\n",
       "      <td>775</td>\n",
       "      <td>Banashankari</td>\n",
       "      <td>[Casual Dining]</td>\n",
       "      <td>[Dum Biryani, Lunch Buffet, Masala Papad, Pane...</td>\n",
       "      <td>[Chinese, Mughlai, North Indian]</td>\n",
       "      <td>Buffet</td>\n",
       "      <td>Banashankari</td>\n",
       "      <td>800.0</td>\n",
       "      <td>6.685861</td>\n",
       "      <td>6.654153</td>\n",
       "      <td>12.926226</td>\n",
       "      <td>77.564738</td>\n",
       "      <td>0</td>\n",
       "      <td>Jayanagar</td>\n",
       "      <td>33.906748</td>\n",
       "      <td>7.128719</td>\n",
       "      <td>12.495867</td>\n",
       "      <td>14.883401</td>\n",
       "      <td>[[Rated 2.0, RATED\\n  Its a restaurant near to...</td>\n",
       "      <td>[Unknown]</td>\n",
       "      <td>RATED\\n  Its a restaurant near to Banashankari...</td>\n",
       "      <td>10</td>\n",
       "      <td>2906</td>\n",
       "      <td>4.662083</td>\n",
       "      <td>its a restaurant near to banashankari bda. me ...</td>\n",
       "      <td>restaurant near banashankari bda along office ...</td>\n",
       "      <td>0.345060</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>0.482831</td>\n",
       "      <td>-0.053563</td>\n",
       "      <td>-0.142821</td>\n",
       "      <td>-0.054958</td>\n",
       "      <td>-0.021470</td>\n",
       "      <td>-0.131860</td>\n",
       "      <td>-0.106416</td>\n",
       "      <td>0.075845</td>\n",
       "      <td>0.018076</td>\n",
       "      <td>-0.025933</td>\n",
       "      <td>0.606136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000139</td>\n",
       "      <td>-0.014075</td>\n",
       "      <td>0.016368</td>\n",
       "      <td>-0.008531</td>\n",
       "      <td>-0.002681</td>\n",
       "      <td>-0.002833</td>\n",
       "      <td>-0.004693</td>\n",
       "      <td>-0.005675</td>\n",
       "      <td>-0.010905</td>\n",
       "      <td>0.007609</td>\n",
       "      <td>0.004142</td>\n",
       "      <td>0.018541</td>\n",
       "      <td>0.008585</td>\n",
       "      <td>-0.004918</td>\n",
       "      <td>0.002574</td>\n",
       "      <td>-0.000303</td>\n",
       "      <td>-0.004193</td>\n",
       "      <td>-0.007041</td>\n",
       "      <td>0.003208</td>\n",
       "      <td>0.000806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spice Elephant</td>\n",
       "      <td>2nd Floor, 80 Feet Road, Near Big Bazaar, 6th ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>787</td>\n",
       "      <td>Banashankari</td>\n",
       "      <td>[Casual Dining]</td>\n",
       "      <td>[Chicken Biryani, Chocolate Nirvana, Dum Birya...</td>\n",
       "      <td>[Chinese, North Indian, Thai]</td>\n",
       "      <td>Buffet</td>\n",
       "      <td>Banashankari</td>\n",
       "      <td>800.0</td>\n",
       "      <td>6.685861</td>\n",
       "      <td>6.669498</td>\n",
       "      <td>13.025403</td>\n",
       "      <td>77.629854</td>\n",
       "      <td>7</td>\n",
       "      <td>Kalyan Nagar</td>\n",
       "      <td>20.912360</td>\n",
       "      <td>6.082985</td>\n",
       "      <td>19.742792</td>\n",
       "      <td>2.715756</td>\n",
       "      <td>[[Rated 2.0, RATED\\n  I had a very bad experie...</td>\n",
       "      <td>[Unknown]</td>\n",
       "      <td>RATED\\n  I had a very bad experience here.\\nI ...</td>\n",
       "      <td>14</td>\n",
       "      <td>4958</td>\n",
       "      <td>4.493304</td>\n",
       "      <td>i had a very bad experience here.\\ni don't kno...</td>\n",
       "      <td>bad experience know carte buffet worst gave co...</td>\n",
       "      <td>0.195731</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>0.602828</td>\n",
       "      <td>-0.031769</td>\n",
       "      <td>-0.063036</td>\n",
       "      <td>-0.030274</td>\n",
       "      <td>-0.018630</td>\n",
       "      <td>-0.168695</td>\n",
       "      <td>-0.074582</td>\n",
       "      <td>0.049469</td>\n",
       "      <td>0.012818</td>\n",
       "      <td>-0.075545</td>\n",
       "      <td>0.409859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010823</td>\n",
       "      <td>-0.001898</td>\n",
       "      <td>-0.003000</td>\n",
       "      <td>-0.007676</td>\n",
       "      <td>-0.004414</td>\n",
       "      <td>0.001336</td>\n",
       "      <td>0.002587</td>\n",
       "      <td>0.007630</td>\n",
       "      <td>-0.004245</td>\n",
       "      <td>-0.001513</td>\n",
       "      <td>-0.001917</td>\n",
       "      <td>-0.000603</td>\n",
       "      <td>-0.019428</td>\n",
       "      <td>0.005711</td>\n",
       "      <td>0.014509</td>\n",
       "      <td>0.005603</td>\n",
       "      <td>-0.006174</td>\n",
       "      <td>-0.005010</td>\n",
       "      <td>0.010610</td>\n",
       "      <td>-0.016491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>San Churro Cafe</td>\n",
       "      <td>1112, Next to KIMS Medical College, 17th Cross...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>918</td>\n",
       "      <td>Banashankari</td>\n",
       "      <td>[Cafe, Casual Dining]</td>\n",
       "      <td>[Cannelloni, Churros, Hot Chocolate, Minestron...</td>\n",
       "      <td>[Cafe, Italian, Mexican]</td>\n",
       "      <td>Buffet</td>\n",
       "      <td>Banashankari</td>\n",
       "      <td>800.0</td>\n",
       "      <td>6.685861</td>\n",
       "      <td>6.823286</td>\n",
       "      <td>12.927690</td>\n",
       "      <td>77.562086</td>\n",
       "      <td>0</td>\n",
       "      <td>Jayanagar</td>\n",
       "      <td>33.894450</td>\n",
       "      <td>7.194585</td>\n",
       "      <td>12.816564</td>\n",
       "      <td>14.856481</td>\n",
       "      <td>[[Rated 1.0, RATED\\n  Cockroaches !! I Repeat ...</td>\n",
       "      <td>[Unknown]</td>\n",
       "      <td>RATED\\n  Cockroaches !! I Repeat cockroaches!!...</td>\n",
       "      <td>20</td>\n",
       "      <td>6993</td>\n",
       "      <td>4.519108</td>\n",
       "      <td>cockroaches !! i repeat cockroaches!!bakasura ...</td>\n",
       "      <td>cockroach repeat cockroach bakasura disappoint...</td>\n",
       "      <td>0.166162</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>0.331411</td>\n",
       "      <td>-0.179015</td>\n",
       "      <td>0.001051</td>\n",
       "      <td>0.081526</td>\n",
       "      <td>0.052696</td>\n",
       "      <td>0.054141</td>\n",
       "      <td>0.051919</td>\n",
       "      <td>0.096816</td>\n",
       "      <td>0.014956</td>\n",
       "      <td>-0.050901</td>\n",
       "      <td>0.188120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.003370</td>\n",
       "      <td>-0.013840</td>\n",
       "      <td>0.005028</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>-0.019702</td>\n",
       "      <td>-0.003763</td>\n",
       "      <td>-0.012497</td>\n",
       "      <td>0.021039</td>\n",
       "      <td>-0.006153</td>\n",
       "      <td>-0.013886</td>\n",
       "      <td>-0.007933</td>\n",
       "      <td>-0.002460</td>\n",
       "      <td>0.003207</td>\n",
       "      <td>0.006325</td>\n",
       "      <td>0.011423</td>\n",
       "      <td>-0.002227</td>\n",
       "      <td>-0.004967</td>\n",
       "      <td>-0.003433</td>\n",
       "      <td>0.000840</td>\n",
       "      <td>-0.002099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Addhuri Udupi Bhojana</td>\n",
       "      <td>1st Floor, Annakuteera, 3rd Stage, Banashankar...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>88</td>\n",
       "      <td>Banashankari</td>\n",
       "      <td>[Quick Bites]</td>\n",
       "      <td>[Masala Dosa]</td>\n",
       "      <td>[North Indian, South Indian]</td>\n",
       "      <td>Buffet</td>\n",
       "      <td>Banashankari</td>\n",
       "      <td>300.0</td>\n",
       "      <td>5.707110</td>\n",
       "      <td>4.488636</td>\n",
       "      <td>12.935209</td>\n",
       "      <td>77.571576</td>\n",
       "      <td>0</td>\n",
       "      <td>Jayanagar</td>\n",
       "      <td>32.680539</td>\n",
       "      <td>5.887258</td>\n",
       "      <td>12.707479</td>\n",
       "      <td>13.671035</td>\n",
       "      <td>[[Rated 1.5, RATED\\n  The food was not satisfa...</td>\n",
       "      <td>[Unknown]</td>\n",
       "      <td>RATED\\n  The food was not satisfactory. Not on...</td>\n",
       "      <td>23</td>\n",
       "      <td>7708</td>\n",
       "      <td>4.539797</td>\n",
       "      <td>the food was not satisfactory. not one item se...</td>\n",
       "      <td>food satisfactory one item served could eaten ...</td>\n",
       "      <td>0.309284</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>0.541989</td>\n",
       "      <td>0.015496</td>\n",
       "      <td>-0.120429</td>\n",
       "      <td>-0.329167</td>\n",
       "      <td>-0.045043</td>\n",
       "      <td>-0.000278</td>\n",
       "      <td>0.053153</td>\n",
       "      <td>0.119441</td>\n",
       "      <td>0.053072</td>\n",
       "      <td>0.128186</td>\n",
       "      <td>0.185093</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023452</td>\n",
       "      <td>-0.001145</td>\n",
       "      <td>-0.044709</td>\n",
       "      <td>-0.004473</td>\n",
       "      <td>-0.001355</td>\n",
       "      <td>0.004533</td>\n",
       "      <td>0.043311</td>\n",
       "      <td>-0.013881</td>\n",
       "      <td>-0.043410</td>\n",
       "      <td>-0.044169</td>\n",
       "      <td>-0.005288</td>\n",
       "      <td>0.006859</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>-0.011015</td>\n",
       "      <td>0.042738</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>0.032093</td>\n",
       "      <td>0.019955</td>\n",
       "      <td>-0.036016</td>\n",
       "      <td>-0.010618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Grand Village</td>\n",
       "      <td>10, 3rd Floor, Lakshmi Associates, Gandhi Baza...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>166</td>\n",
       "      <td>Basavanagudi</td>\n",
       "      <td>[Casual Dining]</td>\n",
       "      <td>[Gol Gappe, Panipuri]</td>\n",
       "      <td>[North Indian, Rajasthani]</td>\n",
       "      <td>Buffet</td>\n",
       "      <td>Banashankari</td>\n",
       "      <td>600.0</td>\n",
       "      <td>6.398595</td>\n",
       "      <td>5.117994</td>\n",
       "      <td>12.944588</td>\n",
       "      <td>77.572084</td>\n",
       "      <td>0</td>\n",
       "      <td>Jayanagar</td>\n",
       "      <td>31.727316</td>\n",
       "      <td>5.096958</td>\n",
       "      <td>13.479727</td>\n",
       "      <td>12.695251</td>\n",
       "      <td>[[Rated 4.0, RATED\\n  Great service, overwhelm...</td>\n",
       "      <td>[Unknown]</td>\n",
       "      <td>RATED\\n  Great service, overwhelming experienc...</td>\n",
       "      <td>2</td>\n",
       "      <td>651</td>\n",
       "      <td>5.252427</td>\n",
       "      <td>great service, overwhelming experience.\\n\\none...</td>\n",
       "      <td>great service overwhelming experience one kind...</td>\n",
       "      <td>0.447883</td>\n",
       "      <td>0.9856</td>\n",
       "      <td>0.220451</td>\n",
       "      <td>-0.022821</td>\n",
       "      <td>-0.090174</td>\n",
       "      <td>-0.110779</td>\n",
       "      <td>-0.016000</td>\n",
       "      <td>-0.052406</td>\n",
       "      <td>-0.034730</td>\n",
       "      <td>0.065407</td>\n",
       "      <td>0.034503</td>\n",
       "      <td>-0.035731</td>\n",
       "      <td>0.668551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026897</td>\n",
       "      <td>-0.015820</td>\n",
       "      <td>0.000905</td>\n",
       "      <td>-0.030901</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.001516</td>\n",
       "      <td>0.026496</td>\n",
       "      <td>-0.018324</td>\n",
       "      <td>-0.014460</td>\n",
       "      <td>-0.002780</td>\n",
       "      <td>-0.005007</td>\n",
       "      <td>-0.013286</td>\n",
       "      <td>-0.006045</td>\n",
       "      <td>0.032203</td>\n",
       "      <td>0.008210</td>\n",
       "      <td>-0.019635</td>\n",
       "      <td>0.014608</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>0.042274</td>\n",
       "      <td>-0.017556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name                                            address  \\\n",
       "0                  Jalsa  942, 21st Main Road, 2nd Stage, Banashankari, ...   \n",
       "1         Spice Elephant  2nd Floor, 80 Feet Road, Near Big Bazaar, 6th ...   \n",
       "2        San Churro Cafe  1112, Next to KIMS Medical College, 17th Cross...   \n",
       "3  Addhuri Udupi Bhojana  1st Floor, Annakuteera, 3rd Stage, Banashankar...   \n",
       "4          Grand Village  10, 3rd Floor, Lakshmi Associates, Gandhi Baza...   \n",
       "\n",
       "   online_order  book_table  rate  votes      location              rest_type  \\\n",
       "0             1           1   4.1    775  Banashankari        [Casual Dining]   \n",
       "1             1           0   4.1    787  Banashankari        [Casual Dining]   \n",
       "2             1           0   3.8    918  Banashankari  [Cafe, Casual Dining]   \n",
       "3             0           0   3.7     88  Banashankari          [Quick Bites]   \n",
       "4             0           0   3.8    166  Basavanagudi        [Casual Dining]   \n",
       "\n",
       "                                          dish_liked  \\\n",
       "0  [Dum Biryani, Lunch Buffet, Masala Papad, Pane...   \n",
       "1  [Chicken Biryani, Chocolate Nirvana, Dum Birya...   \n",
       "2  [Cannelloni, Churros, Hot Chocolate, Minestron...   \n",
       "3                                      [Masala Dosa]   \n",
       "4                              [Gol Gappe, Panipuri]   \n",
       "\n",
       "                           cuisines listed_in_type listed_in_city  \\\n",
       "0  [Chinese, Mughlai, North Indian]         Buffet   Banashankari   \n",
       "1     [Chinese, North Indian, Thai]         Buffet   Banashankari   \n",
       "2          [Cafe, Italian, Mexican]         Buffet   Banashankari   \n",
       "3      [North Indian, South Indian]         Buffet   Banashankari   \n",
       "4        [North Indian, Rajasthani]         Buffet   Banashankari   \n",
       "\n",
       "   cost_for_two  cost_log  votes_log   latitude  longitude  location_cluster  \\\n",
       "0         800.0  6.685861   6.654153  12.926226  77.564738                 0   \n",
       "1         800.0  6.685861   6.669498  13.025403  77.629854                 7   \n",
       "2         800.0  6.685861   6.823286  12.927690  77.562086                 0   \n",
       "3         300.0  5.707110   4.488636  12.935209  77.571576                 0   \n",
       "4         600.0  6.398595   5.117994  12.944588  77.572084                 0   \n",
       "\n",
       "   cluster_name  dist_from_airport_km  dist_from_city_center_mg_road_km  \\\n",
       "0     Jayanagar             33.906748                          7.128719   \n",
       "1  Kalyan Nagar             20.912360                          6.082985   \n",
       "2     Jayanagar             33.894450                          7.194585   \n",
       "3     Jayanagar             32.680539                          5.887258   \n",
       "4     Jayanagar             31.727316                          5.096958   \n",
       "\n",
       "   dist_from_tech_park_electronic_city_km  dist_from_tech_park_manyata_km  \\\n",
       "0                               12.495867                       14.883401   \n",
       "1                               19.742792                        2.715756   \n",
       "2                               12.816564                       14.856481   \n",
       "3                               12.707479                       13.671035   \n",
       "4                               13.479727                       12.695251   \n",
       "\n",
       "                                        reviews_list  menu_item  \\\n",
       "0  [[Rated 2.0, RATED\\n  Its a restaurant near to...  [Unknown]   \n",
       "1  [[Rated 2.0, RATED\\n  I had a very bad experie...  [Unknown]   \n",
       "2  [[Rated 1.0, RATED\\n  Cockroaches !! I Repeat ...  [Unknown]   \n",
       "3  [[Rated 1.5, RATED\\n  The food was not satisfa...  [Unknown]   \n",
       "4  [[Rated 4.0, RATED\\n  Great service, overwhelm...  [Unknown]   \n",
       "\n",
       "                                    full_review_text  review_count  \\\n",
       "0  RATED\\n  Its a restaurant near to Banashankari...            10   \n",
       "1  RATED\\n  I had a very bad experience here.\\nI ...            14   \n",
       "2  RATED\\n  Cockroaches !! I Repeat cockroaches!!...            20   \n",
       "3  RATED\\n  The food was not satisfactory. Not on...            23   \n",
       "4  RATED\\n  Great service, overwhelming experienc...             2   \n",
       "\n",
       "   total_review_length  avg_word_length  \\\n",
       "0                 2906         4.662083   \n",
       "1                 4958         4.493304   \n",
       "2                 6993         4.519108   \n",
       "3                 7708         4.539797   \n",
       "4                  651         5.252427   \n",
       "\n",
       "                                  text_for_sentiment  \\\n",
       "0  its a restaurant near to banashankari bda. me ...   \n",
       "1  i had a very bad experience here.\\ni don't kno...   \n",
       "2  cockroaches !! i repeat cockroaches!!bakasura ...   \n",
       "3  the food was not satisfactory. not one item se...   \n",
       "4  great service, overwhelming experience.\\n\\none...   \n",
       "\n",
       "                                     text_for_topics  sentiment_textblob  \\\n",
       "0  restaurant near banashankari bda along office ...            0.345060   \n",
       "1  bad experience know carte buffet worst gave co...            0.195731   \n",
       "2  cockroach repeat cockroach bakasura disappoint...            0.166162   \n",
       "3  food satisfactory one item served could eaten ...            0.309284   \n",
       "4  great service overwhelming experience one kind...            0.447883   \n",
       "\n",
       "   sentiment_vader   topic_0   topic_1   topic_2   topic_3   topic_4  \\\n",
       "0           0.9996  0.482831 -0.053563 -0.142821 -0.054958 -0.021470   \n",
       "1           0.9996  0.602828 -0.031769 -0.063036 -0.030274 -0.018630   \n",
       "2           0.9997  0.331411 -0.179015  0.001051  0.081526  0.052696   \n",
       "3           0.9998  0.541989  0.015496 -0.120429 -0.329167 -0.045043   \n",
       "4           0.9856  0.220451 -0.022821 -0.090174 -0.110779 -0.016000   \n",
       "\n",
       "    topic_5   topic_6   topic_7   topic_8   topic_9  transformer_sentiment  \\\n",
       "0 -0.131860 -0.106416  0.075845  0.018076 -0.025933               0.606136   \n",
       "1 -0.168695 -0.074582  0.049469  0.012818 -0.075545               0.409859   \n",
       "2  0.054141  0.051919  0.096816  0.014956 -0.050901               0.188120   \n",
       "3 -0.000278  0.053153  0.119441  0.053072  0.128186               0.185093   \n",
       "4 -0.052406 -0.034730  0.065407  0.034503 -0.035731               0.668551   \n",
       "\n",
       "   menu_item_vec_0  menu_item_vec_1  menu_item_vec_2  menu_item_vec_3  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "1              0.0              0.0              0.0              0.0   \n",
       "2              0.0              0.0              0.0              0.0   \n",
       "3              0.0              0.0              0.0              0.0   \n",
       "4              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   menu_item_vec_4  menu_item_vec_5  menu_item_vec_6  menu_item_vec_7  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "1              0.0              0.0              0.0              0.0   \n",
       "2              0.0              0.0              0.0              0.0   \n",
       "3              0.0              0.0              0.0              0.0   \n",
       "4              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   menu_item_vec_8  menu_item_vec_9  menu_item_vec_10  menu_item_vec_11  \\\n",
       "0              0.0              0.0               0.0               0.0   \n",
       "1              0.0              0.0               0.0               0.0   \n",
       "2              0.0              0.0               0.0               0.0   \n",
       "3              0.0              0.0               0.0               0.0   \n",
       "4              0.0              0.0               0.0               0.0   \n",
       "\n",
       "   menu_item_vec_12  menu_item_vec_13  menu_item_vec_14  menu_item_vec_15  \\\n",
       "0               0.0               0.0               0.0               0.0   \n",
       "1               0.0               0.0               0.0               0.0   \n",
       "2               0.0               0.0               0.0               0.0   \n",
       "3               0.0               0.0               0.0               0.0   \n",
       "4               0.0               0.0               0.0               0.0   \n",
       "\n",
       "   menu_item_vec_16  menu_item_vec_17  menu_item_vec_18  menu_item_vec_19  \\\n",
       "0               0.0               0.0               0.0               0.0   \n",
       "1               0.0               0.0               0.0               0.0   \n",
       "2               0.0               0.0               0.0               0.0   \n",
       "3               0.0               0.0               0.0               0.0   \n",
       "4               0.0               0.0               0.0               0.0   \n",
       "\n",
       "   cuisines_vec_0  cuisines_vec_1  cuisines_vec_2  cuisines_vec_3  \\\n",
       "0             0.0             0.0             0.0             0.0   \n",
       "1             0.0             0.0             0.0             0.0   \n",
       "2             0.0             0.0             0.0             0.0   \n",
       "3             0.0             0.0             0.0             0.0   \n",
       "4             0.0             0.0             0.0             0.0   \n",
       "\n",
       "   cuisines_vec_4  cuisines_vec_5  cuisines_vec_6  cuisines_vec_7  \\\n",
       "0             0.0             0.0             0.0             0.0   \n",
       "1             0.0             0.0             0.0             0.0   \n",
       "2             0.0             0.0             0.0             0.0   \n",
       "3             0.0             0.0             0.0             0.0   \n",
       "4             0.0             0.0             0.0             0.0   \n",
       "\n",
       "   cuisines_vec_8  cuisines_vec_9  cuisines_vec_10  cuisines_vec_11  \\\n",
       "0             0.0             0.0              0.0              0.0   \n",
       "1             0.0             0.0              0.0              0.0   \n",
       "2             0.0             0.0              0.0              0.0   \n",
       "3             0.0             0.0              0.0              0.0   \n",
       "4             0.0             0.0              0.0              0.0   \n",
       "\n",
       "   cuisines_vec_12  cuisines_vec_13  cuisines_vec_14  cuisines_vec_15  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "1              0.0              0.0              0.0              0.0   \n",
       "2              0.0              0.0              0.0              0.0   \n",
       "3              0.0              0.0              0.0              0.0   \n",
       "4              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   cuisines_vec_16  cuisines_vec_17  cuisines_vec_18  cuisines_vec_19  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "1              0.0              0.0              0.0              0.0   \n",
       "2              0.0              0.0              0.0              0.0   \n",
       "3              0.0              0.0              0.0              0.0   \n",
       "4              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   dish_liked_vec_0  dish_liked_vec_1  dish_liked_vec_2  dish_liked_vec_3  \\\n",
       "0         -0.000139         -0.014075          0.016368         -0.008531   \n",
       "1          0.010823         -0.001898         -0.003000         -0.007676   \n",
       "2         -0.003370         -0.013840          0.005028          0.002750   \n",
       "3          0.023452         -0.001145         -0.044709         -0.004473   \n",
       "4          0.026897         -0.015820          0.000905         -0.030901   \n",
       "\n",
       "   dish_liked_vec_4  dish_liked_vec_5  dish_liked_vec_6  dish_liked_vec_7  \\\n",
       "0         -0.002681         -0.002833         -0.004693         -0.005675   \n",
       "1         -0.004414          0.001336          0.002587          0.007630   \n",
       "2         -0.019702         -0.003763         -0.012497          0.021039   \n",
       "3         -0.001355          0.004533          0.043311         -0.013881   \n",
       "4          0.003124          0.001516          0.026496         -0.018324   \n",
       "\n",
       "   dish_liked_vec_8  dish_liked_vec_9  dish_liked_vec_10  dish_liked_vec_11  \\\n",
       "0         -0.010905          0.007609           0.004142           0.018541   \n",
       "1         -0.004245         -0.001513          -0.001917          -0.000603   \n",
       "2         -0.006153         -0.013886          -0.007933          -0.002460   \n",
       "3         -0.043410         -0.044169          -0.005288           0.006859   \n",
       "4         -0.014460         -0.002780          -0.005007          -0.013286   \n",
       "\n",
       "   dish_liked_vec_12  dish_liked_vec_13  dish_liked_vec_14  dish_liked_vec_15  \\\n",
       "0           0.008585          -0.004918           0.002574          -0.000303   \n",
       "1          -0.019428           0.005711           0.014509           0.005603   \n",
       "2           0.003207           0.006325           0.011423          -0.002227   \n",
       "3           0.000436          -0.011015           0.042738           0.000532   \n",
       "4          -0.006045           0.032203           0.008210          -0.019635   \n",
       "\n",
       "   dish_liked_vec_16  dish_liked_vec_17  dish_liked_vec_18  dish_liked_vec_19  \n",
       "0          -0.004193          -0.007041           0.003208           0.000806  \n",
       "1          -0.006174          -0.005010           0.010610          -0.016491  \n",
       "2          -0.004967          -0.003433           0.000840          -0.002099  \n",
       "3           0.032093           0.019955          -0.036016          -0.010618  \n",
       "4           0.014608           0.000582           0.042274          -0.017556  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45187 entries, 0 to 45186\n",
      "Columns: 104 entries, name to dish_liked_vec_19\n",
      "dtypes: category(1), float64(84), int64(6), object(13)\n",
      "memory usage: 35.6+ MB\n"
     ]
    }
   ],
   "source": [
    "if 'df_tabular' in locals() and 'df_geo' in locals() and 'df_nlp' in locals():\n",
    "    logger.info(\"--- Starting the DIRECT CONCATENATION Grand Merge ---\")\n",
    "\n",
    "    # --- Verification Step ---\n",
    "    # We verify your hypothesis that all dataframes have the same length\n",
    "    if not (len(df_tabular) == len(df_geo) == len(df_nlp)):\n",
    "        logger.error(\"FATAL: DataFrames have different lengths! Cannot perform direct concatenation.\")\n",
    "        logger.error(f\"Lengths: Tabular={len(df_tabular)}, Geo={len(df_geo)}, NLP={len(df_nlp)}\")\n",
    "    else:\n",
    "        logger.success(\"Verification successful: All DataFrames are perfectly aligned by index.\")\n",
    "\n",
    "        # --- The Grand Concatenation ---\n",
    "        # 1. Start with the tabular data as our base.\n",
    "        df_master = df_tabular.copy()\n",
    "\n",
    "        # 2. Identify the NEW columns to add from the other DataFrames.\n",
    "        #    We must exclude columns that are already in df_master to avoid duplication.\n",
    "        #    We also exclude the keys ('name', 'address') which would be redundant.\n",
    "        primary_key = ['name', 'address']\n",
    "        \n",
    "        cols_from_geo_to_add = [\n",
    "            col for col in df_geo.columns \n",
    "            if col not in df_master.columns and col not in primary_key\n",
    "        ]\n",
    "        \n",
    "        cols_from_nlp_to_add = [\n",
    "            col for col in df_nlp.columns\n",
    "            if col not in df_master.columns and col not in primary_key\n",
    "        ]\n",
    "        \n",
    "        # 3. Use pd.concat to join the new columns side-by-side.\n",
    "        #    axis=1 means we are concatenating columns, not rows.\n",
    "        logger.info(\"Concatenating Geo and NLP features...\")\n",
    "        df_master = pd.concat([\n",
    "            df_master,\n",
    "            df_geo[cols_from_geo_to_add],\n",
    "            df_nlp[cols_from_nlp_to_add]\n",
    "        ], axis=1)\n",
    "\n",
    "        logger.success(\"The Grand Merge via direct concatenation is complete.\")\n",
    "        logger.info(f\"Final master DataFrame shape: {df_master.shape}\")\n",
    "        display(df_master.head())\n",
    "        df_master.info()\n",
    "\n",
    "else:\n",
    "    logger.error(\"One or more source DataFrames are not loaded. Cannot perform the merge.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76d4ce36-eb33-43d3-a7a0-c8e765fcd64d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-19T15:43:28.180817Z",
     "iopub.status.busy": "2025-09-19T15:43:28.180608Z",
     "iopub.status.idle": "2025-09-19T15:43:28.187819Z",
     "shell.execute_reply": "2025-09-19T15:43:28.186548Z",
     "shell.execute_reply.started": "2025-09-19T15:43:28.180801Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45187, 104)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_master.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c73f0f0-0ceb-47bc-9c83-2c25d5605332",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-19T15:43:28.189207Z",
     "iopub.status.busy": "2025-09-19T15:43:28.188886Z",
     "iopub.status.idle": "2025-09-19T15:43:28.210583Z",
     "shell.execute_reply": "2025-09-19T15:43:28.209415Z",
     "shell.execute_reply.started": "2025-09-19T15:43:28.189183Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45187 entries, 0 to 45186\n",
      "Data columns (total 104 columns):\n",
      " #    Column                                  Dtype   \n",
      "---   ------                                  -----   \n",
      " 0    name                                    object  \n",
      " 1    address                                 object  \n",
      " 2    online_order                            int64   \n",
      " 3    book_table                              int64   \n",
      " 4    rate                                    float64 \n",
      " 5    votes                                   int64   \n",
      " 6    location                                object  \n",
      " 7    rest_type                               object  \n",
      " 8    dish_liked                              object  \n",
      " 9    cuisines                                object  \n",
      " 10   listed_in_type                          object  \n",
      " 11   listed_in_city                          object  \n",
      " 12   cost_for_two                            float64 \n",
      " 13   cost_log                                float64 \n",
      " 14   votes_log                               float64 \n",
      " 15   latitude                                float64 \n",
      " 16   longitude                               float64 \n",
      " 17   location_cluster                        int64   \n",
      " 18   cluster_name                            category\n",
      " 19   dist_from_airport_km                    float64 \n",
      " 20   dist_from_city_center_mg_road_km        float64 \n",
      " 21   dist_from_tech_park_electronic_city_km  float64 \n",
      " 22   dist_from_tech_park_manyata_km          float64 \n",
      " 23   reviews_list                            object  \n",
      " 24   menu_item                               object  \n",
      " 25   full_review_text                        object  \n",
      " 26   review_count                            int64   \n",
      " 27   total_review_length                     int64   \n",
      " 28   avg_word_length                         float64 \n",
      " 29   text_for_sentiment                      object  \n",
      " 30   text_for_topics                         object  \n",
      " 31   sentiment_textblob                      float64 \n",
      " 32   sentiment_vader                         float64 \n",
      " 33   topic_0                                 float64 \n",
      " 34   topic_1                                 float64 \n",
      " 35   topic_2                                 float64 \n",
      " 36   topic_3                                 float64 \n",
      " 37   topic_4                                 float64 \n",
      " 38   topic_5                                 float64 \n",
      " 39   topic_6                                 float64 \n",
      " 40   topic_7                                 float64 \n",
      " 41   topic_8                                 float64 \n",
      " 42   topic_9                                 float64 \n",
      " 43   transformer_sentiment                   float64 \n",
      " 44   menu_item_vec_0                         float64 \n",
      " 45   menu_item_vec_1                         float64 \n",
      " 46   menu_item_vec_2                         float64 \n",
      " 47   menu_item_vec_3                         float64 \n",
      " 48   menu_item_vec_4                         float64 \n",
      " 49   menu_item_vec_5                         float64 \n",
      " 50   menu_item_vec_6                         float64 \n",
      " 51   menu_item_vec_7                         float64 \n",
      " 52   menu_item_vec_8                         float64 \n",
      " 53   menu_item_vec_9                         float64 \n",
      " 54   menu_item_vec_10                        float64 \n",
      " 55   menu_item_vec_11                        float64 \n",
      " 56   menu_item_vec_12                        float64 \n",
      " 57   menu_item_vec_13                        float64 \n",
      " 58   menu_item_vec_14                        float64 \n",
      " 59   menu_item_vec_15                        float64 \n",
      " 60   menu_item_vec_16                        float64 \n",
      " 61   menu_item_vec_17                        float64 \n",
      " 62   menu_item_vec_18                        float64 \n",
      " 63   menu_item_vec_19                        float64 \n",
      " 64   cuisines_vec_0                          float64 \n",
      " 65   cuisines_vec_1                          float64 \n",
      " 66   cuisines_vec_2                          float64 \n",
      " 67   cuisines_vec_3                          float64 \n",
      " 68   cuisines_vec_4                          float64 \n",
      " 69   cuisines_vec_5                          float64 \n",
      " 70   cuisines_vec_6                          float64 \n",
      " 71   cuisines_vec_7                          float64 \n",
      " 72   cuisines_vec_8                          float64 \n",
      " 73   cuisines_vec_9                          float64 \n",
      " 74   cuisines_vec_10                         float64 \n",
      " 75   cuisines_vec_11                         float64 \n",
      " 76   cuisines_vec_12                         float64 \n",
      " 77   cuisines_vec_13                         float64 \n",
      " 78   cuisines_vec_14                         float64 \n",
      " 79   cuisines_vec_15                         float64 \n",
      " 80   cuisines_vec_16                         float64 \n",
      " 81   cuisines_vec_17                         float64 \n",
      " 82   cuisines_vec_18                         float64 \n",
      " 83   cuisines_vec_19                         float64 \n",
      " 84   dish_liked_vec_0                        float64 \n",
      " 85   dish_liked_vec_1                        float64 \n",
      " 86   dish_liked_vec_2                        float64 \n",
      " 87   dish_liked_vec_3                        float64 \n",
      " 88   dish_liked_vec_4                        float64 \n",
      " 89   dish_liked_vec_5                        float64 \n",
      " 90   dish_liked_vec_6                        float64 \n",
      " 91   dish_liked_vec_7                        float64 \n",
      " 92   dish_liked_vec_8                        float64 \n",
      " 93   dish_liked_vec_9                        float64 \n",
      " 94   dish_liked_vec_10                       float64 \n",
      " 95   dish_liked_vec_11                       float64 \n",
      " 96   dish_liked_vec_12                       float64 \n",
      " 97   dish_liked_vec_13                       float64 \n",
      " 98   dish_liked_vec_14                       float64 \n",
      " 99   dish_liked_vec_15                       float64 \n",
      " 100  dish_liked_vec_16                       float64 \n",
      " 101  dish_liked_vec_17                       float64 \n",
      " 102  dish_liked_vec_18                       float64 \n",
      " 103  dish_liked_vec_19                       float64 \n",
      "dtypes: category(1), float64(84), int64(6), object(13)\n",
      "memory usage: 35.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_master.info(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c40c02b9-f9cf-4ddb-b49a-6cb0bb19587c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-19T16:38:08.013669Z",
     "iopub.status.busy": "2025-09-19T16:38:08.013425Z",
     "iopub.status.idle": "2025-09-19T16:38:08.069284Z",
     "shell.execute_reply": "2025-09-19T16:38:08.068534Z",
     "shell.execute_reply.started": "2025-09-19T16:38:08.013652Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-19 22:08:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- 1. Final Feature Selection & Data Preparation (DEFINITIVE VERSION) ---\u001b[0m\n",
      "\u001b[32m2025-09-19 22:08:08\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mFeature selection complete. Final shape of X: (45187, 90)\u001b[0m\n",
      "\u001b[32m2025-09-19 22:08:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mSeparating columns into Numerical, Categorical, and Binary types...\u001b[0m\n",
      "\u001b[32m2025-09-19 22:08:08\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mSeparation complete.\u001b[0m\n",
      "\u001b[32m2025-09-19 22:08:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mFound 84 Numerical features (including embeddings, sentiments, etc.).\u001b[0m\n",
      "\u001b[32m2025-09-19 22:08:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mFound 4 Categorical features: ['location', 'listed_in_type', 'listed_in_city', 'location_cluster']\u001b[0m\n",
      "\u001b[32m2025-09-19 22:08:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mFound 2 Binary features: ['online_order', 'book_table']\u001b[0m\n",
      "\u001b[32m2025-09-19 22:08:08\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mData split into training (36149) and testing (9038) rows.\u001b[0m\n",
      "\n",
      "--- Final X DataFrame Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45187 entries, 0 to 45186\n",
      "Columns: 90 entries, online_order to dish_liked_vec_19\n",
      "dtypes: category(4), float64(81), int64(5)\n",
      "memory usage: 29.8 MB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from loguru import logger\n",
    "import numpy as np\n",
    "\n",
    "logger.info(\"--- 1. Final Feature Selection & Data Preparation (DEFINITIVE VERSION) ---\")\n",
    "\n",
    "# --- Define Target and ALL Columns to Drop ---\n",
    "# This is the complete and correct list.\n",
    "cols_to_drop = [\n",
    "    # Identifiers & Keys\n",
    "    'name', \n",
    "    'address',\n",
    "    \n",
    "    # Raw/Intermediate NLP data that is no longer needed\n",
    "    'reviews_list', \n",
    "    'menu_item', \n",
    "    'full_review_text', \n",
    "    'text_for_sentiment', \n",
    "    'text_for_topics',\n",
    "    \n",
    "    # Original numerical features that have been replaced by their log versions in EDA,\n",
    "    # and will be handled by the pipeline from their raw form.\n",
    "    'votes_log', \n",
    "    'cost_log',\n",
    "    \n",
    "    # The original LIST-BASED columns that have been replaced by embeddings\n",
    "    'rest_type', \n",
    "    'cuisines', \n",
    "    'dish_liked',\n",
    "    \n",
    "    # Redundant categorical helper\n",
    "    'cluster_name'\n",
    "]\n",
    "\n",
    "# --- Create X and y ---\n",
    "# The target is the original, untransformed 'rate' column.\n",
    "y = df_master['rate']\n",
    "\n",
    "# X is everything from the master table EXCEPT the target and the columns to drop.\n",
    "X = df_master.drop(columns=['rate'] + cols_to_drop, errors='ignore')\n",
    "\n",
    "logger.success(f\"Feature selection complete. Final shape of X: {X.shape}\")\n",
    "\n",
    "# --- Identify Column Types for the Pipeline (The Correct Way) ---\n",
    "logger.info(\"Separating columns into Numerical, Categorical, and Binary types...\")\n",
    "\n",
    "# 1. Define BINARY features explicitly\n",
    "binary_features = ['online_order', 'book_table']\n",
    "\n",
    "# 2. Define CATEGORICAL features explicitly\n",
    "categorical_features = [\n",
    "    'location', \n",
    "    'listed_in_type', \n",
    "    'listed_in_city', \n",
    "    'location_cluster' # This is a category, not a number\n",
    "]\n",
    "\n",
    "# 3. ALL OTHER columns are NUMERICAL by definition\n",
    "# This is a robust way to select everything else.\n",
    "numerical_features = [\n",
    "    col for col in X.columns \n",
    "    if col not in binary_features and col not in categorical_features\n",
    "]\n",
    "\n",
    "logger.success(\"Separation complete.\")\n",
    "logger.info(f\"Found {len(numerical_features)} Numerical features (including embeddings, sentiments, etc.).\")\n",
    "logger.info(f\"Found {len(categorical_features)} Categorical features: {categorical_features}\")\n",
    "logger.info(f\"Found {len(binary_features)} Binary features: {binary_features}\")\n",
    "\n",
    "# --- Ensure correct dtypes and split the data ---\n",
    "for col in categorical_features:\n",
    "    X[col] = X[col].astype('category')\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "logger.success(f\"Data split into training ({X_train.shape[0]}) and testing ({X_test.shape[0]}) rows.\")\n",
    "\n",
    "# --- Final Verification ---\n",
    "print(\"\\n--- Final X DataFrame Info ---\")\n",
    "X.info(verbose=False) # Use verbose=False for a cleaner summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd270ce5-1ed9-47ce-948c-96edd2483038",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-19T16:38:10.798405Z",
     "iopub.status.busy": "2025-09-19T16:38:10.798125Z",
     "iopub.status.idle": "2025-09-19T16:38:10.809760Z",
     "shell.execute_reply": "2025-09-19T16:38:10.809060Z",
     "shell.execute_reply.started": "2025-09-19T16:38:10.798387Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-19 22:08:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- 2. Building the Definitive, Pandas-Aware Preprocessing Pipeline ---\u001b[0m\n",
      "\u001b[32m2025-09-19 22:08:10\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mDefinitive, Pandas-Aware preprocessing pipeline created successfully.\u001b[0m\n",
      "\n",
      "--- Preprocessor Blueprint ---\n",
      "ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('num',\n",
      "                                 Pipeline(steps=[('power', PowerTransformer()),\n",
      "                                                 ('scaler', StandardScaler())]),\n",
      "                                 ['votes', 'cost_for_two', 'latitude',\n",
      "                                  'longitude', 'dist_from_airport_km',\n",
      "                                  'dist_from_city_center_mg_road_km',\n",
      "                                  'dist_from_tech_park_electronic_city_km',\n",
      "                                  'dist_from_tech_park_manyata_km',\n",
      "                                  'review_count', 'total_review_leng...\n",
      "                                  'topic_6', 'topic_7', 'topic_8', 'topic_9',\n",
      "                                  'transformer_sentiment', 'menu_item_vec_0',\n",
      "                                  'menu_item_vec_1', 'menu_item_vec_2',\n",
      "                                  'menu_item_vec_3', 'menu_item_vec_4',\n",
      "                                  'menu_item_vec_5', ...]),\n",
      "                                ('cat', 'passthrough',\n",
      "                                 ['location', 'listed_in_type',\n",
      "                                  'listed_in_city', 'location_cluster']),\n",
      "                                ('bin', 'passthrough',\n",
      "                                 ['online_order', 'book_table'])],\n",
      "                  verbose_feature_names_out=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from loguru import logger\n",
    "\n",
    "logger.info(\"--- 2. Building the Definitive, Pandas-Aware Preprocessing Pipeline ---\")\n",
    "\n",
    "# ... (the transformer definitions are the same) ...\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('power', PowerTransformer(method='yeo-johnson')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "categorical_transformer = 'passthrough'\n",
    "binary_transformer = 'passthrough'\n",
    "\n",
    "# --- Create the ColumnTransformer with the CRITICAL FIX ---\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features),\n",
    "        ('bin', binary_transformer, binary_features)\n",
    "    ],\n",
    "    remainder='passthrough',\n",
    "    # <<--- THE FIX IS HERE --- >>\n",
    "    verbose_feature_names_out=False # This keeps column names clean\n",
    ")\n",
    "# We will set the output format later for compatibility\n",
    "preprocessor.set_output(transform=\"pandas\") # THIS IS THE MAGIC LINE\n",
    "# --- END OF FIX ---\n",
    "\n",
    "logger.success(\"Definitive, Pandas-Aware preprocessing pipeline created successfully.\")\n",
    "print(\"\\n--- Preprocessor Blueprint ---\")\n",
    "print(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddb0455b-7a0c-48f0-8fdc-1b85cf52e75c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-19T15:43:28.301775Z",
     "iopub.status.busy": "2025-09-19T15:43:28.301615Z",
     "iopub.status.idle": "2025-09-19T15:43:28.310755Z",
     "shell.execute_reply": "2025-09-19T15:43:28.310091Z",
     "shell.execute_reply.started": "2025-09-19T15:43:28.301760Z"
    }
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import xgboost as xgb\n",
    "# import catboost as cb\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.model_selection import KFold, cross_val_score\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "# import optuna\n",
    "# import mlflow\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from loguru import logger\n",
    "\n",
    "# # Assume X_train, X_test, y_train, y_test, preprocessor, and categorical_features\n",
    "# # are all defined from the previous cells.\n",
    "\n",
    "# def run_optimization_study_definitive(\n",
    "#     model_name: str,\n",
    "#     model_class,\n",
    "#     param_search_space,\n",
    "#     X_train: pd.DataFrame,\n",
    "#     y_train: pd.Series,\n",
    "#     X_test: pd.DataFrame,\n",
    "#     y_test: pd.Series,\n",
    "#     n_trials: int = 50,\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     The definitive, titan-level function for a full Optuna hyperparameter search\n",
    "#     with comprehensive, modern MLflow logging, using manual nested runs.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # --- 1. Set up the Experiment ---\n",
    "#     # The modern way to set an experiment. It will create it if it doesn't exist.\n",
    "#     mlflow.set_experiment(f\"Zomato_Prediction_v1{model_name}\")\n",
    "#     cv_strategy = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "#     # This is the main \"Parent Run\" that will contain all the Optuna trials\n",
    "#     with mlflow.start_run(run_name=f\"{model_name}_Optuna_Parent_Run\") as parent_run:\n",
    "#         mlflow.set_tag(\"model_type\", model_name)\n",
    "        \n",
    "#         # --- 2. Define the Optuna Objective Function with MANUAL nested runs ---\n",
    "#         def objective(trial: optuna.Trial) -> float:\n",
    "#             # Each Optuna trial is logged as its own explicit nested run\n",
    "#             with mlflow.start_run(run_name=f\"trial_{trial.number}\", nested=True) as child_run:\n",
    "#                 mlflow.set_tag(\"optuna_trial_number\", trial.number)\n",
    "                \n",
    "#                 # Get hyperparameters and log them to the child run\n",
    "#                 params = param_search_space(trial)\n",
    "#                 mlflow.log_params(params)\n",
    "                \n",
    "#                 # Special handling for CatBoost's categorical features parameter\n",
    "#                 if model_name == \"CatBoost\":\n",
    "#                     model_instance = model_class(**params, cat_features=categorical_features, verbose=0)\n",
    "#                 else:\n",
    "#                     model_instance = model_class(**params)\n",
    "\n",
    "#                 # Create the full scikit-learn pipeline for this trial\n",
    "#                 model_pipeline = Pipeline(steps=[\n",
    "#                     ('preprocessor', preprocessor),\n",
    "#                     ('regressor', model_instance)\n",
    "#                 ])\n",
    "                \n",
    "#                 # Perform cross-validation\n",
    "#                 rmse_score = -cross_val_score(\n",
    "#                     model_pipeline, X_train, y_train, \n",
    "#                     cv=cv_strategy, \n",
    "#                     scoring='neg_root_mean_squared_error',\n",
    "#                     n_jobs=-1\n",
    "#                 ).mean()\n",
    "                \n",
    "#                 # Log the result of this trial to its child run\n",
    "#                 mlflow.log_metric(\"cv_rmse\", rmse_score)\n",
    "                \n",
    "#                 # Optuna maximizes, so we return the score it should maximize\n",
    "#                 return rmse_score\n",
    "\n",
    "#         # --- 3. Run the Optuna Study ---\n",
    "#         logger.info(f\"--- Starting Optuna study for {model_name} with {n_trials} trials ---\")\n",
    "#         study = optuna.create_study(direction='minimize') # Maximize neg_rmse\n",
    "#         study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
    "        \n",
    "#         # --- 4. Log Optuna Analysis Plots to the PARENT run ---\n",
    "#         logger.info(\"Logging Optuna analysis plots to the parent run...\")\n",
    "#         try:\n",
    "#             fig_importance = optuna.visualization.plot_param_importances(study)\n",
    "#             fig_history = optuna.visualization.plot_optimization_history(study)\n",
    "#             mlflow.log_figure(fig_importance, \"optuna_param_importances.html\")\n",
    "#             mlflow.log_figure(fig_history, \"optuna_optimization_history.html\")\n",
    "#         except Exception as e:\n",
    "#             logger.warning(f\"Could not generate Optuna plots. Error: {e}\")\n",
    "        \n",
    "#         # --- 5. Train and Log the FINAL Champion Model in a SEPARATE run for clarity ---\n",
    "#         logger.info(\"Training and logging the final champion model in a new run...\")\n",
    "#         best_params = study.best_params\n",
    "        \n",
    "#         # We start a new top-level run for the champion model\n",
    "#         with mlflow.start_run(run_name=f\"Champion_{model_name}\") as champion_run:\n",
    "#             mlflow.log_params(best_params)\n",
    "#             mlflow.log_metric(\"best_cv_rmse_from_optuna\", -study.best_value)\n",
    "#             mlflow.set_tag(\"source_optuna_run_id\", parent_run.info.run_id)\n",
    "\n",
    "#             if model_name == \"CatBoost\":\n",
    "#                 final_model = model_class(**best_params, cat_features=categorical_features, verbose=0)\n",
    "#             else:\n",
    "#                 final_model = model_class(**best_params)\n",
    "            \n",
    "#             final_pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('regressor', final_model)])\n",
    "#             final_pipeline.fit(X_train, y_train)\n",
    "            \n",
    "#             # --- 6. Comprehensive Evaluation with mlflow.evaluate() ---\n",
    "#             logger.info(\"Performing comprehensive evaluation on the test set...\")\n",
    "#             eval_data = X_test.copy()\n",
    "#             eval_data[y_test.name] = y_test\n",
    "            \n",
    "#             results = mlflow.evaluate(\n",
    "#                 model=final_pipeline, data=eval_data, targets=y_test.name,\n",
    "#                 model_type=\"regressor\", evaluators=[\"default\"]\n",
    "#             )\n",
    "#             logger.success(f\"Evaluation complete. Test R2 Score from mlflow.evaluate: {results.metrics['r2_score']:.4f}\")\n",
    "            \n",
    "#             mlflow.sklearn.log_model(final_pipeline, \"champion_model\")\n",
    "\n",
    "#     logger.info(f\"--- All runs for {model_name} are complete. Check the MLflow UI. ---\")\n",
    "#     return study\n",
    "\n",
    "# # ===================================================================\n",
    "# #                      EXECUTION\n",
    "# # ===================================================================\n",
    "\n",
    "# # --- 1. Define the search space for XGBoost ---\n",
    "# def xgb_search_space(trial):\n",
    "#     return {\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 200, 2000, step=100),\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2, log=True),\n",
    "#         'max_depth': trial.suggest_int('max_depth', 4, 12),\n",
    "#         'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "#         'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "#         'tree_method': 'hist', 'enable_categorical': True, 'device': 'cuda', 'random_state': 42\n",
    "#     }\n",
    "\n",
    "# # --- 2. LAUNCH THE EXPERIMENT FOR XGBOOST ---\n",
    "# study_xgb = run_optimization_study_definitive(\n",
    "#     model_name=\"XGBoost\", model_class=xgb.XGBRegressor,\n",
    "#     param_search_space=xgb_search_space,\n",
    "#     X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test, n_trials=50\n",
    "# )\n",
    "\n",
    "# # --- 3. Define the search space for CatBoost ---\n",
    "# def catboost_search_space(trial):\n",
    "#     return {\n",
    "#         'iterations': trial.suggest_int('iterations', 200, 2000, step=100),\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2, log=True),\n",
    "#         'depth': trial.suggest_int('depth', 4, 12),\n",
    "#         'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-2, 10.0, log=True),\n",
    "#         'task_type': 'GPU', 'random_state': 42\n",
    "#     }\n",
    "\n",
    "# # --- 4. LAUNCH THE EXPERIMENT FOR CATBOOST ---\n",
    "# # study_cat = run_optimization_study_definitive(\n",
    "# #     model_name=\"CatBoost\", model_class=cb.CatBoostRegressor,\n",
    "# #     param_search_space=catboost_search_space,\n",
    "# #     X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test, n_trials=50\n",
    "# # )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705b6076-7094-4f67-8163-7e6fc4a4b459",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9653403b-7432-48bb-b425-a6ae28feeb21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-19T15:43:28.311428Z",
     "iopub.status.busy": "2025-09-19T15:43:28.311246Z",
     "iopub.status.idle": "2025-09-19T15:43:28.320849Z",
     "shell.execute_reply": "2025-09-19T15:43:28.320142Z",
     "shell.execute_reply.started": "2025-09-19T15:43:28.311414Z"
    }
   },
   "outputs": [],
   "source": [
    "# # ===================================================================\n",
    "# # CELL 3: The God-Level Evaluation Suite\n",
    "# # ===================================================================\n",
    "# from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import mlflow\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# def evaluate_and_log_champion(pipeline, model_name: str, X_test: pd.DataFrame, y_test: pd.Series):\n",
    "#     \"\"\"\n",
    "#     Performs a deep evaluation of a final model and logs all metrics and\n",
    "#     visualizations as artifacts to the active MLflow run.\n",
    "#     \"\"\"\n",
    "#     logger.info(f\"--- Performing Deep Evaluation for Champion {model_name} Model ---\")\n",
    "    \n",
    "#     y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "#     # --- 1. Log Core Metrics ---\n",
    "#     metrics = {\n",
    "#         \"test_rmse\": np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "#         \"test_mae\": mean_absolute_error(y_test, y_pred),\n",
    "#         \"test_r2\": r2_score(y_test, y_pred)\n",
    "#     }\n",
    "#     mlflow.log_metrics(metrics)\n",
    "#     logger.success(f\"Test Set Performance Logged: {metrics}\")\n",
    "    \n",
    "#     # --- 2. Create and Log Visualizations ---\n",
    "#     logger.info(\"Generating and logging evaluation plots...\")\n",
    "    \n",
    "#     # Prediction Error Plot\n",
    "#     plt.figure(figsize=(10, 10))\n",
    "#     sns.scatterplot(x=y_test, y=y_pred, alpha=0.5)\n",
    "#     plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "#     plt.xlabel(\"Actual Ratings\", fontsize=14); plt.ylabel(\"Predicted Ratings\", fontsize=14)\n",
    "#     plt.title(\"Prediction Error Plot (Actual vs. Predicted)\", fontsize=16)\n",
    "#     mlflow.log_figure(plt.gcf(), \"prediction_error_plot.png\"); plt.close()\n",
    "\n",
    "#     # Residuals Plot\n",
    "#     residuals = y_test - y_pred\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     sns.histplot(residuals, kde=True, bins=50)\n",
    "#     plt.xlabel(\"Residuals (Actual - Predicted)\", fontsize=14)\n",
    "#     plt.title(\"Distribution of Residuals\", fontsize=16)\n",
    "#     mlflow.log_figure(plt.gcf(), \"residuals_plot.png\"); plt.close()\n",
    "    \n",
    "#     # Feature Importance Plot (if available)\n",
    "#     model_step = pipeline.named_steps['regressor']\n",
    "#     if hasattr(model_step, 'feature_importances_'):\n",
    "#         try:\n",
    "#             feature_names = pipeline.named_steps['preprocessor'].get_feature_names_out()\n",
    "#             importances = pd.Series(model_step.feature_importances_, index=feature_names).sort_values(ascending=False)\n",
    "#             plt.figure(figsize=(12, 12))\n",
    "#             sns.barplot(x=importances.head(30), y=importances.head(30).index)\n",
    "#             plt.title(f\"Top 30 Feature Importances - {model_name}\", fontsize=16)\n",
    "#             plt.tight_layout()\n",
    "#             mlflow.log_figure(plt.gcf(), \"feature_importance.png\"); plt.close()\n",
    "#         except Exception as e:\n",
    "#             logger.warning(f\"Could not generate feature importance plot. Error: {e}\")\n",
    "            \n",
    "#     logger.success(\"All evaluation artifacts have been logged to MLflow.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1f62d32-55a0-4258-a301-f66cfc0b83ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-19T15:43:28.321601Z",
     "iopub.status.busy": "2025-09-19T15:43:28.321409Z",
     "iopub.status.idle": "2025-09-19T15:43:28.333909Z",
     "shell.execute_reply": "2025-09-19T15:43:28.333253Z",
     "shell.execute_reply.started": "2025-09-19T15:43:28.321587Z"
    }
   },
   "outputs": [],
   "source": [
    "# # ===================================================================\n",
    "# # CELL 4: The Definitive Training and Optimization Pipeline\n",
    "# # ===================================================================\n",
    "# import optuna\n",
    "# import os\n",
    "# from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "# def run_optimization_study(\n",
    "#     model_name: str,\n",
    "#     model_class,\n",
    "#     param_search_space,\n",
    "#     X_train: pd.DataFrame,\n",
    "#     y_train: pd.Series,\n",
    "#     X_test: pd.DataFrame,\n",
    "#     y_test: pd.Series,\n",
    "#     n_trials: int = 50,\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     The definitive, titan-level function for a full Optuna hyperparameter search\n",
    "#     with comprehensive, modern MLflow logging and persistent Optuna storage.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # --- 1. Set up Optuna Study with Persistent Storage ---\n",
    "#     # This is the fix for your missing sqlite file.\n",
    "#     optuna_db_path = \"optuna_studies\"\n",
    "#     os.makedirs(optuna_db_path, exist_ok=True)\n",
    "#     storage_name = f\"sqlite:///{optuna_db_path}/{model_name}_study.db\"\n",
    "    \n",
    "#     study = optuna.create_study(\n",
    "#         direction='minimize',\n",
    "#         study_name=f\"Zomato_{model_name}_Optimization\",\n",
    "#         storage=storage_name,\n",
    "#         load_if_exists=True # This allows you to resume studies\n",
    "#     )\n",
    "    \n",
    "#     # --- 2. Set up MLflow Experiment ---\n",
    "#     mlflow.set_experiment(f\"Zomato_Prediction_v1{model_name}\")\n",
    "#     cv_strategy = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "#     # --- 3. Define the Objective Function ---\n",
    "#     def objective(trial: optuna.Trial) -> float:\n",
    "#         with mlflow.start_run(run_name=f\"trial_{trial.number}\", nested=True):\n",
    "#             params = param_search_space(trial)\n",
    "#             mlflow.log_params(params)\n",
    "            \n",
    "#             # Special handling for CatBoost/XGBoost categorical features\n",
    "#             if model_name == \"CatBoost\":\n",
    "#                 model_instance = model_class(**params, cat_features=categorical_features, verbose=0)\n",
    "#             elif model_name == \"XGBoost\":\n",
    "#                 # Ensure the model class itself is called with the right params\n",
    "#                 model_instance = model_class(**{**params, 'enable_categorical': True})\n",
    "#             else:\n",
    "#                 model_instance = model_class(**params)\n",
    "\n",
    "#             pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('regressor', model_instance)])\n",
    "            \n",
    "#             scores = cross_val_score(\n",
    "#                 pipeline, X_train, y_train,\n",
    "#                 cv=cv_strategy, scoring='neg_root_mean_squared_error', n_jobs=-1\n",
    "#             )\n",
    "#             avg_rmse = -np.mean(scores)\n",
    "#             mlflow.log_metric(\"cv_rmse\", avg_rmse)\n",
    "#             return avg_rmse\n",
    "\n",
    "#     # --- 4. Run the Study ---\n",
    "#     logger.info(f\"--- Starting Optuna study for {model_name} with {n_trials} trials ---\")\n",
    "#     study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
    "    \n",
    "#     # --- 5. Train and Log the Champion Model in a NEW Parent Run ---\n",
    "#     logger.info(\"Training and logging the final champion model...\")\n",
    "#     best_params = study.best_params\n",
    "    \n",
    "#     with mlflow.start_run(run_name=f\"Champion_{model_name}\") as champion_run:\n",
    "#         mlflow.log_params(best_params)\n",
    "#         mlflow.log_metric(\"best_cv_rmse_from_optuna\", study.best_value)\n",
    "        \n",
    "#         if model_name == \"CatBoost\":\n",
    "#             final_model = model_class(**best_params, cat_features=categorical_features, verbose=0)\n",
    "#         elif model_name == \"XGBoost\":\n",
    "#             final_model = model_class(**{**best_params, 'enable_categorical': True})\n",
    "#         else:\n",
    "#             final_model = model_class(**best_params)\n",
    "            \n",
    "#         final_pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('regressor', final_model)])\n",
    "#         final_pipeline.fit(X_train, y_train)\n",
    "        \n",
    "#         # --- 6. Perform Comprehensive Evaluation using our God-Level Function ---\n",
    "#         evaluate_and_log_champion(final_pipeline, model_name, X_test, y_test)\n",
    "        \n",
    "#         # --- 7. Log All Optuna Visualizations (Your Request) ---\n",
    "#         logger.info(\"Logging all available Optuna visualization plots...\")\n",
    "#         try:\n",
    "#             mlflow.log_figure(optuna.visualization.plot_optimization_history(study), \"optuna_history.html\")\n",
    "#             mlflow.log_figure(optuna.visualization.plot_param_importances(study), \"optuna_param_importances.html\")\n",
    "#             mlflow.log_figure(optuna.visualization.plot_slice(study), \"optuna_slice.html\")\n",
    "#             mlflow.log_figure(optuna.visualization.plot_parallel_coordinate(study), \"optuna_parallel_coordinate.html\")\n",
    "#             mlflow.log_figure(optuna.visualization.plot_contour(study), \"optuna_contour.html\")\n",
    "#         except Exception as e:\n",
    "#             logger.warning(f\"Could not generate all Optuna plots. Error: {e}\")\n",
    "        \n",
    "#         # --- 8. Log the Final Model ---\n",
    "#         mlflow.sklearn.log_model(final_pipeline, \"champion_model\")\n",
    "\n",
    "#     logger.info(f\"--- Run for {model_name} complete. Check the MLflow UI and Optuna Dashboard. ---\")\n",
    "#     return study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1ba01f4-bee2-445c-910b-de2f841036b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-19T15:43:28.334627Z",
     "iopub.status.busy": "2025-09-19T15:43:28.334462Z",
     "iopub.status.idle": "2025-09-19T15:43:28.345685Z",
     "shell.execute_reply": "2025-09-19T15:43:28.344851Z",
     "shell.execute_reply.started": "2025-09-19T15:43:28.334613Z"
    }
   },
   "outputs": [],
   "source": [
    "# # ===================================================================\n",
    "# # CELL 5: Execution - Train XGBoost\n",
    "# # ===================================================================\n",
    "\n",
    "# # --- Define the search space for XGBoost ---\n",
    "# def xgb_search_space(trial):\n",
    "#     return {\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 200, 1000, step=100),\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 0.02, 0.2, log=True),\n",
    "#         'max_depth': trial.suggest_int('max_depth', 4, 8),\n",
    "#         'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
    "#         'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 1.0),\n",
    "#         'tree_method': 'hist', 'device': 'cuda', 'random_state': 42\n",
    "#     }\n",
    "\n",
    "# # --- LAUNCH THE EXPERIMENT FOR XGBOOST ---\n",
    "# study_xgb = run_optimization_study(\n",
    "#     model_name=\"XGBoost\", \n",
    "#     model_class=xgb.XGBRegressor,\n",
    "#     param_search_space=xgb_search_space,\n",
    "#     X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test, n_trials=3\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fedf91-c63d-4b1a-b1b8-027c1311944e",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6454964c-1b58-4fae-8bf2-e7b62a7c5c50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-19T19:58:07.697789Z",
     "iopub.status.busy": "2025-09-19T19:58:07.697457Z",
     "iopub.status.idle": "2025-09-19T19:58:07.713393Z",
     "shell.execute_reply": "2025-09-19T19:58:07.712597Z",
     "shell.execute_reply.started": "2025-09-19T19:58:07.697770Z"
    }
   },
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# CELL 1: The God-Level Evaluation Suite (FINAL)\n",
    "# ===================================================================\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import json\n",
    "import graphviz # <<< Import graphviz\n",
    "\n",
    "def evaluate_and_log_champion(pipeline, model_name: str, X_test: pd.DataFrame, y_test: pd.Series):\n",
    "    \"\"\"\n",
    "    Performs a deep evaluation of a final model and logs all metrics and\n",
    "    visualizations as artifacts to the active MLflow run. Includes intuitive,\n",
    "    percentage-based metrics for communication.\n",
    "    \"\"\"\n",
    "    logger.info(f\"--- Performing Deep Evaluation for Champion {model_name} Model ---\")\n",
    "    \n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    # --- 1. Log Core Technical Metrics ---\n",
    "    metrics = {\n",
    "        \"test_rmse\": np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "        \"test_mae\": mean_absolute_error(y_test, y_pred),\n",
    "        \"test_r2\": r2_score(y_test, y_pred)\n",
    "    }\n",
    "    \n",
    "    # --- 2. Calculate and Log Intuitive, Percentage-Based Metrics ---\n",
    "    \n",
    "    # \"Accuracy\" within a tolerance of 0.25 stars\n",
    "    tolerance = 0.25\n",
    "    accuracy_within_tolerance = np.mean(np.abs(y_test - y_pred) <= tolerance) * 100\n",
    "    metrics[\"accuracy_within_0.25_stars_pct\"] = accuracy_within_tolerance\n",
    "    \n",
    "    # Mean Absolute Percentage Error (MAPE)\n",
    "    # We add a small epsilon to avoid division by zero for any zero-rated items\n",
    "    mape = np.mean(np.abs((y_test - y_pred) / (y_test + 1e-8))) * 100\n",
    "    metrics[\"mape_pct\"] = mape\n",
    "    \n",
    "    # R-squared as a percentage\n",
    "    metrics[\"explained_variance_pct\"] = metrics[\"test_r2\"] * 100\n",
    "    \n",
    "    # Log all metrics to MLflow\n",
    "    mlflow.log_metrics(metrics)\n",
    "    logger.success(f\"Test Set Performance Logged (Technical): RMSE={metrics['test_rmse']:.4f}, R2={metrics['test_r2']:.4f}\")\n",
    "    logger.success(f\"Test Set Performance Logged (Business): Accuracy (±0.25)={accuracy_within_tolerance:.2f}%, MAPE={mape:.2f}%\")\n",
    "    \n",
    "    # --- 3. Create and Log Visualizations (unchanged) ---\n",
    "    logger.info(\"Generating and logging evaluation plots...\")\n",
    "    # ... (all the plotting code remains exactly the same) ...\n",
    "    plt.figure(figsize=(10, 10)); sns.scatterplot(x=y_test, y=y_pred, alpha=0.5); plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2); plt.xlabel(\"Actual Ratings\", fontsize=14); plt.ylabel(\"Predicted Ratings\", fontsize=14); plt.title(\"Prediction Error Plot (Actual vs. Predicted)\", fontsize=16); mlflow.log_figure(plt.gcf(), \"prediction_error_plot.png\"); plt.close()\n",
    "    residuals = y_test - y_pred\n",
    "    plt.figure(figsize=(10, 6)); sns.histplot(residuals, kde=True, bins=50); plt.xlabel(\"Residuals (Actual - Predicted)\", fontsize=14); plt.title(\"Distribution of Residuals\", fontsize=16); mlflow.log_figure(plt.gcf(), \"residuals_plot.png\"); plt.close()\n",
    "    model_step = pipeline.named_steps['regressor']\n",
    "    if hasattr(model_step, 'feature_importances_'):\n",
    "        try:\n",
    "            feature_names = pipeline.named_steps['preprocessor'].get_feature_names_out()\n",
    "            importances = pd.Series(model_step.feature_importances_, index=feature_names).sort_values(ascending=False)\n",
    "            plt.figure(figsize=(12, 12)); sns.barplot(x=importances.head(30), y=importances.head(30).index); plt.title(f\"Top 30 Feature Importances - {model_name}\", fontsize=16); plt.tight_layout(); mlflow.log_figure(plt.gcf(), \"feature_importance.png\"); plt.close()\n",
    "        except Exception as e: logger.warning(f\"Could not generate generic feature importance plot. Error: {e}\")\n",
    "    logger.success(\"All evaluation artifacts have been logged to MLflow.\")\n",
    "\n",
    "def log_xgboost_artifacts(pipeline, model_name: str):\n",
    "    logger.info(f\"--- Logging XGBoost-specific artifacts for {model_name} ---\")\n",
    "    xgb_model = pipeline.named_steps.get('regressor')\n",
    "    if not isinstance(xgb_model, xgb.XGBModel):\n",
    "        logger.warning(f\"Model is not an XGBoost model. Skipping XGBoost artifact logging.\")\n",
    "        return\n",
    "        \n",
    "    # --- 1. Log multiple types of feature importances (Unchanged) ---\n",
    "    importance_types = ['weight', 'gain', 'cover', 'total_gain', 'total_cover']\n",
    "    feature_names = pipeline.named_steps['preprocessor'].get_feature_names_out()\n",
    "    for imp_type in importance_types:\n",
    "        try:\n",
    "            scores = xgb_model.get_booster().get_score(importance_type=imp_type)\n",
    "            if not scores: continue\n",
    "            importance_df = pd.DataFrame({'Feature': list(scores.keys()), 'Score': list(scores.values())}).sort_values(by='Score', ascending=False).head(30)\n",
    "            plt.figure(figsize=(12, 10)); sns.barplot(x='Score', y='Feature', data=importance_df); plt.title(f\"XGBoost Feature Importance ({imp_type})\", fontsize=16); plt.tight_layout(); mlflow.log_figure(plt.gcf(), f\"xgb_importance_{imp_type}.png\"); plt.close()\n",
    "            logger.success(f\"Logged feature importance plot for type: {imp_type}\")\n",
    "        except Exception as e: logger.warning(f\"Could not generate importance plot for type '{imp_type}'. Error: {e}\")\n",
    "\n",
    "    # --- 2. Log a sample decision tree as PNG (Unchanged) ---\n",
    "    try:\n",
    "        fig, ax = plt.subplots(figsize=(30, 30)); xgb.plot_tree(xgb_model, tree_idx=0, ax=ax, feature_names=feature_names); plt.title(\"XGBoost - First Decision Tree\", fontsize=24); mlflow.log_figure(fig, \"xgb_first_tree.png\"); plt.close()\n",
    "        logger.success(\"Logged sample decision tree plot.\")\n",
    "    except Exception as e: logger.warning(f\"Could not plot XGBoost tree. Error: {e}\")\n",
    "        \n",
    "    # <<< --- NEW INTERACTIVE PLOT LOGIC --- >>>\n",
    "    \n",
    "    # --- 3. Log the first tree as an interactive SVG file ---\n",
    "    try:\n",
    "        # Create a graphviz representation of the first tree\n",
    "        tree_dot = xgb.to_graphviz(xgb_model, tree_idx=0, feature_names=feature_names)\n",
    "        # Save it as an SVG file\n",
    "        svg_file_path = \"xgb_interactive_tree.svg\"\n",
    "        tree_dot.render(outfile=svg_file_path, format='svg', view=False, cleanup=True)\n",
    "        # Log the SVG file as an artifact\n",
    "        mlflow.log_artifact(svg_file_path, \"interactive_plots\")\n",
    "        logger.success(\"Logged interactive SVG decision tree plot.\")\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Could not create interactive SVG tree plot. Ensure graphviz is installed. Error: {e}\")\n",
    "    # <<< --- END NEW LOGIC --- >>>\n",
    "\n",
    "    # --- 4. Log the model's full configuration as JSON (Unchanged) ---\n",
    "    try:\n",
    "        config = xgb_model.get_params()\n",
    "        mlflow.log_dict(config, \"xgb_configuration.json\")\n",
    "        logger.success(\"Logged XGBoost model configuration.\")\n",
    "    except Exception as e: logger.warning(f\"Could not log XGBoost configuration. Error: {e}\")\n",
    "\n",
    "import catboost as cb # Add catboost import\n",
    "\n",
    "def log_catboost_artifacts(pipeline, model_name: str):\n",
    "    \"\"\"\n",
    "    Logs artifacts specific to a trained CatBoost model.\n",
    "    \"\"\"\n",
    "    logger.info(f\"--- Logging CatBoost-specific artifacts for {model_name} ---\")\n",
    "    \n",
    "    # Safely extract the CatBoost model from the pipeline\n",
    "    cat_model = pipeline.named_steps.get('regressor')\n",
    "    if not isinstance(cat_model, cb.CatBoost):\n",
    "        logger.warning(f\"Model is not a CatBoost model. Skipping artifact logging.\")\n",
    "        return\n",
    "        \n",
    "    # 1. Log feature importances\n",
    "    try:\n",
    "        feature_importances = cat_model.get_feature_importance()\n",
    "        feature_names = cat_model.feature_names_\n",
    "        \n",
    "        importance_df = pd.DataFrame({\n",
    "            'Feature': feature_names,\n",
    "            'Importance': feature_importances\n",
    "        }).sort_values(by='Importance', ascending=False).head(30)\n",
    "        \n",
    "        plt.figure(figsize=(12, 10))\n",
    "        sns.barplot(x='Importance', y='Feature', data=importance_df)\n",
    "        plt.title(f\"CatBoost Feature Importance\", fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        mlflow.log_figure(plt.gcf(), f\"catboost_feature_importance.png\")\n",
    "        plt.close()\n",
    "        logger.success(f\"Logged CatBoost feature importance plot.\")\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Could not generate CatBoost feature importance plot. Error: {e}\")\n",
    "\n",
    "    # 2. Log the model's full configuration as JSON\n",
    "    try:\n",
    "        config = cat_model.get_params()\n",
    "        # Convert non-serializable types to string\n",
    "        for key, value in config.items():\n",
    "            if not isinstance(value, (str, int, float, bool, list, dict, type(None))):\n",
    "                config[key] = str(value)\n",
    "        mlflow.log_dict(config, \"catboost_configuration.json\")\n",
    "        logger.success(\"Logged CatBoost model configuration.\")\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Could not log CatBoost configuration. Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "43e4a4a7-dd5f-4fde-b2bb-1b47c20506fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-19T19:53:52.987555Z",
     "iopub.status.busy": "2025-09-19T19:53:52.987225Z",
     "iopub.status.idle": "2025-09-19T19:53:53.000154Z",
     "shell.execute_reply": "2025-09-19T19:53:52.999222Z",
     "shell.execute_reply.started": "2025-09-19T19:53:52.987537Z"
    }
   },
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# CELL 2: The Definitive Training and Optimization Pipeline (FINAL)\n",
    "# ===================================================================\n",
    "# ... (all imports and the DtypeEnforcingModel class are the same) ...\n",
    "import optuna, os\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from mlflow.models import infer_signature\n",
    "import mlflow.pyfunc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class DtypeEnforcingModel(mlflow.pyfunc.PythonModel):\n",
    "    def __init__(self, pipeline, categorical_features): self.pipeline = pipeline; self.categorical_features = categorical_features\n",
    "    def _enforce_dtypes(self, data: pd.DataFrame) -> pd.DataFrame:\n",
    "        data_copy = data.copy();\n",
    "        for col in self.categorical_features:\n",
    "            if col in data_copy.columns: data_copy[col] = data_copy[col].astype('category')\n",
    "        return data_copy\n",
    "    def predict(self, context, model_input: pd.DataFrame) -> np.ndarray:\n",
    "        processed_input = self._enforce_dtypes(model_input); return self.pipeline.predict(processed_input)\n",
    "\n",
    "def run_optimization_study_flexible(\n",
    "    model_name: str, model_class, param_search_space,\n",
    "    X_train: pd.DataFrame, y_train: pd.Series,\n",
    "    X_test: pd.DataFrame, y_test: pd.Series,\n",
    "    preprocessor,\n",
    "    n_trials: int = 50\n",
    "):\n",
    "    optuna_db_path = \"optuna_studies\"; os.makedirs(optuna_db_path, exist_ok=True); storage_name = f\"sqlite:///{optuna_db_path}/{model_name}_study.db\"\n",
    "    study = optuna.create_study(direction='minimize', study_name=f\"Zomato_{model_name}_Optimization\", storage=storage_name, load_if_exists=True)\n",
    "    mlflow.set_experiment(f\"Zomato_Prediction_v1_{model_name}\"); cv_strategy = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    def objective(trial: optuna.Trial) -> float:\n",
    "        with mlflow.start_run(run_name=f\"trial_{trial.number}\", nested=True):\n",
    "            params = param_search_space(trial); mlflow.log_params(params)\n",
    "            \n",
    "            # <<< --- START OF THE BUG FIX --- >>>\n",
    "            if model_name == \"CatBoost\":\n",
    "                model_instance = model_class(**params, cat_features=categorical_features, verbose=0)\n",
    "            # Use 'in' to catch both \"XGBoost\" and \"XGBoost_RF\"\n",
    "            elif \"XGBoost\" in model_name: \n",
    "                model_instance = model_class(**{**params, 'enable_categorical': True})\n",
    "            else:\n",
    "                model_instance = model_class(**params)\n",
    "            # <<< --- END OF THE BUG FIX --- >>>\n",
    "\n",
    "            pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('regressor', model_instance)])\n",
    "            logger.info(f\"--- [Trial {trial.number}] Starting 5-Fold CV ---\")\n",
    "            fold_scores = []\n",
    "            for fold, (train_idx, val_idx) in enumerate(cv_strategy.split(X_train, y_train)):\n",
    "                logger.info(f\"  [Trial {trial.number}, Fold {fold+1}/5] Training...\")\n",
    "                X_train_fold, X_val_fold = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "                y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "                pipeline.fit(X_train_fold, y_train_fold)\n",
    "                preds = pipeline.predict(X_val_fold); rmse = np.sqrt(mean_squared_error(y_val_fold, preds))\n",
    "                fold_scores.append(rmse); logger.success(f\"  [Trial {trial.number}, Fold {fold+1}/5] RMSE: {rmse:.4f}\")\n",
    "            avg_rmse = np.mean(fold_scores); mlflow.log_metric(\"cv_rmse\", avg_rmse); return avg_rmse\n",
    "            \n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
    "    logger.info(\"Training and logging the final champion model...\")\n",
    "    best_params = study.best_params\n",
    "    with mlflow.start_run(run_name=f\"Champion_{model_name}\") as champion_run:\n",
    "        mlflow.log_params(best_params); mlflow.log_metric(\"best_cv_rmse_from_optuna\", study.best_value)\n",
    "        \n",
    "        # <<< --- START OF THE BUG FIX (repeated for final model) --- >>>\n",
    "        if model_name == \"CatBoost\":\n",
    "            final_model = model_class(**best_params, cat_features=categorical_features, verbose=0)\n",
    "        elif \"XGBoost\" in model_name:\n",
    "            final_model = model_class(**{**best_params, 'enable_categorical': True})\n",
    "        else:\n",
    "            final_model = model_class(**best_params)\n",
    "        # <<< --- END OF THE BUG FIX --- >>>\n",
    "\n",
    "        final_pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('regressor', final_model)])\n",
    "        final_pipeline.fit(X_train, y_train)\n",
    "        evaluate_and_log_champion(final_pipeline, model_name, X_test, y_test)\n",
    "        if \"XGBoost\" in model_name: log_xgboost_artifacts(final_pipeline, model_name)\n",
    "        elif model_name == \"CatBoost\":\n",
    "            log_catboost_artifacts(final_pipeline, model_name)    \n",
    "        \n",
    "        # ... (rest of the function is the same) ...\n",
    "        logger.info(\"Logging all available Optuna visualization plots...\")\n",
    "        plot_functions = [\"plot_contour\", \"plot_edf\", \"plot_hypervolume_history\", \"plot_intermediate_values\", \"plot_optimization_history\", \"plot_parallel_coordinate\", \"plot_param_importances\", \"plot_pareto_front\", \"plot_rank\", \"plot_slice\", \"plot_terminator_improvement\", \"plot_timeline\"]\n",
    "        for plot_func_name in plot_functions:\n",
    "            try:\n",
    "                plot_func = getattr(optuna.visualization, plot_func_name); fig = plot_func(study); mlflow.log_figure(fig, f\"optuna_{plot_func_name}.html\")\n",
    "            except (ValueError, TypeError) as e: logger.warning(f\"Could not generate Optuna plot '{plot_func_name}'. Skipping. Error: {e}\")\n",
    "            except Exception as e: logger.error(f\"An unexpected error occurred while generating plot '{plot_func_name}'. Skipping. Error: {e}\")\n",
    "        logger.info(\"Wrapping model in custom PyFunc and logging...\")\n",
    "        wrapped_model = DtypeEnforcingModel(pipeline=final_pipeline, categorical_features=categorical_features)\n",
    "        signature = infer_signature(X_train, final_pipeline.predict(X_train))\n",
    "        mlflow.pyfunc.log_model(\n",
    "            artifact_path=\"champion_model\", # This creates the folder\n",
    "            python_model=wrapped_model,\n",
    "            signature=signature,\n",
    "            registered_model_name=f\"{model_name}_Zomato_Champion\"\n",
    "        )\n",
    "\n",
    "    logger.info(f\"--- Run for {model_name} complete. Check the MLflow UI and Optuna Dashboard. ---\")\n",
    "    return study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3b6a7f71-1800-4255-8161-38980abb63f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-19T20:02:01.182482Z",
     "iopub.status.busy": "2025-09-19T20:02:01.182150Z",
     "iopub.status.idle": "2025-09-20T05:05:59.977332Z",
     "shell.execute_reply": "2025-09-20T05:05:59.974812Z",
     "shell.execute_reply.started": "2025-09-19T20:02:01.182449Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-20 01:32:01,209] Using an existing study with name 'Zomato_XGBoost_Optimization' instead of creating a new one.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e8bfad3b5ef4502b2ed260b344172c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-20 01:32:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 101] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 01:32:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 101, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:32:19\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 101, Fold 1/5] RMSE: 0.1492\u001b[0m\n",
      "\u001b[32m2025-09-20 01:32:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 101, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:32:38\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 101, Fold 2/5] RMSE: 0.1363\u001b[0m\n",
      "\u001b[32m2025-09-20 01:32:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 101, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:32:57\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 101, Fold 3/5] RMSE: 0.1334\u001b[0m\n",
      "\u001b[32m2025-09-20 01:32:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 101, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:33:15\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 101, Fold 4/5] RMSE: 0.1492\u001b[0m\n",
      "\u001b[32m2025-09-20 01:33:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 101, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:33:34\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 101, Fold 5/5] RMSE: 0.1301\u001b[0m\n",
      "[I 2025-09-20 01:33:34,557] Trial 101 finished with value: 0.13964962342264983 and parameters: {'n_estimators': 1000, 'learning_rate': 0.06028152711307212, 'max_depth': 8, 'subsample': 0.9574287570691302, 'colsample_bytree': 0.7846381363617485}. Best is trial 101 with value: 0.13964962342264983.\n",
      "\u001b[32m2025-09-20 01:33:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 102] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 01:33:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 102, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:33:53\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 102, Fold 1/5] RMSE: 0.1494\u001b[0m\n",
      "\u001b[32m2025-09-20 01:33:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 102, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:34:11\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 102, Fold 2/5] RMSE: 0.1373\u001b[0m\n",
      "\u001b[32m2025-09-20 01:34:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 102, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:34:30\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 102, Fold 3/5] RMSE: 0.1363\u001b[0m\n",
      "\u001b[32m2025-09-20 01:34:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 102, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:34:50\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 102, Fold 4/5] RMSE: 0.1504\u001b[0m\n",
      "\u001b[32m2025-09-20 01:34:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 102, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:35:09\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 102, Fold 5/5] RMSE: 0.1300\u001b[0m\n",
      "[I 2025-09-20 01:35:09,616] Trial 102 finished with value: 0.14067965387902093 and parameters: {'n_estimators': 1000, 'learning_rate': 0.07335596780703554, 'max_depth': 8, 'subsample': 0.9497260644226049, 'colsample_bytree': 0.7638001835012882}. Best is trial 101 with value: 0.13964962342264983.\n",
      "\u001b[32m2025-09-20 01:35:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 103] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 01:35:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 103, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:35:28\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 103, Fold 1/5] RMSE: 0.1477\u001b[0m\n",
      "\u001b[32m2025-09-20 01:35:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 103, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:35:47\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 103, Fold 2/5] RMSE: 0.1375\u001b[0m\n",
      "\u001b[32m2025-09-20 01:35:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 103, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:36:05\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 103, Fold 3/5] RMSE: 0.1347\u001b[0m\n",
      "\u001b[32m2025-09-20 01:36:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 103, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:36:24\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 103, Fold 4/5] RMSE: 0.1527\u001b[0m\n",
      "\u001b[32m2025-09-20 01:36:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 103, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:36:42\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 103, Fold 5/5] RMSE: 0.1299\u001b[0m\n",
      "[I 2025-09-20 01:36:42,715] Trial 103 finished with value: 0.14051358659477725 and parameters: {'n_estimators': 1000, 'learning_rate': 0.06157317242897156, 'max_depth': 8, 'subsample': 0.9791229746129957, 'colsample_bytree': 0.7886418270915053}. Best is trial 101 with value: 0.13964962342264983.\n",
      "\u001b[32m2025-09-20 01:36:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 104] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 01:36:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 104, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:37:02\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 104, Fold 1/5] RMSE: 0.1479\u001b[0m\n",
      "\u001b[32m2025-09-20 01:37:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 104, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:37:21\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 104, Fold 2/5] RMSE: 0.1394\u001b[0m\n",
      "\u001b[32m2025-09-20 01:37:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 104, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:37:40\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 104, Fold 3/5] RMSE: 0.1354\u001b[0m\n",
      "\u001b[32m2025-09-20 01:37:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 104, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:38:00\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 104, Fold 4/5] RMSE: 0.1511\u001b[0m\n",
      "\u001b[32m2025-09-20 01:38:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 104, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:38:20\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 104, Fold 5/5] RMSE: 0.1312\u001b[0m\n",
      "[I 2025-09-20 01:38:20,604] Trial 104 finished with value: 0.1410122146628731 and parameters: {'n_estimators': 1000, 'learning_rate': 0.08039288837184652, 'max_depth': 8, 'subsample': 0.9362894494341172, 'colsample_bytree': 0.7709025104654618}. Best is trial 101 with value: 0.13964962342264983.\n",
      "\u001b[32m2025-09-20 01:38:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 105] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 01:38:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 105, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:38:39\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 105, Fold 1/5] RMSE: 0.1488\u001b[0m\n",
      "\u001b[32m2025-09-20 01:38:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 105, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:38:58\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 105, Fold 2/5] RMSE: 0.1393\u001b[0m\n",
      "\u001b[32m2025-09-20 01:38:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 105, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:39:17\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 105, Fold 3/5] RMSE: 0.1338\u001b[0m\n",
      "\u001b[32m2025-09-20 01:39:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 105, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:39:38\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 105, Fold 4/5] RMSE: 0.1499\u001b[0m\n",
      "\u001b[32m2025-09-20 01:39:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 105, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:40:00\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 105, Fold 5/5] RMSE: 0.1296\u001b[0m\n",
      "[I 2025-09-20 01:40:00,410] Trial 105 finished with value: 0.14028500820935944 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05409792173799599, 'max_depth': 8, 'subsample': 0.9532220101476365, 'colsample_bytree': 0.7262392167302706}. Best is trial 101 with value: 0.13964962342264983.\n",
      "\u001b[32m2025-09-20 01:40:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 106] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 01:40:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 106, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:40:22\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 106, Fold 1/5] RMSE: 0.1501\u001b[0m\n",
      "\u001b[32m2025-09-20 01:40:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 106, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:40:42\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 106, Fold 2/5] RMSE: 0.1390\u001b[0m\n",
      "\u001b[32m2025-09-20 01:40:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 106, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:41:01\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 106, Fold 3/5] RMSE: 0.1338\u001b[0m\n",
      "\u001b[32m2025-09-20 01:41:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 106, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:41:20\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 106, Fold 4/5] RMSE: 0.1532\u001b[0m\n",
      "\u001b[32m2025-09-20 01:41:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 106, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:41:39\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 106, Fold 5/5] RMSE: 0.1303\u001b[0m\n",
      "[I 2025-09-20 01:41:39,416] Trial 106 finished with value: 0.1412763753116356 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05125391476603234, 'max_depth': 8, 'subsample': 0.9420062394382395, 'colsample_bytree': 0.8025672838119711}. Best is trial 101 with value: 0.13964962342264983.\n",
      "\u001b[32m2025-09-20 01:41:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 107] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 01:41:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 107, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:41:56\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 107, Fold 1/5] RMSE: 0.1471\u001b[0m\n",
      "\u001b[32m2025-09-20 01:41:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 107, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:42:13\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 107, Fold 2/5] RMSE: 0.1382\u001b[0m\n",
      "\u001b[32m2025-09-20 01:42:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 107, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:42:30\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 107, Fold 3/5] RMSE: 0.1342\u001b[0m\n",
      "\u001b[32m2025-09-20 01:42:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 107, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:42:47\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 107, Fold 4/5] RMSE: 0.1533\u001b[0m\n",
      "\u001b[32m2025-09-20 01:42:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 107, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:43:04\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 107, Fold 5/5] RMSE: 0.1312\u001b[0m\n",
      "[I 2025-09-20 01:43:04,043] Trial 107 finished with value: 0.14081620925873942 and parameters: {'n_estimators': 900, 'learning_rate': 0.06809789335460957, 'max_depth': 8, 'subsample': 0.9688023574614392, 'colsample_bytree': 0.7484427103220199}. Best is trial 101 with value: 0.13964962342264983.\n",
      "\u001b[32m2025-09-20 01:43:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 108] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 01:43:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 108, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:43:27\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 108, Fold 1/5] RMSE: 0.1491\u001b[0m\n",
      "\u001b[32m2025-09-20 01:43:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 108, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:43:52\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 108, Fold 2/5] RMSE: 0.1379\u001b[0m\n",
      "\u001b[32m2025-09-20 01:43:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 108, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:44:11\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 108, Fold 3/5] RMSE: 0.1355\u001b[0m\n",
      "\u001b[32m2025-09-20 01:44:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 108, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:44:30\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 108, Fold 4/5] RMSE: 0.1508\u001b[0m\n",
      "\u001b[32m2025-09-20 01:44:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 108, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:44:49\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 108, Fold 5/5] RMSE: 0.1298\u001b[0m\n",
      "[I 2025-09-20 01:44:49,045] Trial 108 finished with value: 0.14062518515237912 and parameters: {'n_estimators': 1000, 'learning_rate': 0.07300268174303785, 'max_depth': 8, 'subsample': 0.96056309712057, 'colsample_bytree': 0.7340721808213206}. Best is trial 101 with value: 0.13964962342264983.\n",
      "\u001b[32m2025-09-20 01:44:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 109] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 01:44:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 109, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:45:07\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 109, Fold 1/5] RMSE: 0.1488\u001b[0m\n",
      "\u001b[32m2025-09-20 01:45:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 109, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:45:26\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 109, Fold 2/5] RMSE: 0.1368\u001b[0m\n",
      "\u001b[32m2025-09-20 01:45:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 109, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:45:44\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 109, Fold 3/5] RMSE: 0.1358\u001b[0m\n",
      "\u001b[32m2025-09-20 01:45:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 109, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:46:03\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 109, Fold 4/5] RMSE: 0.1499\u001b[0m\n",
      "\u001b[32m2025-09-20 01:46:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 109, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:46:22\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 109, Fold 5/5] RMSE: 0.1320\u001b[0m\n",
      "[I 2025-09-20 01:46:22,103] Trial 109 finished with value: 0.14066549050182883 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05529274228594685, 'max_depth': 8, 'subsample': 0.9243945945939459, 'colsample_bytree': 0.7839963841695158}. Best is trial 101 with value: 0.13964962342264983.\n",
      "\u001b[32m2025-09-20 01:46:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 110] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 01:46:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 110, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:46:38\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 110, Fold 1/5] RMSE: 0.1488\u001b[0m\n",
      "\u001b[32m2025-09-20 01:46:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 110, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:46:55\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 110, Fold 2/5] RMSE: 0.1380\u001b[0m\n",
      "\u001b[32m2025-09-20 01:46:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 110, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:47:12\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 110, Fold 3/5] RMSE: 0.1358\u001b[0m\n",
      "\u001b[32m2025-09-20 01:47:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 110, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:47:28\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 110, Fold 4/5] RMSE: 0.1516\u001b[0m\n",
      "\u001b[32m2025-09-20 01:47:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 110, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:47:45\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 110, Fold 5/5] RMSE: 0.1315\u001b[0m\n",
      "[I 2025-09-20 01:47:45,259] Trial 110 finished with value: 0.141127825010383 and parameters: {'n_estimators': 900, 'learning_rate': 0.06051542014227838, 'max_depth': 8, 'subsample': 0.9457020765339599, 'colsample_bytree': 0.7712549260064209}. Best is trial 101 with value: 0.13964962342264983.\n",
      "\u001b[32m2025-09-20 01:47:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 111] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 01:47:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 111, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:48:03\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 111, Fold 1/5] RMSE: 0.1479\u001b[0m\n",
      "\u001b[32m2025-09-20 01:48:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 111, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:48:21\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 111, Fold 2/5] RMSE: 0.1389\u001b[0m\n",
      "\u001b[32m2025-09-20 01:48:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 111, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:48:39\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 111, Fold 3/5] RMSE: 0.1343\u001b[0m\n",
      "\u001b[32m2025-09-20 01:48:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 111, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:48:57\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 111, Fold 4/5] RMSE: 0.1524\u001b[0m\n",
      "\u001b[32m2025-09-20 01:48:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 111, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:49:15\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 111, Fold 5/5] RMSE: 0.1308\u001b[0m\n",
      "[I 2025-09-20 01:49:15,638] Trial 111 finished with value: 0.14086857041778406 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05820297297595402, 'max_depth': 8, 'subsample': 0.9855530560037669, 'colsample_bytree': 0.7944747135599092}. Best is trial 101 with value: 0.13964962342264983.\n",
      "\u001b[32m2025-09-20 01:49:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 112] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 01:49:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 112, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:49:35\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 112, Fold 1/5] RMSE: 0.1500\u001b[0m\n",
      "\u001b[32m2025-09-20 01:49:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 112, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:49:53\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 112, Fold 2/5] RMSE: 0.1379\u001b[0m\n",
      "\u001b[32m2025-09-20 01:49:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 112, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:50:12\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 112, Fold 3/5] RMSE: 0.1341\u001b[0m\n",
      "\u001b[32m2025-09-20 01:50:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 112, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:50:32\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 112, Fold 4/5] RMSE: 0.1501\u001b[0m\n",
      "\u001b[32m2025-09-20 01:50:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 112, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:50:50\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 112, Fold 5/5] RMSE: 0.1294\u001b[0m\n",
      "[I 2025-09-20 01:50:50,815] Trial 112 finished with value: 0.1402970385789752 and parameters: {'n_estimators': 1000, 'learning_rate': 0.06462059952958825, 'max_depth': 8, 'subsample': 0.9597261116339912, 'colsample_bytree': 0.78274545249314}. Best is trial 101 with value: 0.13964962342264983.\n",
      "\u001b[32m2025-09-20 01:50:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 113] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 01:50:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 113, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:51:09\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 113, Fold 1/5] RMSE: 0.1493\u001b[0m\n",
      "\u001b[32m2025-09-20 01:51:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 113, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:51:28\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 113, Fold 2/5] RMSE: 0.1384\u001b[0m\n",
      "\u001b[32m2025-09-20 01:51:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 113, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:51:47\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 113, Fold 3/5] RMSE: 0.1355\u001b[0m\n",
      "\u001b[32m2025-09-20 01:51:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 113, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:52:06\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 113, Fold 4/5] RMSE: 0.1497\u001b[0m\n",
      "\u001b[32m2025-09-20 01:52:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 113, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:52:25\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 113, Fold 5/5] RMSE: 0.1313\u001b[0m\n",
      "[I 2025-09-20 01:52:25,077] Trial 113 finished with value: 0.14084548422975113 and parameters: {'n_estimators': 1000, 'learning_rate': 0.059238813516569795, 'max_depth': 8, 'subsample': 0.9536061340133609, 'colsample_bytree': 0.7648446716724048}. Best is trial 101 with value: 0.13964962342264983.\n",
      "\u001b[32m2025-09-20 01:52:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 114] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 01:52:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 114, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:52:44\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 114, Fold 1/5] RMSE: 0.1529\u001b[0m\n",
      "\u001b[32m2025-09-20 01:52:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 114, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:53:03\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 114, Fold 2/5] RMSE: 0.1405\u001b[0m\n",
      "\u001b[32m2025-09-20 01:53:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 114, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:53:23\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 114, Fold 3/5] RMSE: 0.1354\u001b[0m\n",
      "\u001b[32m2025-09-20 01:53:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 114, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:53:42\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 114, Fold 4/5] RMSE: 0.1531\u001b[0m\n",
      "\u001b[32m2025-09-20 01:53:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 114, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:54:02\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 114, Fold 5/5] RMSE: 0.1346\u001b[0m\n",
      "[I 2025-09-20 01:54:02,185] Trial 114 finished with value: 0.14328188511637857 and parameters: {'n_estimators': 1000, 'learning_rate': 0.07697969921779572, 'max_depth': 8, 'subsample': 0.7067334961342052, 'colsample_bytree': 0.7990936203964577}. Best is trial 101 with value: 0.13964962342264983.\n",
      "\u001b[32m2025-09-20 01:54:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 115] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 01:54:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 115, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:54:20\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 115, Fold 1/5] RMSE: 0.1487\u001b[0m\n",
      "\u001b[32m2025-09-20 01:54:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 115, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:54:37\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 115, Fold 2/5] RMSE: 0.1377\u001b[0m\n",
      "\u001b[32m2025-09-20 01:54:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 115, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:54:55\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 115, Fold 3/5] RMSE: 0.1351\u001b[0m\n",
      "\u001b[32m2025-09-20 01:54:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 115, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:55:13\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 115, Fold 4/5] RMSE: 0.1515\u001b[0m\n",
      "\u001b[32m2025-09-20 01:55:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 115, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:55:31\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 115, Fold 5/5] RMSE: 0.1310\u001b[0m\n",
      "[I 2025-09-20 01:55:31,358] Trial 115 finished with value: 0.14078858395111873 and parameters: {'n_estimators': 1000, 'learning_rate': 0.06648519263902836, 'max_depth': 8, 'subsample': 0.9776196509562511, 'colsample_bytree': 0.755724488458793}. Best is trial 101 with value: 0.13964962342264983.\n",
      "\u001b[32m2025-09-20 01:55:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 116] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 01:55:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 116, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:55:41\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 116, Fold 1/5] RMSE: 0.1526\u001b[0m\n",
      "\u001b[32m2025-09-20 01:55:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 116, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:55:51\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 116, Fold 2/5] RMSE: 0.1430\u001b[0m\n",
      "\u001b[32m2025-09-20 01:55:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 116, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:56:01\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 116, Fold 3/5] RMSE: 0.1390\u001b[0m\n",
      "\u001b[32m2025-09-20 01:56:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 116, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:56:10\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 116, Fold 4/5] RMSE: 0.1548\u001b[0m\n",
      "\u001b[32m2025-09-20 01:56:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 116, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:56:20\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 116, Fold 5/5] RMSE: 0.1349\u001b[0m\n",
      "[I 2025-09-20 01:56:20,939] Trial 116 finished with value: 0.1448496699779484 and parameters: {'n_estimators': 500, 'learning_rate': 0.06959979281549915, 'max_depth': 8, 'subsample': 0.9593708353321398, 'colsample_bytree': 0.7788882515172111}. Best is trial 101 with value: 0.13964962342264983.\n",
      "\u001b[32m2025-09-20 01:56:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 117] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 01:56:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 117, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:56:38\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 117, Fold 1/5] RMSE: 0.1487\u001b[0m\n",
      "\u001b[32m2025-09-20 01:56:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 117, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:56:55\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 117, Fold 2/5] RMSE: 0.1382\u001b[0m\n",
      "\u001b[32m2025-09-20 01:56:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 117, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:57:11\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 117, Fold 3/5] RMSE: 0.1360\u001b[0m\n",
      "\u001b[32m2025-09-20 01:57:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 117, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:57:28\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 117, Fold 4/5] RMSE: 0.1494\u001b[0m\n",
      "\u001b[32m2025-09-20 01:57:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 117, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:57:46\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 117, Fold 5/5] RMSE: 0.1326\u001b[0m\n",
      "[I 2025-09-20 01:57:46,043] Trial 117 finished with value: 0.14097945046133337 and parameters: {'n_estimators': 900, 'learning_rate': 0.0629940778204462, 'max_depth': 8, 'subsample': 0.9350004779010542, 'colsample_bytree': 0.7423488162455408}. Best is trial 101 with value: 0.13964962342264983.\n",
      "\u001b[32m2025-09-20 01:57:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 118] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 01:57:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 118, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:57:53\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 118, Fold 1/5] RMSE: 0.1686\u001b[0m\n",
      "\u001b[32m2025-09-20 01:57:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 118, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:58:01\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 118, Fold 2/5] RMSE: 0.1577\u001b[0m\n",
      "\u001b[32m2025-09-20 01:58:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 118, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:58:09\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 118, Fold 3/5] RMSE: 0.1535\u001b[0m\n",
      "\u001b[32m2025-09-20 01:58:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 118, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:58:17\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 118, Fold 4/5] RMSE: 0.1742\u001b[0m\n",
      "\u001b[32m2025-09-20 01:58:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 118, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:58:24\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 118, Fold 5/5] RMSE: 0.1517\u001b[0m\n",
      "[I 2025-09-20 01:58:24,789] Trial 118 finished with value: 0.16113477924517533 and parameters: {'n_estimators': 1000, 'learning_rate': 0.08396257135549298, 'max_depth': 5, 'subsample': 0.9664885404050512, 'colsample_bytree': 0.7900280198251204}. Best is trial 101 with value: 0.13964962342264983.\n",
      "\u001b[32m2025-09-20 01:58:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 119] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 01:58:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 119, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:58:43\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 119, Fold 1/5] RMSE: 0.1507\u001b[0m\n",
      "\u001b[32m2025-09-20 01:58:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 119, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:59:01\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 119, Fold 2/5] RMSE: 0.1417\u001b[0m\n",
      "\u001b[32m2025-09-20 01:59:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 119, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:59:18\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 119, Fold 3/5] RMSE: 0.1368\u001b[0m\n",
      "\u001b[32m2025-09-20 01:59:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 119, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:59:36\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 119, Fold 4/5] RMSE: 0.1536\u001b[0m\n",
      "\u001b[32m2025-09-20 01:59:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 119, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:59:53\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 119, Fold 5/5] RMSE: 0.1343\u001b[0m\n",
      "[I 2025-09-20 01:59:53,902] Trial 119 finished with value: 0.14342804932302639 and parameters: {'n_estimators': 900, 'learning_rate': 0.0460070156832531, 'max_depth': 8, 'subsample': 0.833918572182456, 'colsample_bytree': 0.773764752431772}. Best is trial 101 with value: 0.13964962342264983.\n",
      "\u001b[32m2025-09-20 01:59:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 120] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 01:59:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 120, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:00:08\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 120, Fold 1/5] RMSE: 0.1535\u001b[0m\n",
      "\u001b[32m2025-09-20 02:00:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 120, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:00:21\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 120, Fold 2/5] RMSE: 0.1449\u001b[0m\n",
      "\u001b[32m2025-09-20 02:00:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 120, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:00:34\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 120, Fold 3/5] RMSE: 0.1404\u001b[0m\n",
      "\u001b[32m2025-09-20 02:00:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 120, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:00:48\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 120, Fold 4/5] RMSE: 0.1594\u001b[0m\n",
      "\u001b[32m2025-09-20 02:00:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 120, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:01:04\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 120, Fold 5/5] RMSE: 0.1376\u001b[0m\n",
      "[I 2025-09-20 02:01:04,212] Trial 120 finished with value: 0.14716264585429517 and parameters: {'n_estimators': 1000, 'learning_rate': 0.04331631349996, 'max_depth': 7, 'subsample': 0.9442599118226209, 'colsample_bytree': 0.8094775960633647}. Best is trial 101 with value: 0.13964962342264983.\n",
      "\u001b[32m2025-09-20 02:01:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 121] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 02:01:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 121, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:01:25\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 121, Fold 1/5] RMSE: 0.1503\u001b[0m\n",
      "\u001b[32m2025-09-20 02:01:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 121, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:01:43\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 121, Fold 2/5] RMSE: 0.1384\u001b[0m\n",
      "\u001b[32m2025-09-20 02:01:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 121, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:02:01\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 121, Fold 3/5] RMSE: 0.1345\u001b[0m\n",
      "\u001b[32m2025-09-20 02:02:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 121, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:02:19\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 121, Fold 4/5] RMSE: 0.1502\u001b[0m\n",
      "\u001b[32m2025-09-20 02:02:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 121, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:02:38\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 121, Fold 5/5] RMSE: 0.1302\u001b[0m\n",
      "[I 2025-09-20 02:02:38,351] Trial 121 finished with value: 0.14073307097046778 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05406133585038952, 'max_depth': 8, 'subsample': 0.9528921680653458, 'colsample_bytree': 0.7241130185144092}. Best is trial 101 with value: 0.13964962342264983.\n",
      "\u001b[32m2025-09-20 02:02:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 122] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 02:02:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 122, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:02:56\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 122, Fold 1/5] RMSE: 0.1496\u001b[0m\n",
      "\u001b[32m2025-09-20 02:02:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 122, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:03:14\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 122, Fold 2/5] RMSE: 0.1392\u001b[0m\n",
      "\u001b[32m2025-09-20 02:03:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 122, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:03:32\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 122, Fold 3/5] RMSE: 0.1346\u001b[0m\n",
      "\u001b[32m2025-09-20 02:03:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 122, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:03:50\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 122, Fold 4/5] RMSE: 0.1508\u001b[0m\n",
      "\u001b[32m2025-09-20 02:03:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 122, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:04:08\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 122, Fold 5/5] RMSE: 0.1326\u001b[0m\n",
      "[I 2025-09-20 02:04:08,544] Trial 122 finished with value: 0.14137066795087955 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05113179642701557, 'max_depth': 8, 'subsample': 0.9554019582674897, 'colsample_bytree': 0.7101881543542928}. Best is trial 101 with value: 0.13964962342264983.\n",
      "\u001b[32m2025-09-20 02:04:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 123] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 02:04:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 123, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:04:26\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 123, Fold 1/5] RMSE: 0.1495\u001b[0m\n",
      "\u001b[32m2025-09-20 02:04:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 123, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:04:44\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 123, Fold 2/5] RMSE: 0.1371\u001b[0m\n",
      "\u001b[32m2025-09-20 02:04:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 123, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:05:03\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 123, Fold 3/5] RMSE: 0.1352\u001b[0m\n",
      "\u001b[32m2025-09-20 02:05:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 123, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:05:21\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 123, Fold 4/5] RMSE: 0.1504\u001b[0m\n",
      "\u001b[32m2025-09-20 02:05:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 123, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:05:40\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 123, Fold 5/5] RMSE: 0.1296\u001b[0m\n",
      "[I 2025-09-20 02:05:40,399] Trial 123 finished with value: 0.14035635753544537 and parameters: {'n_estimators': 1000, 'learning_rate': 0.06001624942535809, 'max_depth': 8, 'subsample': 0.9498106062377875, 'colsample_bytree': 0.7305821575403272}. Best is trial 101 with value: 0.13964962342264983.\n",
      "\u001b[32m2025-09-20 02:05:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 124] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 02:05:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 124, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:05:59\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 124, Fold 1/5] RMSE: 0.1485\u001b[0m\n",
      "\u001b[32m2025-09-20 02:05:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 124, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:06:17\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 124, Fold 2/5] RMSE: 0.1362\u001b[0m\n",
      "\u001b[32m2025-09-20 02:06:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 124, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:06:36\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 124, Fold 3/5] RMSE: 0.1344\u001b[0m\n",
      "\u001b[32m2025-09-20 02:06:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 124, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:06:54\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 124, Fold 4/5] RMSE: 0.1500\u001b[0m\n",
      "\u001b[32m2025-09-20 02:06:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 124, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:07:12\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 124, Fold 5/5] RMSE: 0.1288\u001b[0m\n",
      "[I 2025-09-20 02:07:12,455] Trial 124 finished with value: 0.13959429910714827 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05486744427762486, 'max_depth': 8, 'subsample': 0.9628350986580778, 'colsample_bytree': 0.7646066116589173}. Best is trial 124 with value: 0.13959429910714827.\n",
      "\u001b[32m2025-09-20 02:07:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 125] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 02:07:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 125, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:07:30\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 125, Fold 1/5] RMSE: 0.1486\u001b[0m\n",
      "\u001b[32m2025-09-20 02:07:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 125, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:07:49\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 125, Fold 2/5] RMSE: 0.1399\u001b[0m\n",
      "\u001b[32m2025-09-20 02:07:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 125, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:08:08\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 125, Fold 3/5] RMSE: 0.1351\u001b[0m\n",
      "\u001b[32m2025-09-20 02:08:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 125, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:08:27\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 125, Fold 4/5] RMSE: 0.1555\u001b[0m\n",
      "\u001b[32m2025-09-20 02:08:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 125, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:08:46\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 125, Fold 5/5] RMSE: 0.1304\u001b[0m\n",
      "[I 2025-09-20 02:08:46,600] Trial 125 finished with value: 0.14189866976499604 and parameters: {'n_estimators': 1000, 'learning_rate': 0.07107508351654357, 'max_depth': 8, 'subsample': 0.9702667993765046, 'colsample_bytree': 0.9131474244352438}. Best is trial 124 with value: 0.13959429910714827.\n",
      "\u001b[32m2025-09-20 02:08:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 126] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 02:08:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 126, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:09:03\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 126, Fold 1/5] RMSE: 0.1488\u001b[0m\n",
      "\u001b[32m2025-09-20 02:09:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 126, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:09:20\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 126, Fold 2/5] RMSE: 0.1391\u001b[0m\n",
      "\u001b[32m2025-09-20 02:09:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 126, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:09:37\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 126, Fold 3/5] RMSE: 0.1342\u001b[0m\n",
      "\u001b[32m2025-09-20 02:09:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 126, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:09:54\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 126, Fold 4/5] RMSE: 0.1518\u001b[0m\n",
      "\u001b[32m2025-09-20 02:09:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 126, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:10:15\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 126, Fold 5/5] RMSE: 0.1304\u001b[0m\n",
      "[I 2025-09-20 02:10:15,277] Trial 126 finished with value: 0.14085456451126946 and parameters: {'n_estimators': 900, 'learning_rate': 0.056621108049877404, 'max_depth': 8, 'subsample': 0.9289469533633387, 'colsample_bytree': 0.7819694654781153}. Best is trial 124 with value: 0.13959429910714827.\n",
      "\u001b[32m2025-09-20 02:10:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 127] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 02:10:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 127, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:10:37\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 127, Fold 1/5] RMSE: 0.1504\u001b[0m\n",
      "\u001b[32m2025-09-20 02:10:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 127, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:10:58\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 127, Fold 2/5] RMSE: 0.1393\u001b[0m\n",
      "\u001b[32m2025-09-20 02:10:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 127, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:11:16\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 127, Fold 3/5] RMSE: 0.1340\u001b[0m\n",
      "\u001b[32m2025-09-20 02:11:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 127, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:11:34\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 127, Fold 4/5] RMSE: 0.1524\u001b[0m\n",
      "\u001b[32m2025-09-20 02:11:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 127, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:11:52\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 127, Fold 5/5] RMSE: 0.1305\u001b[0m\n",
      "[I 2025-09-20 02:11:52,172] Trial 127 finished with value: 0.1413421135866603 and parameters: {'n_estimators': 1000, 'learning_rate': 0.04867100157407737, 'max_depth': 8, 'subsample': 0.9633103349371546, 'colsample_bytree': 0.7628549620138189}. Best is trial 124 with value: 0.13959429910714827.\n",
      "\u001b[32m2025-09-20 02:11:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 128] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 02:11:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 128, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:12:10\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 128, Fold 1/5] RMSE: 0.1470\u001b[0m\n",
      "\u001b[32m2025-09-20 02:12:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 128, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:12:27\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 128, Fold 2/5] RMSE: 0.1382\u001b[0m\n",
      "\u001b[32m2025-09-20 02:12:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 128, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:12:45\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 128, Fold 3/5] RMSE: 0.1337\u001b[0m\n",
      "\u001b[32m2025-09-20 02:12:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 128, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:13:03\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 128, Fold 4/5] RMSE: 0.1501\u001b[0m\n",
      "\u001b[32m2025-09-20 02:13:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 128, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:13:20\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 128, Fold 5/5] RMSE: 0.1306\u001b[0m\n",
      "[I 2025-09-20 02:13:20,708] Trial 128 finished with value: 0.1399177400942127 and parameters: {'n_estimators': 1000, 'learning_rate': 0.06566314892101946, 'max_depth': 8, 'subsample': 0.9929991815983702, 'colsample_bytree': 0.74853842340255}. Best is trial 124 with value: 0.13959429910714827.\n",
      "\u001b[32m2025-09-20 02:13:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 129] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 02:13:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 129, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:13:39\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 129, Fold 1/5] RMSE: 0.1466\u001b[0m\n",
      "\u001b[32m2025-09-20 02:13:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 129, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:13:57\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 129, Fold 2/5] RMSE: 0.1390\u001b[0m\n",
      "\u001b[32m2025-09-20 02:13:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 129, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:14:15\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 129, Fold 3/5] RMSE: 0.1354\u001b[0m\n",
      "\u001b[32m2025-09-20 02:14:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 129, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:14:33\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 129, Fold 4/5] RMSE: 0.1545\u001b[0m\n",
      "\u001b[32m2025-09-20 02:14:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 129, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:14:52\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 129, Fold 5/5] RMSE: 0.1314\u001b[0m\n",
      "[I 2025-09-20 02:14:52,558] Trial 129 finished with value: 0.14138627618105043 and parameters: {'n_estimators': 1000, 'learning_rate': 0.0781907576490845, 'max_depth': 8, 'subsample': 0.984393197967344, 'colsample_bytree': 0.8729670097918545}. Best is trial 124 with value: 0.13959429910714827.\n",
      "\u001b[32m2025-09-20 02:14:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 130] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 02:14:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 130, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:15:00\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 130, Fold 1/5] RMSE: 0.1562\u001b[0m\n",
      "\u001b[32m2025-09-20 02:15:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 130, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:15:08\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 130, Fold 2/5] RMSE: 0.1481\u001b[0m\n",
      "\u001b[32m2025-09-20 02:15:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 130, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:15:16\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 130, Fold 3/5] RMSE: 0.1427\u001b[0m\n",
      "\u001b[32m2025-09-20 02:15:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 130, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:15:24\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 130, Fold 4/5] RMSE: 0.1613\u001b[0m\n",
      "\u001b[32m2025-09-20 02:15:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 130, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:15:32\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 130, Fold 5/5] RMSE: 0.1411\u001b[0m\n",
      "[I 2025-09-20 02:15:32,134] Trial 130 finished with value: 0.14990687765999755 and parameters: {'n_estimators': 400, 'learning_rate': 0.0651438704764276, 'max_depth': 8, 'subsample': 0.9777710416491754, 'colsample_bytree': 0.749965143745463}. Best is trial 124 with value: 0.13959429910714827.\n",
      "\u001b[32m2025-09-20 02:15:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 131] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 02:15:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 131, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:15:50\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 131, Fold 1/5] RMSE: 0.1484\u001b[0m\n",
      "\u001b[32m2025-09-20 02:15:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 131, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:16:08\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 131, Fold 2/5] RMSE: 0.1366\u001b[0m\n",
      "\u001b[32m2025-09-20 02:16:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 131, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:16:26\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 131, Fold 3/5] RMSE: 0.1344\u001b[0m\n",
      "\u001b[32m2025-09-20 02:16:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 131, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:16:44\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 131, Fold 4/5] RMSE: 0.1521\u001b[0m\n",
      "\u001b[32m2025-09-20 02:16:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 131, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:17:02\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 131, Fold 5/5] RMSE: 0.1319\u001b[0m\n",
      "[I 2025-09-20 02:17:02,329] Trial 131 finished with value: 0.14068563799857103 and parameters: {'n_estimators': 1000, 'learning_rate': 0.06195418982475726, 'max_depth': 8, 'subsample': 0.9956007636604285, 'colsample_bytree': 0.7678792606598535}. Best is trial 124 with value: 0.13959429910714827.\n",
      "\u001b[32m2025-09-20 02:17:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 132] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 02:17:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 132, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:17:20\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 132, Fold 1/5] RMSE: 0.1489\u001b[0m\n",
      "\u001b[32m2025-09-20 02:17:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 132, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:17:39\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 132, Fold 2/5] RMSE: 0.1379\u001b[0m\n",
      "\u001b[32m2025-09-20 02:17:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 132, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:17:57\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 132, Fold 3/5] RMSE: 0.1340\u001b[0m\n",
      "\u001b[32m2025-09-20 02:17:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 132, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:18:15\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 132, Fold 4/5] RMSE: 0.1507\u001b[0m\n",
      "\u001b[32m2025-09-20 02:18:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 132, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:18:34\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 132, Fold 5/5] RMSE: 0.1311\u001b[0m\n",
      "[I 2025-09-20 02:18:34,260] Trial 132 finished with value: 0.1405105594554798 and parameters: {'n_estimators': 1000, 'learning_rate': 0.07424601514367046, 'max_depth': 8, 'subsample': 0.9400142005192559, 'colsample_bytree': 0.7566162519123245}. Best is trial 124 with value: 0.13959429910714827.\n",
      "\u001b[32m2025-09-20 02:18:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 133] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 02:18:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 133, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:18:54\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 133, Fold 1/5] RMSE: 0.1500\u001b[0m\n",
      "\u001b[32m2025-09-20 02:18:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 133, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:19:12\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 133, Fold 2/5] RMSE: 0.1363\u001b[0m\n",
      "\u001b[32m2025-09-20 02:19:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 133, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:19:30\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 133, Fold 3/5] RMSE: 0.1327\u001b[0m\n",
      "\u001b[32m2025-09-20 02:19:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 133, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:19:50\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 133, Fold 4/5] RMSE: 0.1514\u001b[0m\n",
      "\u001b[32m2025-09-20 02:19:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 133, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:20:10\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 133, Fold 5/5] RMSE: 0.1315\u001b[0m\n",
      "[I 2025-09-20 02:20:10,933] Trial 133 finished with value: 0.14036240127078742 and parameters: {'n_estimators': 1000, 'learning_rate': 0.0673356151476832, 'max_depth': 8, 'subsample': 0.9103319387773178, 'colsample_bytree': 0.7419905562245881}. Best is trial 124 with value: 0.13959429910714827.\n",
      "\u001b[32m2025-09-20 02:20:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 134] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 02:20:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 134, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:20:21\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 134, Fold 1/5] RMSE: 0.1571\u001b[0m\n",
      "\u001b[32m2025-09-20 02:20:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 134, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:20:30\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 134, Fold 2/5] RMSE: 0.1472\u001b[0m\n",
      "\u001b[32m2025-09-20 02:20:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 134, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:20:40\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 134, Fold 3/5] RMSE: 0.1446\u001b[0m\n",
      "\u001b[32m2025-09-20 02:20:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 134, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 02:20:49\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 134, Fold 4/5] RMSE: 0.1595\u001b[0m\n",
      "\u001b[32m2025-09-20 02:20:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 134, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 08:57:32\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 134, Fold 5/5] RMSE: 0.1408\u001b[0m\n",
      "[I 2025-09-20 08:57:32,255] Trial 134 finished with value: 0.1498212785105525 and parameters: {'n_estimators': 1000, 'learning_rate': 0.07107612141327921, 'max_depth': 6, 'subsample': 0.9715461425778944, 'colsample_bytree': 0.7745021512427375}. Best is trial 124 with value: 0.13959429910714827.\n",
      "\u001b[32m2025-09-20 08:57:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 135] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 08:57:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 135, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 08:57:51\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 135, Fold 1/5] RMSE: 0.1473\u001b[0m\n",
      "\u001b[32m2025-09-20 08:57:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 135, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 08:58:08\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 135, Fold 2/5] RMSE: 0.1369\u001b[0m\n",
      "\u001b[32m2025-09-20 08:58:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 135, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 08:58:27\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 135, Fold 3/5] RMSE: 0.1345\u001b[0m\n",
      "\u001b[32m2025-09-20 08:58:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 135, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 08:58:46\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 135, Fold 4/5] RMSE: 0.1488\u001b[0m\n",
      "\u001b[32m2025-09-20 08:58:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 135, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 08:59:05\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 135, Fold 5/5] RMSE: 0.1303\u001b[0m\n",
      "[I 2025-09-20 08:59:05,401] Trial 135 finished with value: 0.13955016459661373 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05927154133758313, 'max_depth': 8, 'subsample': 0.9619321172925456, 'colsample_bytree': 0.7800779709812554}. Best is trial 135 with value: 0.13955016459661373.\n",
      "\u001b[32m2025-09-20 08:59:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 136] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 08:59:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 136, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 08:59:21\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 136, Fold 1/5] RMSE: 0.1597\u001b[0m\n",
      "\u001b[32m2025-09-20 08:59:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 136, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 08:59:36\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 136, Fold 2/5] RMSE: 0.1536\u001b[0m\n",
      "\u001b[32m2025-09-20 08:59:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 136, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 08:59:52\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 136, Fold 3/5] RMSE: 0.1481\u001b[0m\n",
      "\u001b[32m2025-09-20 08:59:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 136, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:00:08\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 136, Fold 4/5] RMSE: 0.1651\u001b[0m\n",
      "\u001b[32m2025-09-20 09:00:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 136, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:00:24\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 136, Fold 5/5] RMSE: 0.1448\u001b[0m\n",
      "[I 2025-09-20 09:00:24,558] Trial 136 finished with value: 0.15424248026056953 and parameters: {'n_estimators': 900, 'learning_rate': 0.02211180350075981, 'max_depth': 8, 'subsample': 0.9933006325877142, 'colsample_bytree': 0.7610455477909709}. Best is trial 135 with value: 0.13955016459661373.\n",
      "\u001b[32m2025-09-20 09:00:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 137] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 09:00:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 137, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:00:42\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 137, Fold 1/5] RMSE: 0.1476\u001b[0m\n",
      "\u001b[32m2025-09-20 09:00:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 137, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:01:00\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 137, Fold 2/5] RMSE: 0.1376\u001b[0m\n",
      "\u001b[32m2025-09-20 09:01:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 137, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:01:18\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 137, Fold 3/5] RMSE: 0.1333\u001b[0m\n",
      "\u001b[32m2025-09-20 09:01:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 137, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:01:36\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 137, Fold 4/5] RMSE: 0.1490\u001b[0m\n",
      "\u001b[32m2025-09-20 09:01:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 137, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:01:54\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 137, Fold 5/5] RMSE: 0.1297\u001b[0m\n",
      "[I 2025-09-20 09:01:54,359] Trial 137 finished with value: 0.13944099438321522 and parameters: {'n_estimators': 1000, 'learning_rate': 0.06295755102767644, 'max_depth': 8, 'subsample': 0.9646079204749475, 'colsample_bytree': 0.7928964216707967}. Best is trial 137 with value: 0.13944099438321522.\n",
      "\u001b[32m2025-09-20 09:01:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 138] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 09:01:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 138, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:02:12\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 138, Fold 1/5] RMSE: 0.1492\u001b[0m\n",
      "\u001b[32m2025-09-20 09:02:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 138, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:02:30\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 138, Fold 2/5] RMSE: 0.1384\u001b[0m\n",
      "\u001b[32m2025-09-20 09:02:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 138, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:02:48\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 138, Fold 3/5] RMSE: 0.1329\u001b[0m\n",
      "\u001b[32m2025-09-20 09:02:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 138, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:03:06\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 138, Fold 4/5] RMSE: 0.1511\u001b[0m\n",
      "\u001b[32m2025-09-20 09:03:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 138, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:03:24\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 138, Fold 5/5] RMSE: 0.1313\u001b[0m\n",
      "[I 2025-09-20 09:03:24,437] Trial 138 finished with value: 0.14057743604018685 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05519896324757894, 'max_depth': 8, 'subsample': 0.9651860916671552, 'colsample_bytree': 0.7929511633038032}. Best is trial 137 with value: 0.13944099438321522.\n",
      "\u001b[32m2025-09-20 09:03:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 139] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 09:03:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 139, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:03:40\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 139, Fold 1/5] RMSE: 0.1478\u001b[0m\n",
      "\u001b[32m2025-09-20 09:03:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 139, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:03:56\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 139, Fold 2/5] RMSE: 0.1389\u001b[0m\n",
      "\u001b[32m2025-09-20 09:03:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 139, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:04:12\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 139, Fold 3/5] RMSE: 0.1337\u001b[0m\n",
      "\u001b[32m2025-09-20 09:04:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 139, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:04:27\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 139, Fold 4/5] RMSE: 0.1518\u001b[0m\n",
      "\u001b[32m2025-09-20 09:04:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 139, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:04:43\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 139, Fold 5/5] RMSE: 0.1323\u001b[0m\n",
      "[I 2025-09-20 09:04:43,994] Trial 139 finished with value: 0.1408665652351757 and parameters: {'n_estimators': 900, 'learning_rate': 0.060643674928920636, 'max_depth': 8, 'subsample': 0.9890946766996169, 'colsample_bytree': 0.7383767592621476}. Best is trial 137 with value: 0.13944099438321522.\n",
      "\u001b[32m2025-09-20 09:04:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 140] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 09:04:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 140, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:05:00\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 140, Fold 1/5] RMSE: 0.1478\u001b[0m\n",
      "\u001b[32m2025-09-20 09:05:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 140, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:05:16\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 140, Fold 2/5] RMSE: 0.1390\u001b[0m\n",
      "\u001b[32m2025-09-20 09:05:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 140, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:05:32\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 140, Fold 3/5] RMSE: 0.1357\u001b[0m\n",
      "\u001b[32m2025-09-20 09:05:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 140, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:05:48\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 140, Fold 4/5] RMSE: 0.1522\u001b[0m\n",
      "\u001b[32m2025-09-20 09:05:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 140, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:06:04\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 140, Fold 5/5] RMSE: 0.1308\u001b[0m\n",
      "[I 2025-09-20 09:06:04,694] Trial 140 finished with value: 0.14110233068327532 and parameters: {'n_estimators': 900, 'learning_rate': 0.06756696682575784, 'max_depth': 8, 'subsample': 0.9761682638462087, 'colsample_bytree': 0.767725817488216}. Best is trial 137 with value: 0.13944099438321522.\n",
      "\u001b[32m2025-09-20 09:06:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 141] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 09:06:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 141, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:06:22\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 141, Fold 1/5] RMSE: 0.1475\u001b[0m\n",
      "\u001b[32m2025-09-20 09:06:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 141, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:06:40\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 141, Fold 2/5] RMSE: 0.1379\u001b[0m\n",
      "\u001b[32m2025-09-20 09:06:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 141, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:06:58\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 141, Fold 3/5] RMSE: 0.1339\u001b[0m\n",
      "\u001b[32m2025-09-20 09:06:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 141, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:07:16\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 141, Fold 4/5] RMSE: 0.1514\u001b[0m\n",
      "\u001b[32m2025-09-20 09:07:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 141, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:07:34\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 141, Fold 5/5] RMSE: 0.1304\u001b[0m\n",
      "[I 2025-09-20 09:07:34,752] Trial 141 finished with value: 0.1402085500499817 and parameters: {'n_estimators': 1000, 'learning_rate': 0.058866691119594305, 'max_depth': 8, 'subsample': 0.9603107554043995, 'colsample_bytree': 0.7849981671222782}. Best is trial 137 with value: 0.13944099438321522.\n",
      "\u001b[32m2025-09-20 09:07:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 142] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 09:07:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 142, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:07:53\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 142, Fold 1/5] RMSE: 0.1487\u001b[0m\n",
      "\u001b[32m2025-09-20 09:07:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 142, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:08:10\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 142, Fold 2/5] RMSE: 0.1382\u001b[0m\n",
      "\u001b[32m2025-09-20 09:08:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 142, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:08:28\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 142, Fold 3/5] RMSE: 0.1366\u001b[0m\n",
      "\u001b[32m2025-09-20 09:08:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 142, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:08:46\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 142, Fold 4/5] RMSE: 0.1499\u001b[0m\n",
      "\u001b[32m2025-09-20 09:08:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 142, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:09:05\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 142, Fold 5/5] RMSE: 0.1305\u001b[0m\n",
      "[I 2025-09-20 09:09:05,038] Trial 142 finished with value: 0.14077537482923064 and parameters: {'n_estimators': 1000, 'learning_rate': 0.06395410960053713, 'max_depth': 8, 'subsample': 0.9457881083731132, 'colsample_bytree': 0.7776370563687612}. Best is trial 137 with value: 0.13944099438321522.\n",
      "\u001b[32m2025-09-20 09:09:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 143] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 09:09:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 143, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:09:23\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 143, Fold 1/5] RMSE: 0.1497\u001b[0m\n",
      "\u001b[32m2025-09-20 09:09:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 143, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:09:41\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 143, Fold 2/5] RMSE: 0.1360\u001b[0m\n",
      "\u001b[32m2025-09-20 09:09:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 143, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:09:59\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 143, Fold 3/5] RMSE: 0.1355\u001b[0m\n",
      "\u001b[32m2025-09-20 09:09:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 143, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:10:17\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 143, Fold 4/5] RMSE: 0.1506\u001b[0m\n",
      "\u001b[32m2025-09-20 09:10:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 143, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:10:35\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 143, Fold 5/5] RMSE: 0.1296\u001b[0m\n",
      "[I 2025-09-20 09:10:35,433] Trial 143 finished with value: 0.14026423425777063 and parameters: {'n_estimators': 1000, 'learning_rate': 0.0626005578505217, 'max_depth': 8, 'subsample': 0.9509983860464413, 'colsample_bytree': 0.7470876629284744}. Best is trial 137 with value: 0.13944099438321522.\n",
      "\u001b[32m2025-09-20 09:10:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 144] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 09:10:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 144, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:10:54\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 144, Fold 1/5] RMSE: 0.1488\u001b[0m\n",
      "\u001b[32m2025-09-20 09:10:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 144, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:11:12\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 144, Fold 2/5] RMSE: 0.1369\u001b[0m\n",
      "\u001b[32m2025-09-20 09:11:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 144, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:11:30\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 144, Fold 3/5] RMSE: 0.1346\u001b[0m\n",
      "\u001b[32m2025-09-20 09:11:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 144, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:11:49\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 144, Fold 4/5] RMSE: 0.1515\u001b[0m\n",
      "\u001b[32m2025-09-20 09:11:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 144, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:12:07\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 144, Fold 5/5] RMSE: 0.1290\u001b[0m\n",
      "[I 2025-09-20 09:12:07,845] Trial 144 finished with value: 0.14014791596894421 and parameters: {'n_estimators': 1000, 'learning_rate': 0.06951970362308209, 'max_depth': 8, 'subsample': 0.9346002140573989, 'colsample_bytree': 0.7990146274067016}. Best is trial 137 with value: 0.13944099438321522.\n",
      "\u001b[32m2025-09-20 09:12:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 145] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 09:12:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 145, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:12:26\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 145, Fold 1/5] RMSE: 0.1477\u001b[0m\n",
      "\u001b[32m2025-09-20 09:12:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 145, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:12:44\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 145, Fold 2/5] RMSE: 0.1389\u001b[0m\n",
      "\u001b[32m2025-09-20 09:12:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 145, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:13:02\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 145, Fold 3/5] RMSE: 0.1339\u001b[0m\n",
      "\u001b[32m2025-09-20 09:13:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 145, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:13:21\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 145, Fold 4/5] RMSE: 0.1524\u001b[0m\n",
      "\u001b[32m2025-09-20 09:13:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 145, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:13:39\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 145, Fold 5/5] RMSE: 0.1284\u001b[0m\n",
      "[I 2025-09-20 09:13:39,732] Trial 145 finished with value: 0.14026815881023297 and parameters: {'n_estimators': 1000, 'learning_rate': 0.08123041961362433, 'max_depth': 8, 'subsample': 0.9351322727857763, 'colsample_bytree': 0.7978575788941523}. Best is trial 137 with value: 0.13944099438321522.\n",
      "\u001b[32m2025-09-20 09:13:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 146] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 09:13:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 146, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:13:59\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 146, Fold 1/5] RMSE: 0.1507\u001b[0m\n",
      "\u001b[32m2025-09-20 09:13:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 146, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:14:17\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 146, Fold 2/5] RMSE: 0.1381\u001b[0m\n",
      "\u001b[32m2025-09-20 09:14:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 146, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:14:35\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 146, Fold 3/5] RMSE: 0.1317\u001b[0m\n",
      "\u001b[32m2025-09-20 09:14:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 146, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:14:54\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 146, Fold 4/5] RMSE: 0.1505\u001b[0m\n",
      "\u001b[32m2025-09-20 09:14:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 146, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:15:13\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 146, Fold 5/5] RMSE: 0.1323\u001b[0m\n",
      "[I 2025-09-20 09:15:13,153] Trial 146 finished with value: 0.14065546114120725 and parameters: {'n_estimators': 1000, 'learning_rate': 0.07335919697664535, 'max_depth': 8, 'subsample': 0.9264262185458505, 'colsample_bytree': 0.8023249213651807}. Best is trial 137 with value: 0.13944099438321522.\n",
      "\u001b[32m2025-09-20 09:15:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 147] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 09:15:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 147, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:15:31\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 147, Fold 1/5] RMSE: 0.1479\u001b[0m\n",
      "\u001b[32m2025-09-20 09:15:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 147, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:15:49\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 147, Fold 2/5] RMSE: 0.1359\u001b[0m\n",
      "\u001b[32m2025-09-20 09:15:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 147, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:16:07\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 147, Fold 3/5] RMSE: 0.1345\u001b[0m\n",
      "\u001b[32m2025-09-20 09:16:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 147, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:16:25\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 147, Fold 4/5] RMSE: 0.1522\u001b[0m\n",
      "\u001b[32m2025-09-20 09:16:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 147, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:16:43\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 147, Fold 5/5] RMSE: 0.1301\u001b[0m\n",
      "[I 2025-09-20 09:16:43,125] Trial 147 finished with value: 0.14011390403352308 and parameters: {'n_estimators': 1000, 'learning_rate': 0.07025773209996942, 'max_depth': 8, 'subsample': 0.9694257542731182, 'colsample_bytree': 0.7910492128864819}. Best is trial 137 with value: 0.13944099438321522.\n",
      "\u001b[32m2025-09-20 09:16:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 148] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 09:16:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 148, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:17:01\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 148, Fold 1/5] RMSE: 0.1459\u001b[0m\n",
      "\u001b[32m2025-09-20 09:17:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 148, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:17:19\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 148, Fold 2/5] RMSE: 0.1374\u001b[0m\n",
      "\u001b[32m2025-09-20 09:17:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 148, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:17:37\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 148, Fold 3/5] RMSE: 0.1328\u001b[0m\n",
      "\u001b[32m2025-09-20 09:17:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 148, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:17:55\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 148, Fold 4/5] RMSE: 0.1512\u001b[0m\n",
      "\u001b[32m2025-09-20 09:17:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 148, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:18:13\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 148, Fold 5/5] RMSE: 0.1318\u001b[0m\n",
      "[I 2025-09-20 09:18:13,750] Trial 148 finished with value: 0.13983975794355769 and parameters: {'n_estimators': 1000, 'learning_rate': 0.08672997826109298, 'max_depth': 8, 'subsample': 0.9700687957516979, 'colsample_bytree': 0.793430529583892}. Best is trial 137 with value: 0.13944099438321522.\n",
      "\u001b[32m2025-09-20 09:18:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 149] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 09:18:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 149, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:18:19\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 149, Fold 1/5] RMSE: 0.1901\u001b[0m\n",
      "\u001b[32m2025-09-20 09:18:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 149, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:18:25\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 149, Fold 2/5] RMSE: 0.1847\u001b[0m\n",
      "\u001b[32m2025-09-20 09:18:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 149, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:18:30\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 149, Fold 3/5] RMSE: 0.1792\u001b[0m\n",
      "\u001b[32m2025-09-20 09:18:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 149, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:18:36\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 149, Fold 4/5] RMSE: 0.1949\u001b[0m\n",
      "\u001b[32m2025-09-20 09:18:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 149, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:18:42\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 149, Fold 5/5] RMSE: 0.1802\u001b[0m\n",
      "[I 2025-09-20 09:18:42,666] Trial 149 finished with value: 0.18582322383351974 and parameters: {'n_estimators': 1000, 'learning_rate': 0.08772168821756494, 'max_depth': 4, 'subsample': 0.981838957190731, 'colsample_bytree': 0.7901703387955894}. Best is trial 137 with value: 0.13944099438321522.\n",
      "\u001b[32m2025-09-20 09:18:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 150] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 09:18:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 150, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:19:00\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 150, Fold 1/5] RMSE: 0.1504\u001b[0m\n",
      "\u001b[32m2025-09-20 09:19:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 150, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:19:16\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 150, Fold 2/5] RMSE: 0.1408\u001b[0m\n",
      "\u001b[32m2025-09-20 09:19:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 150, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:19:33\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 150, Fold 3/5] RMSE: 0.1378\u001b[0m\n",
      "\u001b[32m2025-09-20 09:19:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 150, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:19:50\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 150, Fold 4/5] RMSE: 0.1583\u001b[0m\n",
      "\u001b[32m2025-09-20 09:19:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 150, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:20:07\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 150, Fold 5/5] RMSE: 0.1319\u001b[0m\n",
      "[I 2025-09-20 09:20:07,945] Trial 150 finished with value: 0.1438632438042999 and parameters: {'n_estimators': 900, 'learning_rate': 0.07692868041884422, 'max_depth': 8, 'subsample': 0.9701366399354149, 'colsample_bytree': 0.9943257495239807}. Best is trial 137 with value: 0.13944099438321522.\n",
      "\u001b[32m2025-09-20 09:20:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 151] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 09:20:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 151, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:20:26\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 151, Fold 1/5] RMSE: 0.1488\u001b[0m\n",
      "\u001b[32m2025-09-20 09:20:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 151, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:20:44\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 151, Fold 2/5] RMSE: 0.1366\u001b[0m\n",
      "\u001b[32m2025-09-20 09:20:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 151, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:21:02\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 151, Fold 3/5] RMSE: 0.1339\u001b[0m\n",
      "\u001b[32m2025-09-20 09:21:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 151, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:21:19\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 151, Fold 4/5] RMSE: 0.1518\u001b[0m\n",
      "\u001b[32m2025-09-20 09:21:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 151, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:21:38\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 151, Fold 5/5] RMSE: 0.1287\u001b[0m\n",
      "[I 2025-09-20 09:21:38,057] Trial 151 finished with value: 0.13996996813133072 and parameters: {'n_estimators': 1000, 'learning_rate': 0.06926720568933625, 'max_depth': 8, 'subsample': 0.9640539911616781, 'colsample_bytree': 0.8070881887607092}. Best is trial 137 with value: 0.13944099438321522.\n",
      "\u001b[32m2025-09-20 09:21:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 152] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 09:21:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 152, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:21:56\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 152, Fold 1/5] RMSE: 0.1473\u001b[0m\n",
      "\u001b[32m2025-09-20 09:21:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 152, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:22:14\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 152, Fold 2/5] RMSE: 0.1372\u001b[0m\n",
      "\u001b[32m2025-09-20 09:22:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 152, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:22:33\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 152, Fold 3/5] RMSE: 0.1338\u001b[0m\n",
      "\u001b[32m2025-09-20 09:22:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 152, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:22:51\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 152, Fold 4/5] RMSE: 0.1524\u001b[0m\n",
      "\u001b[32m2025-09-20 09:22:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 152, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:23:10\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 152, Fold 5/5] RMSE: 0.1309\u001b[0m\n",
      "[I 2025-09-20 09:23:10,562] Trial 152 finished with value: 0.14032740461728924 and parameters: {'n_estimators': 1000, 'learning_rate': 0.0798822367006668, 'max_depth': 8, 'subsample': 0.9638948182135925, 'colsample_bytree': 0.8238262293767072}. Best is trial 137 with value: 0.13944099438321522.\n",
      "\u001b[32m2025-09-20 09:23:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 153] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 09:23:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 153, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:23:28\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 153, Fold 1/5] RMSE: 0.1485\u001b[0m\n",
      "\u001b[32m2025-09-20 09:23:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 153, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:23:46\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 153, Fold 2/5] RMSE: 0.1378\u001b[0m\n",
      "\u001b[32m2025-09-20 09:23:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 153, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:24:04\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 153, Fold 3/5] RMSE: 0.1344\u001b[0m\n",
      "\u001b[32m2025-09-20 09:24:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 153, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:24:22\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 153, Fold 4/5] RMSE: 0.1524\u001b[0m\n",
      "\u001b[32m2025-09-20 09:24:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 153, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:24:40\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 153, Fold 5/5] RMSE: 0.1305\u001b[0m\n",
      "[I 2025-09-20 09:24:40,841] Trial 153 finished with value: 0.1407215278124567 and parameters: {'n_estimators': 1000, 'learning_rate': 0.07297347318461635, 'max_depth': 8, 'subsample': 0.9709576510590757, 'colsample_bytree': 0.8051967493453569}. Best is trial 137 with value: 0.13944099438321522.\n",
      "\u001b[32m2025-09-20 09:24:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 154] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 09:24:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 154, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:24:58\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 154, Fold 1/5] RMSE: 0.1479\u001b[0m\n",
      "\u001b[32m2025-09-20 09:24:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 154, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:25:16\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 154, Fold 2/5] RMSE: 0.1383\u001b[0m\n",
      "\u001b[32m2025-09-20 09:25:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 154, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:25:34\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 154, Fold 3/5] RMSE: 0.1333\u001b[0m\n",
      "\u001b[32m2025-09-20 09:25:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 154, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:25:52\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 154, Fold 4/5] RMSE: 0.1524\u001b[0m\n",
      "\u001b[32m2025-09-20 09:25:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 154, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:26:10\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 154, Fold 5/5] RMSE: 0.1295\u001b[0m\n",
      "[I 2025-09-20 09:26:10,658] Trial 154 finished with value: 0.14026201042485423 and parameters: {'n_estimators': 1000, 'learning_rate': 0.06686370518522189, 'max_depth': 8, 'subsample': 0.975159140361864, 'colsample_bytree': 0.7899870632782254}. Best is trial 137 with value: 0.13944099438321522.\n",
      "\u001b[32m2025-09-20 09:26:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 155] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 09:26:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 155, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:26:28\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 155, Fold 1/5] RMSE: 0.1501\u001b[0m\n",
      "\u001b[32m2025-09-20 09:26:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 155, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:26:47\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 155, Fold 2/5] RMSE: 0.1383\u001b[0m\n",
      "\u001b[32m2025-09-20 09:26:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 155, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:27:05\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 155, Fold 3/5] RMSE: 0.1320\u001b[0m\n",
      "\u001b[32m2025-09-20 09:27:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 155, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:27:22\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 155, Fold 4/5] RMSE: 0.1512\u001b[0m\n",
      "\u001b[32m2025-09-20 09:27:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 155, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:27:41\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 155, Fold 5/5] RMSE: 0.1304\u001b[0m\n",
      "[I 2025-09-20 09:27:41,037] Trial 155 finished with value: 0.14039538612990826 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05567840354633974, 'max_depth': 8, 'subsample': 0.9653515566756417, 'colsample_bytree': 0.8144196803882038}. Best is trial 137 with value: 0.13944099438321522.\n",
      "\u001b[32m2025-09-20 09:27:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 156] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 09:27:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 156, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:27:59\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 156, Fold 1/5] RMSE: 0.1467\u001b[0m\n",
      "\u001b[32m2025-09-20 09:27:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 156, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:28:17\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 156, Fold 2/5] RMSE: 0.1364\u001b[0m\n",
      "\u001b[32m2025-09-20 09:28:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 156, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:28:35\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 156, Fold 3/5] RMSE: 0.1342\u001b[0m\n",
      "\u001b[32m2025-09-20 09:28:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 156, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:28:53\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 156, Fold 4/5] RMSE: 0.1494\u001b[0m\n",
      "\u001b[32m2025-09-20 09:28:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 156, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:29:12\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 156, Fold 5/5] RMSE: 0.1334\u001b[0m\n",
      "[I 2025-09-20 09:29:12,223] Trial 156 finished with value: 0.14002788930157523 and parameters: {'n_estimators': 1000, 'learning_rate': 0.08484475456683534, 'max_depth': 8, 'subsample': 0.955396105580846, 'colsample_bytree': 0.7563855154690368}. Best is trial 137 with value: 0.13944099438321522.\n",
      "\u001b[32m2025-09-20 09:29:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 157] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 09:29:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 157, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:29:30\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 157, Fold 1/5] RMSE: 0.1481\u001b[0m\n",
      "\u001b[32m2025-09-20 09:29:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 157, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:29:48\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 157, Fold 2/5] RMSE: 0.1371\u001b[0m\n",
      "\u001b[32m2025-09-20 09:29:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 157, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:30:07\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 157, Fold 3/5] RMSE: 0.1352\u001b[0m\n",
      "\u001b[32m2025-09-20 09:30:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 157, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:30:25\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 157, Fold 4/5] RMSE: 0.1501\u001b[0m\n",
      "\u001b[32m2025-09-20 09:30:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 157, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:30:43\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 157, Fold 5/5] RMSE: 0.1301\u001b[0m\n",
      "[I 2025-09-20 09:30:43,828] Trial 157 finished with value: 0.14013388265298993 and parameters: {'n_estimators': 1000, 'learning_rate': 0.08319750397528575, 'max_depth': 8, 'subsample': 0.9563785408986444, 'colsample_bytree': 0.7548713623602259}. Best is trial 137 with value: 0.13944099438321522.\n",
      "\u001b[32m2025-09-20 09:30:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 158] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 09:30:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 158, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:31:03\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 158, Fold 1/5] RMSE: 0.1476\u001b[0m\n",
      "\u001b[32m2025-09-20 09:31:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 158, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:31:21\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 158, Fold 2/5] RMSE: 0.1376\u001b[0m\n",
      "\u001b[32m2025-09-20 09:31:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 158, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:31:39\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 158, Fold 3/5] RMSE: 0.1347\u001b[0m\n",
      "\u001b[32m2025-09-20 09:31:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 158, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:31:58\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 158, Fold 4/5] RMSE: 0.1513\u001b[0m\n",
      "\u001b[32m2025-09-20 09:31:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 158, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:32:16\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 158, Fold 5/5] RMSE: 0.1317\u001b[0m\n",
      "[I 2025-09-20 09:32:16,555] Trial 158 finished with value: 0.14059551146583726 and parameters: {'n_estimators': 1000, 'learning_rate': 0.09728382583965514, 'max_depth': 8, 'subsample': 0.9533946871788604, 'colsample_bytree': 0.7616843334877319}. Best is trial 137 with value: 0.13944099438321522.\n",
      "\u001b[32m2025-09-20 09:32:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 159] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 09:32:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 159, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:32:34\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 159, Fold 1/5] RMSE: 0.1477\u001b[0m\n",
      "\u001b[32m2025-09-20 09:32:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 159, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:32:53\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 159, Fold 2/5] RMSE: 0.1374\u001b[0m\n",
      "\u001b[32m2025-09-20 09:32:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 159, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:33:11\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 159, Fold 3/5] RMSE: 0.1358\u001b[0m\n",
      "\u001b[32m2025-09-20 09:33:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 159, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:33:29\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 159, Fold 4/5] RMSE: 0.1495\u001b[0m\n",
      "\u001b[32m2025-09-20 09:33:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 159, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:33:47\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 159, Fold 5/5] RMSE: 0.1296\u001b[0m\n",
      "[I 2025-09-20 09:33:47,650] Trial 159 finished with value: 0.14001268043586182 and parameters: {'n_estimators': 1000, 'learning_rate': 0.08726593293172387, 'max_depth': 8, 'subsample': 0.961405423285474, 'colsample_bytree': 0.7695630199726513}. Best is trial 137 with value: 0.13944099438321522.\n",
      "\u001b[32m2025-09-20 09:33:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 160] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 09:33:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 160, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:34:06\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 160, Fold 1/5] RMSE: 0.1500\u001b[0m\n",
      "\u001b[32m2025-09-20 09:34:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 160, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:34:24\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 160, Fold 2/5] RMSE: 0.1388\u001b[0m\n",
      "\u001b[32m2025-09-20 09:34:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 160, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:34:42\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 160, Fold 3/5] RMSE: 0.1366\u001b[0m\n",
      "\u001b[32m2025-09-20 09:34:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 160, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:35:00\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 160, Fold 4/5] RMSE: 0.1511\u001b[0m\n",
      "\u001b[32m2025-09-20 09:35:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 160, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:35:18\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 160, Fold 5/5] RMSE: 0.1310\u001b[0m\n",
      "[I 2025-09-20 09:35:18,487] Trial 160 finished with value: 0.14150706829026677 and parameters: {'n_estimators': 1000, 'learning_rate': 0.09144901439207806, 'max_depth': 8, 'subsample': 0.9798575866097963, 'colsample_bytree': 0.7694960590126342}. Best is trial 137 with value: 0.13944099438321522.\n",
      "\u001b[32m2025-09-20 09:35:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 161] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 09:35:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 161, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:35:36\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 161, Fold 1/5] RMSE: 0.1479\u001b[0m\n",
      "\u001b[32m2025-09-20 09:35:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 161, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:35:54\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 161, Fold 2/5] RMSE: 0.1361\u001b[0m\n",
      "\u001b[32m2025-09-20 09:35:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 161, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:36:12\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 161, Fold 3/5] RMSE: 0.1354\u001b[0m\n",
      "\u001b[32m2025-09-20 09:36:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 161, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:36:30\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 161, Fold 4/5] RMSE: 0.1510\u001b[0m\n",
      "\u001b[32m2025-09-20 09:36:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 161, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:36:49\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 161, Fold 5/5] RMSE: 0.1319\u001b[0m\n",
      "[I 2025-09-20 09:36:49,080] Trial 161 finished with value: 0.14045453646327327 and parameters: {'n_estimators': 1000, 'learning_rate': 0.0892409633160329, 'max_depth': 8, 'subsample': 0.960050170301549, 'colsample_bytree': 0.7526515093536381}. Best is trial 137 with value: 0.13944099438321522.\n",
      "\u001b[32m2025-09-20 09:36:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 162] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 09:36:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 162, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:37:08\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 162, Fold 1/5] RMSE: 0.1491\u001b[0m\n",
      "\u001b[32m2025-09-20 09:37:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 162, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:37:27\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 162, Fold 2/5] RMSE: 0.1381\u001b[0m\n",
      "\u001b[32m2025-09-20 09:37:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 162, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:37:46\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 162, Fold 3/5] RMSE: 0.1370\u001b[0m\n",
      "\u001b[32m2025-09-20 09:37:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 162, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:38:06\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 162, Fold 4/5] RMSE: 0.1556\u001b[0m\n",
      "\u001b[32m2025-09-20 09:38:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 162, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:38:26\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 162, Fold 5/5] RMSE: 0.1326\u001b[0m\n",
      "[I 2025-09-20 09:38:26,621] Trial 162 finished with value: 0.1424733491344247 and parameters: {'n_estimators': 1000, 'learning_rate': 0.08544658832928874, 'max_depth': 8, 'subsample': 0.9486453952428169, 'colsample_bytree': 0.9792243019731238}. Best is trial 137 with value: 0.13944099438321522.\n",
      "\u001b[32m2025-09-20 09:38:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 163] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 09:38:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 163, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:38:45\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 163, Fold 1/5] RMSE: 0.1489\u001b[0m\n",
      "\u001b[32m2025-09-20 09:38:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 163, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:39:03\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 163, Fold 2/5] RMSE: 0.1364\u001b[0m\n",
      "\u001b[32m2025-09-20 09:39:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 163, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:39:21\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 163, Fold 3/5] RMSE: 0.1353\u001b[0m\n",
      "\u001b[32m2025-09-20 09:39:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 163, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:39:39\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 163, Fold 4/5] RMSE: 0.1519\u001b[0m\n",
      "\u001b[32m2025-09-20 09:39:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 163, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:39:58\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 163, Fold 5/5] RMSE: 0.1313\u001b[0m\n",
      "[I 2025-09-20 09:39:58,041] Trial 163 finished with value: 0.1407635169698133 and parameters: {'n_estimators': 1000, 'learning_rate': 0.10031454535239286, 'max_depth': 8, 'subsample': 0.9629010139861217, 'colsample_bytree': 0.7462806802843879}. Best is trial 137 with value: 0.13944099438321522.\n",
      "\u001b[32m2025-09-20 09:39:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 164] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 09:39:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 164, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:40:16\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 164, Fold 1/5] RMSE: 0.1479\u001b[0m\n",
      "\u001b[32m2025-09-20 09:40:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 164, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:40:34\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 164, Fold 2/5] RMSE: 0.1369\u001b[0m\n",
      "\u001b[32m2025-09-20 09:40:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 164, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:40:53\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 164, Fold 3/5] RMSE: 0.1347\u001b[0m\n",
      "\u001b[32m2025-09-20 09:40:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 164, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:41:11\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 164, Fold 4/5] RMSE: 0.1491\u001b[0m\n",
      "\u001b[32m2025-09-20 09:41:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 164, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:41:29\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 164, Fold 5/5] RMSE: 0.1298\u001b[0m\n",
      "[I 2025-09-20 09:41:29,492] Trial 164 finished with value: 0.13969697920797436 and parameters: {'n_estimators': 1000, 'learning_rate': 0.07642716187481631, 'max_depth': 8, 'subsample': 0.9429097246073483, 'colsample_bytree': 0.7730757316205512}. Best is trial 137 with value: 0.13944099438321522.\n",
      "\u001b[32m2025-09-20 09:41:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 165] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 09:41:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 165, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:41:47\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 165, Fold 1/5] RMSE: 0.1470\u001b[0m\n",
      "\u001b[32m2025-09-20 09:41:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 165, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:42:06\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 165, Fold 2/5] RMSE: 0.1381\u001b[0m\n",
      "\u001b[32m2025-09-20 09:42:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 165, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:42:24\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 165, Fold 3/5] RMSE: 0.1353\u001b[0m\n",
      "\u001b[32m2025-09-20 09:42:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 165, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:42:42\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 165, Fold 4/5] RMSE: 0.1495\u001b[0m\n",
      "\u001b[32m2025-09-20 09:42:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 165, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:43:01\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 165, Fold 5/5] RMSE: 0.1301\u001b[0m\n",
      "[I 2025-09-20 09:43:01,269] Trial 165 finished with value: 0.1400083287481873 and parameters: {'n_estimators': 1000, 'learning_rate': 0.07559500217684993, 'max_depth': 8, 'subsample': 0.9421394896095935, 'colsample_bytree': 0.780462107687869}. Best is trial 137 with value: 0.13944099438321522.\n",
      "\u001b[32m2025-09-20 09:43:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 166] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 09:43:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 166, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:43:19\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 166, Fold 1/5] RMSE: 0.1464\u001b[0m\n",
      "\u001b[32m2025-09-20 09:43:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 166, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:43:37\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 166, Fold 2/5] RMSE: 0.1387\u001b[0m\n",
      "\u001b[32m2025-09-20 09:43:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 166, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:43:55\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 166, Fold 3/5] RMSE: 0.1343\u001b[0m\n",
      "\u001b[32m2025-09-20 09:43:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 166, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:44:13\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 166, Fold 4/5] RMSE: 0.1488\u001b[0m\n",
      "\u001b[32m2025-09-20 09:44:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 166, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:44:32\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 166, Fold 5/5] RMSE: 0.1295\u001b[0m\n",
      "[I 2025-09-20 09:44:32,171] Trial 166 finished with value: 0.13951907995303414 and parameters: {'n_estimators': 1000, 'learning_rate': 0.07480429333706883, 'max_depth': 8, 'subsample': 0.9396517458441777, 'colsample_bytree': 0.7825477745466781}. Best is trial 137 with value: 0.13944099438321522.\n",
      "\u001b[32m2025-09-20 09:44:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 167] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 09:44:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 167, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:44:50\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 167, Fold 1/5] RMSE: 0.1456\u001b[0m\n",
      "\u001b[32m2025-09-20 09:44:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 167, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:45:08\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 167, Fold 2/5] RMSE: 0.1391\u001b[0m\n",
      "\u001b[32m2025-09-20 09:45:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 167, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:45:26\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 167, Fold 3/5] RMSE: 0.1335\u001b[0m\n",
      "\u001b[32m2025-09-20 09:45:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 167, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:45:45\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 167, Fold 4/5] RMSE: 0.1506\u001b[0m\n",
      "\u001b[32m2025-09-20 09:45:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 167, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:46:03\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 167, Fold 5/5] RMSE: 0.1299\u001b[0m\n",
      "[I 2025-09-20 09:46:03,727] Trial 167 finished with value: 0.13973580029461546 and parameters: {'n_estimators': 1000, 'learning_rate': 0.07607040716382434, 'max_depth': 8, 'subsample': 0.9408812902666482, 'colsample_bytree': 0.7811405566539672}. Best is trial 137 with value: 0.13944099438321522.\n",
      "\u001b[32m2025-09-20 09:46:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 168] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 09:46:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 168, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:46:22\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 168, Fold 1/5] RMSE: 0.1477\u001b[0m\n",
      "\u001b[32m2025-09-20 09:46:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 168, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:46:40\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 168, Fold 2/5] RMSE: 0.1372\u001b[0m\n",
      "\u001b[32m2025-09-20 09:46:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 168, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:46:59\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 168, Fold 3/5] RMSE: 0.1340\u001b[0m\n",
      "\u001b[32m2025-09-20 09:46:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 168, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:47:17\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 168, Fold 4/5] RMSE: 0.1503\u001b[0m\n",
      "\u001b[32m2025-09-20 09:47:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 168, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:47:35\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 168, Fold 5/5] RMSE: 0.1279\u001b[0m\n",
      "[I 2025-09-20 09:47:35,790] Trial 168 finished with value: 0.13945059916813737 and parameters: {'n_estimators': 1000, 'learning_rate': 0.07535715793371575, 'max_depth': 8, 'subsample': 0.9414208002861848, 'colsample_bytree': 0.7853401376900437}. Best is trial 137 with value: 0.13944099438321522.\n",
      "\u001b[32m2025-09-20 09:47:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 169] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 09:47:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 169, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:47:54\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 169, Fold 1/5] RMSE: 0.1469\u001b[0m\n",
      "\u001b[32m2025-09-20 09:47:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 169, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:48:12\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 169, Fold 2/5] RMSE: 0.1369\u001b[0m\n",
      "\u001b[32m2025-09-20 09:48:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 169, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:48:30\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 169, Fold 3/5] RMSE: 0.1333\u001b[0m\n",
      "\u001b[32m2025-09-20 09:48:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 169, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:48:49\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 169, Fold 4/5] RMSE: 0.1489\u001b[0m\n",
      "\u001b[32m2025-09-20 09:48:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 169, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:49:07\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 169, Fold 5/5] RMSE: 0.1277\u001b[0m\n",
      "[I 2025-09-20 09:49:07,718] Trial 169 finished with value: 0.13873005082072956 and parameters: {'n_estimators': 1000, 'learning_rate': 0.07680902164332667, 'max_depth': 8, 'subsample': 0.9392496800876371, 'colsample_bytree': 0.7877773419720474}. Best is trial 169 with value: 0.13873005082072956.\n",
      "\u001b[32m2025-09-20 09:49:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 170] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 09:49:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 170, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:49:26\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 170, Fold 1/5] RMSE: 0.1486\u001b[0m\n",
      "\u001b[32m2025-09-20 09:49:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 170, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:49:44\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 170, Fold 2/5] RMSE: 0.1360\u001b[0m\n",
      "\u001b[32m2025-09-20 09:49:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 170, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:50:02\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 170, Fold 3/5] RMSE: 0.1349\u001b[0m\n",
      "\u001b[32m2025-09-20 09:50:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 170, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:50:21\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 170, Fold 4/5] RMSE: 0.1518\u001b[0m\n",
      "\u001b[32m2025-09-20 09:50:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 170, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:50:39\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 170, Fold 5/5] RMSE: 0.1303\u001b[0m\n",
      "[I 2025-09-20 09:50:39,809] Trial 170 finished with value: 0.1403004959336529 and parameters: {'n_estimators': 1000, 'learning_rate': 0.07757706352514415, 'max_depth': 8, 'subsample': 0.923360428716645, 'colsample_bytree': 0.7866539839878778}. Best is trial 169 with value: 0.13873005082072956.\n",
      "\u001b[32m2025-09-20 09:50:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 171] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 09:50:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 171, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:50:59\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 171, Fold 1/5] RMSE: 0.1463\u001b[0m\n",
      "\u001b[32m2025-09-20 09:50:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 171, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:51:17\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 171, Fold 2/5] RMSE: 0.1371\u001b[0m\n",
      "\u001b[32m2025-09-20 09:51:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 171, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:51:35\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 171, Fold 3/5] RMSE: 0.1344\u001b[0m\n",
      "\u001b[32m2025-09-20 09:51:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 171, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:51:54\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 171, Fold 4/5] RMSE: 0.1529\u001b[0m\n",
      "\u001b[32m2025-09-20 09:51:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 171, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:52:12\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 171, Fold 5/5] RMSE: 0.1295\u001b[0m\n",
      "[I 2025-09-20 09:52:12,894] Trial 171 finished with value: 0.14003274879731892 and parameters: {'n_estimators': 1000, 'learning_rate': 0.07250716026504829, 'max_depth': 8, 'subsample': 0.9395836035982615, 'colsample_bytree': 0.794831500449641}. Best is trial 169 with value: 0.13873005082072956.\n",
      "\u001b[32m2025-09-20 09:52:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 172] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 09:52:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 172, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:52:31\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 172, Fold 1/5] RMSE: 0.1470\u001b[0m\n",
      "\u001b[32m2025-09-20 09:52:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 172, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:52:49\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 172, Fold 2/5] RMSE: 0.1377\u001b[0m\n",
      "\u001b[32m2025-09-20 09:52:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 172, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:53:08\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 172, Fold 3/5] RMSE: 0.1321\u001b[0m\n",
      "\u001b[32m2025-09-20 09:53:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 172, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:53:26\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 172, Fold 4/5] RMSE: 0.1502\u001b[0m\n",
      "\u001b[32m2025-09-20 09:53:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 172, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:53:44\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 172, Fold 5/5] RMSE: 0.1300\u001b[0m\n",
      "[I 2025-09-20 09:53:44,891] Trial 172 finished with value: 0.13941543769172693 and parameters: {'n_estimators': 1000, 'learning_rate': 0.06900989406871438, 'max_depth': 8, 'subsample': 0.9305217299387628, 'colsample_bytree': 0.7847019917041756}. Best is trial 169 with value: 0.13873005082072956.\n",
      "\u001b[32m2025-09-20 09:53:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 173] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 09:53:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 173, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:54:03\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 173, Fold 1/5] RMSE: 0.1494\u001b[0m\n",
      "\u001b[32m2025-09-20 09:54:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 173, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:54:21\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 173, Fold 2/5] RMSE: 0.1382\u001b[0m\n",
      "\u001b[32m2025-09-20 09:54:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 173, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:54:40\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 173, Fold 3/5] RMSE: 0.1354\u001b[0m\n",
      "\u001b[32m2025-09-20 09:54:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 173, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:54:59\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 173, Fold 4/5] RMSE: 0.1516\u001b[0m\n",
      "\u001b[32m2025-09-20 09:54:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 173, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:55:17\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 173, Fold 5/5] RMSE: 0.1313\u001b[0m\n",
      "[I 2025-09-20 09:55:17,478] Trial 173 finished with value: 0.1411841911961227 and parameters: {'n_estimators': 1000, 'learning_rate': 0.07538063207896328, 'max_depth': 8, 'subsample': 0.9311069796183691, 'colsample_bytree': 0.7803395941590311}. Best is trial 169 with value: 0.13873005082072956.\n",
      "\u001b[32m2025-09-20 09:55:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 174] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 09:55:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 174, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:55:36\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 174, Fold 1/5] RMSE: 0.1471\u001b[0m\n",
      "\u001b[32m2025-09-20 09:55:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 174, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:55:54\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 174, Fold 2/5] RMSE: 0.1386\u001b[0m\n",
      "\u001b[32m2025-09-20 09:55:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 174, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:56:13\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 174, Fold 3/5] RMSE: 0.1349\u001b[0m\n",
      "\u001b[32m2025-09-20 09:56:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 174, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:56:33\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 174, Fold 4/5] RMSE: 0.1490\u001b[0m\n",
      "\u001b[32m2025-09-20 09:56:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 174, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:56:52\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 174, Fold 5/5] RMSE: 0.1322\u001b[0m\n",
      "[I 2025-09-20 09:56:52,535] Trial 174 finished with value: 0.14037887515819453 and parameters: {'n_estimators': 1000, 'learning_rate': 0.08120543658133622, 'max_depth': 8, 'subsample': 0.9131928797615173, 'colsample_bytree': 0.7859513150855836}. Best is trial 169 with value: 0.13873005082072956.\n",
      "\u001b[32m2025-09-20 09:56:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 175] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 09:56:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 175, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:57:11\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 175, Fold 1/5] RMSE: 0.1481\u001b[0m\n",
      "\u001b[32m2025-09-20 09:57:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 175, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:57:33\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 175, Fold 2/5] RMSE: 0.1375\u001b[0m\n",
      "\u001b[32m2025-09-20 09:57:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 175, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:57:51\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 175, Fold 3/5] RMSE: 0.1356\u001b[0m\n",
      "\u001b[32m2025-09-20 09:57:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 175, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:58:09\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 175, Fold 4/5] RMSE: 0.1512\u001b[0m\n",
      "\u001b[32m2025-09-20 09:58:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 175, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:58:28\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 175, Fold 5/5] RMSE: 0.1323\u001b[0m\n",
      "[I 2025-09-20 09:58:28,307] Trial 175 finished with value: 0.14092097405039178 and parameters: {'n_estimators': 1000, 'learning_rate': 0.060728178818296216, 'max_depth': 8, 'subsample': 0.9405760097421576, 'colsample_bytree': 0.7738361683570226}. Best is trial 169 with value: 0.13873005082072956.\n",
      "\u001b[32m2025-09-20 09:58:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 176] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 09:58:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 176, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:58:46\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 176, Fold 1/5] RMSE: 0.1489\u001b[0m\n",
      "\u001b[32m2025-09-20 09:58:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 176, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:59:04\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 176, Fold 2/5] RMSE: 0.1391\u001b[0m\n",
      "\u001b[32m2025-09-20 09:59:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 176, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:59:22\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 176, Fold 3/5] RMSE: 0.1352\u001b[0m\n",
      "\u001b[32m2025-09-20 09:59:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 176, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:59:40\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 176, Fold 4/5] RMSE: 0.1508\u001b[0m\n",
      "\u001b[32m2025-09-20 09:59:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 176, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 09:59:59\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 176, Fold 5/5] RMSE: 0.1312\u001b[0m\n",
      "[I 2025-09-20 09:59:59,047] Trial 176 finished with value: 0.14106509633429645 and parameters: {'n_estimators': 1000, 'learning_rate': 0.058208394897214716, 'max_depth': 8, 'subsample': 0.9276794576769506, 'colsample_bytree': 0.7760093537455153}. Best is trial 169 with value: 0.13873005082072956.\n",
      "\u001b[32m2025-09-20 09:59:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 177] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 09:59:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 177, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:00:17\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 177, Fold 1/5] RMSE: 0.1504\u001b[0m\n",
      "\u001b[32m2025-09-20 10:00:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 177, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:00:35\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 177, Fold 2/5] RMSE: 0.1384\u001b[0m\n",
      "\u001b[32m2025-09-20 10:00:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 177, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:00:54\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 177, Fold 3/5] RMSE: 0.1326\u001b[0m\n",
      "\u001b[32m2025-09-20 10:00:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 177, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:01:13\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 177, Fold 4/5] RMSE: 0.1523\u001b[0m\n",
      "\u001b[32m2025-09-20 10:01:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 177, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:01:31\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 177, Fold 5/5] RMSE: 0.1313\u001b[0m\n",
      "[I 2025-09-20 10:01:31,540] Trial 177 finished with value: 0.1410047847358163 and parameters: {'n_estimators': 1000, 'learning_rate': 0.06531353516542392, 'max_depth': 8, 'subsample': 0.9013572236605891, 'colsample_bytree': 0.7941896496832912}. Best is trial 169 with value: 0.13873005082072956.\n",
      "\u001b[32m2025-09-20 10:01:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 178] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 10:01:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 178, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:01:50\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 178, Fold 1/5] RMSE: 0.1487\u001b[0m\n",
      "\u001b[32m2025-09-20 10:01:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 178, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:02:08\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 178, Fold 2/5] RMSE: 0.1384\u001b[0m\n",
      "\u001b[32m2025-09-20 10:02:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 178, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:02:26\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 178, Fold 3/5] RMSE: 0.1324\u001b[0m\n",
      "\u001b[32m2025-09-20 10:02:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 178, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:02:44\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 178, Fold 4/5] RMSE: 0.1503\u001b[0m\n",
      "\u001b[32m2025-09-20 10:02:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 178, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:03:04\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 178, Fold 5/5] RMSE: 0.1301\u001b[0m\n",
      "[I 2025-09-20 10:03:04,063] Trial 178 finished with value: 0.13998594563091996 and parameters: {'n_estimators': 1000, 'learning_rate': 0.0683829198642275, 'max_depth': 8, 'subsample': 0.9204349729230934, 'colsample_bytree': 0.7853156308508437}. Best is trial 169 with value: 0.13873005082072956.\n",
      "\u001b[32m2025-09-20 10:03:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 179] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 10:03:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 179, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:03:22\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 179, Fold 1/5] RMSE: 0.1483\u001b[0m\n",
      "\u001b[32m2025-09-20 10:03:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 179, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:03:40\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 179, Fold 2/5] RMSE: 0.1380\u001b[0m\n",
      "\u001b[32m2025-09-20 10:03:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 179, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:03:58\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 179, Fold 3/5] RMSE: 0.1349\u001b[0m\n",
      "\u001b[32m2025-09-20 10:03:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 179, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:04:16\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 179, Fold 4/5] RMSE: 0.1513\u001b[0m\n",
      "\u001b[32m2025-09-20 10:04:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 179, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:04:34\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 179, Fold 5/5] RMSE: 0.1295\u001b[0m\n",
      "[I 2025-09-20 10:04:34,729] Trial 179 finished with value: 0.14040368706175257 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05253631276932004, 'max_depth': 8, 'subsample': 0.9383185686013745, 'colsample_bytree': 0.7783237728180269}. Best is trial 169 with value: 0.13873005082072956.\n",
      "\u001b[32m2025-09-20 10:04:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 180] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 10:04:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 180, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:04:53\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 180, Fold 1/5] RMSE: 0.1495\u001b[0m\n",
      "\u001b[32m2025-09-20 10:04:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 180, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:05:11\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 180, Fold 2/5] RMSE: 0.1386\u001b[0m\n",
      "\u001b[32m2025-09-20 10:05:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 180, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:05:29\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 180, Fold 3/5] RMSE: 0.1341\u001b[0m\n",
      "\u001b[32m2025-09-20 10:05:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 180, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:05:47\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 180, Fold 4/5] RMSE: 0.1499\u001b[0m\n",
      "\u001b[32m2025-09-20 10:05:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 180, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:06:05\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 180, Fold 5/5] RMSE: 0.1290\u001b[0m\n",
      "[I 2025-09-20 10:06:05,766] Trial 180 finished with value: 0.14022586770867088 and parameters: {'n_estimators': 1000, 'learning_rate': 0.07163241138784061, 'max_depth': 8, 'subsample': 0.9442896661369693, 'colsample_bytree': 0.7873636690432921}. Best is trial 169 with value: 0.13873005082072956.\n",
      "\u001b[32m2025-09-20 10:06:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 181] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 10:06:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 181, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:06:24\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 181, Fold 1/5] RMSE: 0.1479\u001b[0m\n",
      "\u001b[32m2025-09-20 10:06:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 181, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:06:42\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 181, Fold 2/5] RMSE: 0.1369\u001b[0m\n",
      "\u001b[32m2025-09-20 10:06:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 181, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:07:00\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 181, Fold 3/5] RMSE: 0.1349\u001b[0m\n",
      "\u001b[32m2025-09-20 10:07:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 181, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:07:19\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 181, Fold 4/5] RMSE: 0.1517\u001b[0m\n",
      "\u001b[32m2025-09-20 10:07:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 181, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:07:37\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 181, Fold 5/5] RMSE: 0.1301\u001b[0m\n",
      "[I 2025-09-20 10:07:37,490] Trial 181 finished with value: 0.1402978627744094 and parameters: {'n_estimators': 1000, 'learning_rate': 0.06949100150506055, 'max_depth': 8, 'subsample': 0.9487950284512691, 'colsample_bytree': 0.8059414129826862}. Best is trial 169 with value: 0.13873005082072956.\n",
      "\u001b[32m2025-09-20 10:07:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 182] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 10:07:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 182, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:07:55\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 182, Fold 1/5] RMSE: 0.1470\u001b[0m\n",
      "\u001b[32m2025-09-20 10:07:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 182, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:08:13\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 182, Fold 2/5] RMSE: 0.1389\u001b[0m\n",
      "\u001b[32m2025-09-20 10:08:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 182, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:08:31\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 182, Fold 3/5] RMSE: 0.1323\u001b[0m\n",
      "\u001b[32m2025-09-20 10:08:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 182, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:08:50\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 182, Fold 4/5] RMSE: 0.1517\u001b[0m\n",
      "\u001b[32m2025-09-20 10:08:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 182, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:09:08\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 182, Fold 5/5] RMSE: 0.1297\u001b[0m\n",
      "[I 2025-09-20 10:09:08,477] Trial 182 finished with value: 0.1399116025418581 and parameters: {'n_estimators': 1000, 'learning_rate': 0.06245639195280788, 'max_depth': 8, 'subsample': 0.9329078205514025, 'colsample_bytree': 0.7984295519356537}. Best is trial 169 with value: 0.13873005082072956.\n",
      "\u001b[32m2025-09-20 10:09:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 183] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 10:09:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 183, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:09:26\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 183, Fold 1/5] RMSE: 0.1485\u001b[0m\n",
      "\u001b[32m2025-09-20 10:09:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 183, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:09:45\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 183, Fold 2/5] RMSE: 0.1385\u001b[0m\n",
      "\u001b[32m2025-09-20 10:09:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 183, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:10:03\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 183, Fold 3/5] RMSE: 0.1332\u001b[0m\n",
      "\u001b[32m2025-09-20 10:10:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 183, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:10:21\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 183, Fold 4/5] RMSE: 0.1510\u001b[0m\n",
      "\u001b[32m2025-09-20 10:10:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 183, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:10:39\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 183, Fold 5/5] RMSE: 0.1291\u001b[0m\n",
      "[I 2025-09-20 10:10:39,747] Trial 183 finished with value: 0.14006737476120962 and parameters: {'n_estimators': 1000, 'learning_rate': 0.061430385318244095, 'max_depth': 8, 'subsample': 0.932957474623861, 'colsample_bytree': 0.7982717574310979}. Best is trial 169 with value: 0.13873005082072956.\n",
      "\u001b[32m2025-09-20 10:10:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 184] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 10:10:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 184, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:10:58\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 184, Fold 1/5] RMSE: 0.1478\u001b[0m\n",
      "\u001b[32m2025-09-20 10:10:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 184, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:11:16\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 184, Fold 2/5] RMSE: 0.1389\u001b[0m\n",
      "\u001b[32m2025-09-20 10:11:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 184, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:11:34\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 184, Fold 3/5] RMSE: 0.1344\u001b[0m\n",
      "\u001b[32m2025-09-20 10:11:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 184, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:11:52\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 184, Fold 4/5] RMSE: 0.1514\u001b[0m\n",
      "\u001b[32m2025-09-20 10:11:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 184, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:12:10\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 184, Fold 5/5] RMSE: 0.1298\u001b[0m\n",
      "[I 2025-09-20 10:12:10,477] Trial 184 finished with value: 0.14048344749103997 and parameters: {'n_estimators': 1000, 'learning_rate': 0.06302657622860916, 'max_depth': 8, 'subsample': 0.9292913905254875, 'colsample_bytree': 0.7804792060069735}. Best is trial 169 with value: 0.13873005082072956.\n",
      "\u001b[32m2025-09-20 10:12:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 185] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 10:12:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 185, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:12:28\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 185, Fold 1/5] RMSE: 0.1480\u001b[0m\n",
      "\u001b[32m2025-09-20 10:12:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 185, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:12:46\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 185, Fold 2/5] RMSE: 0.1393\u001b[0m\n",
      "\u001b[32m2025-09-20 10:12:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 185, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:13:05\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 185, Fold 3/5] RMSE: 0.1334\u001b[0m\n",
      "\u001b[32m2025-09-20 10:13:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 185, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:13:23\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 185, Fold 4/5] RMSE: 0.1526\u001b[0m\n",
      "\u001b[32m2025-09-20 10:13:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 185, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:13:41\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 185, Fold 5/5] RMSE: 0.1324\u001b[0m\n",
      "[I 2025-09-20 10:13:41,458] Trial 185 finished with value: 0.14113220022900336 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05681725287156621, 'max_depth': 8, 'subsample': 0.9346436233483258, 'colsample_bytree': 0.7920015935286954}. Best is trial 169 with value: 0.13873005082072956.\n",
      "\u001b[32m2025-09-20 10:13:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 186] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 10:13:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 186, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:13:59\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 186, Fold 1/5] RMSE: 0.1474\u001b[0m\n",
      "\u001b[32m2025-09-20 10:13:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 186, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:14:17\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 186, Fold 2/5] RMSE: 0.1365\u001b[0m\n",
      "\u001b[32m2025-09-20 10:14:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 186, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:14:35\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 186, Fold 3/5] RMSE: 0.1357\u001b[0m\n",
      "\u001b[32m2025-09-20 10:14:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 186, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:14:54\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 186, Fold 4/5] RMSE: 0.1498\u001b[0m\n",
      "\u001b[32m2025-09-20 10:14:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 186, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:15:12\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 186, Fold 5/5] RMSE: 0.1304\u001b[0m\n",
      "[I 2025-09-20 10:15:12,734] Trial 186 finished with value: 0.13993953125712869 and parameters: {'n_estimators': 1000, 'learning_rate': 0.0761746582628783, 'max_depth': 8, 'subsample': 0.9446082813166655, 'colsample_bytree': 0.771702806706016}. Best is trial 169 with value: 0.13873005082072956.\n",
      "\u001b[32m2025-09-20 10:15:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 187] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 10:15:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 187, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:15:31\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 187, Fold 1/5] RMSE: 0.1477\u001b[0m\n",
      "\u001b[32m2025-09-20 10:15:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 187, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:15:49\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 187, Fold 2/5] RMSE: 0.1388\u001b[0m\n",
      "\u001b[32m2025-09-20 10:15:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 187, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:16:07\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 187, Fold 3/5] RMSE: 0.1335\u001b[0m\n",
      "\u001b[32m2025-09-20 10:16:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 187, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:16:26\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 187, Fold 4/5] RMSE: 0.1516\u001b[0m\n",
      "\u001b[32m2025-09-20 10:16:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 187, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:16:44\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 187, Fold 5/5] RMSE: 0.1316\u001b[0m\n",
      "[I 2025-09-20 10:16:44,460] Trial 187 finished with value: 0.1406384602356771 and parameters: {'n_estimators': 1000, 'learning_rate': 0.06617749005434614, 'max_depth': 8, 'subsample': 0.920990922295926, 'colsample_bytree': 0.7833298406267508}. Best is trial 169 with value: 0.13873005082072956.\n",
      "\u001b[32m2025-09-20 10:16:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 188] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 10:16:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 188, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:17:02\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 188, Fold 1/5] RMSE: 0.1489\u001b[0m\n",
      "\u001b[32m2025-09-20 10:17:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 188, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:17:20\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 188, Fold 2/5] RMSE: 0.1386\u001b[0m\n",
      "\u001b[32m2025-09-20 10:17:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 188, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:17:39\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 188, Fold 3/5] RMSE: 0.1341\u001b[0m\n",
      "\u001b[32m2025-09-20 10:17:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 188, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:17:57\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 188, Fold 4/5] RMSE: 0.1517\u001b[0m\n",
      "\u001b[32m2025-09-20 10:17:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 188, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:18:15\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 188, Fold 5/5] RMSE: 0.1297\u001b[0m\n",
      "[I 2025-09-20 10:18:15,441] Trial 188 finished with value: 0.14059122972714308 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05913983331166129, 'max_depth': 8, 'subsample': 0.9378754491538911, 'colsample_bytree': 0.7989925184561155}. Best is trial 169 with value: 0.13873005082072956.\n",
      "\u001b[32m2025-09-20 10:18:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 189] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 10:18:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 189, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:18:34\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 189, Fold 1/5] RMSE: 0.1487\u001b[0m\n",
      "\u001b[32m2025-09-20 10:18:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 189, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:18:53\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 189, Fold 2/5] RMSE: 0.1364\u001b[0m\n",
      "\u001b[32m2025-09-20 10:18:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 189, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:19:11\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 189, Fold 3/5] RMSE: 0.1345\u001b[0m\n",
      "\u001b[32m2025-09-20 10:19:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 189, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:19:29\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 189, Fold 4/5] RMSE: 0.1519\u001b[0m\n",
      "\u001b[32m2025-09-20 10:19:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 189, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:19:48\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 189, Fold 5/5] RMSE: 0.1318\u001b[0m\n",
      "[I 2025-09-20 10:19:48,346] Trial 189 finished with value: 0.14065684407154516 and parameters: {'n_estimators': 1000, 'learning_rate': 0.08024070184888486, 'max_depth': 8, 'subsample': 0.9274082462224442, 'colsample_bytree': 0.7890361276397442}. Best is trial 169 with value: 0.13873005082072956.\n",
      "\u001b[32m2025-09-20 10:19:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 190] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 10:19:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 190, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:20:06\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 190, Fold 1/5] RMSE: 0.1475\u001b[0m\n",
      "\u001b[32m2025-09-20 10:20:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 190, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:20:24\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 190, Fold 2/5] RMSE: 0.1375\u001b[0m\n",
      "\u001b[32m2025-09-20 10:20:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 190, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:20:42\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 190, Fold 3/5] RMSE: 0.1343\u001b[0m\n",
      "\u001b[32m2025-09-20 10:20:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 190, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:21:00\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 190, Fold 4/5] RMSE: 0.1502\u001b[0m\n",
      "\u001b[32m2025-09-20 10:21:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 190, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:21:18\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 190, Fold 5/5] RMSE: 0.1296\u001b[0m\n",
      "[I 2025-09-20 10:21:18,482] Trial 190 finished with value: 0.13979891970535735 and parameters: {'n_estimators': 1000, 'learning_rate': 0.07296670147510109, 'max_depth': 8, 'subsample': 0.949250542355705, 'colsample_bytree': 0.7730306937338293}. Best is trial 169 with value: 0.13873005082072956.\n",
      "\u001b[32m2025-09-20 10:21:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 191] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 10:21:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 191, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:21:36\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 191, Fold 1/5] RMSE: 0.1492\u001b[0m\n",
      "\u001b[32m2025-09-20 10:21:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 191, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:21:54\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 191, Fold 2/5] RMSE: 0.1388\u001b[0m\n",
      "\u001b[32m2025-09-20 10:21:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 191, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:22:12\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 191, Fold 3/5] RMSE: 0.1351\u001b[0m\n",
      "\u001b[32m2025-09-20 10:22:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 191, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:22:30\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 191, Fold 4/5] RMSE: 0.1501\u001b[0m\n",
      "\u001b[32m2025-09-20 10:22:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 191, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:22:49\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 191, Fold 5/5] RMSE: 0.1305\u001b[0m\n",
      "[I 2025-09-20 10:22:49,180] Trial 191 finished with value: 0.14074119890333014 and parameters: {'n_estimators': 1000, 'learning_rate': 0.07420043403641176, 'max_depth': 8, 'subsample': 0.950299772200156, 'colsample_bytree': 0.77567049106744}. Best is trial 169 with value: 0.13873005082072956.\n",
      "\u001b[32m2025-09-20 10:22:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 192] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 10:22:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 192, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:23:07\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 192, Fold 1/5] RMSE: 0.1479\u001b[0m\n",
      "\u001b[32m2025-09-20 10:23:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 192, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:23:25\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 192, Fold 2/5] RMSE: 0.1387\u001b[0m\n",
      "\u001b[32m2025-09-20 10:23:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 192, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:23:43\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 192, Fold 3/5] RMSE: 0.1339\u001b[0m\n",
      "\u001b[32m2025-09-20 10:23:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 192, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:24:01\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 192, Fold 4/5] RMSE: 0.1508\u001b[0m\n",
      "\u001b[32m2025-09-20 10:24:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 192, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:24:20\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 192, Fold 5/5] RMSE: 0.1297\u001b[0m\n",
      "[I 2025-09-20 10:24:20,114] Trial 192 finished with value: 0.1402067849383488 and parameters: {'n_estimators': 1000, 'learning_rate': 0.06540512753076796, 'max_depth': 8, 'subsample': 0.944828560383923, 'colsample_bytree': 0.7819882240561974}. Best is trial 169 with value: 0.13873005082072956.\n",
      "\u001b[32m2025-09-20 10:24:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 193] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 10:24:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 193, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:24:38\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 193, Fold 1/5] RMSE: 0.1478\u001b[0m\n",
      "\u001b[32m2025-09-20 10:24:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 193, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:24:56\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 193, Fold 2/5] RMSE: 0.1404\u001b[0m\n",
      "\u001b[32m2025-09-20 10:24:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 193, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:25:14\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 193, Fold 3/5] RMSE: 0.1334\u001b[0m\n",
      "\u001b[32m2025-09-20 10:25:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 193, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:25:32\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 193, Fold 4/5] RMSE: 0.1492\u001b[0m\n",
      "\u001b[32m2025-09-20 10:25:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 193, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:25:50\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 193, Fold 5/5] RMSE: 0.1302\u001b[0m\n",
      "[I 2025-09-20 10:25:50,458] Trial 193 finished with value: 0.14017911979618994 and parameters: {'n_estimators': 1000, 'learning_rate': 0.07168317111721209, 'max_depth': 8, 'subsample': 0.9518937447655693, 'colsample_bytree': 0.7677321304192626}. Best is trial 169 with value: 0.13873005082072956.\n",
      "\u001b[32m2025-09-20 10:25:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 194] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 10:25:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 194, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:26:08\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 194, Fold 1/5] RMSE: 0.1484\u001b[0m\n",
      "\u001b[32m2025-09-20 10:26:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 194, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:26:26\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 194, Fold 2/5] RMSE: 0.1377\u001b[0m\n",
      "\u001b[32m2025-09-20 10:26:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 194, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:26:45\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 194, Fold 3/5] RMSE: 0.1331\u001b[0m\n",
      "\u001b[32m2025-09-20 10:26:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 194, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:27:03\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 194, Fold 4/5] RMSE: 0.1522\u001b[0m\n",
      "\u001b[32m2025-09-20 10:27:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 194, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:27:22\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 194, Fold 5/5] RMSE: 0.1297\u001b[0m\n",
      "[I 2025-09-20 10:27:22,069] Trial 194 finished with value: 0.14022486616338453 and parameters: {'n_estimators': 1000, 'learning_rate': 0.06190968470085041, 'max_depth': 8, 'subsample': 0.9366891442354567, 'colsample_bytree': 0.7937210669271813}. Best is trial 169 with value: 0.13873005082072956.\n",
      "\u001b[32m2025-09-20 10:27:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 195] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 10:27:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 195, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:27:40\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 195, Fold 1/5] RMSE: 0.1459\u001b[0m\n",
      "\u001b[32m2025-09-20 10:27:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 195, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:27:58\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 195, Fold 2/5] RMSE: 0.1389\u001b[0m\n",
      "\u001b[32m2025-09-20 10:27:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 195, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:28:16\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 195, Fold 3/5] RMSE: 0.1350\u001b[0m\n",
      "\u001b[32m2025-09-20 10:28:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 195, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:28:34\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 195, Fold 4/5] RMSE: 0.1500\u001b[0m\n",
      "\u001b[32m2025-09-20 10:28:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 195, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:28:52\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 195, Fold 5/5] RMSE: 0.1303\u001b[0m\n",
      "[I 2025-09-20 10:28:52,923] Trial 195 finished with value: 0.14001073265937353 and parameters: {'n_estimators': 1000, 'learning_rate': 0.07826704332524884, 'max_depth': 8, 'subsample': 0.9438630874808178, 'colsample_bytree': 0.7734659609985515}. Best is trial 169 with value: 0.13873005082072956.\n",
      "\u001b[32m2025-09-20 10:28:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 196] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 10:28:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 196, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:29:10\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 196, Fold 1/5] RMSE: 0.1493\u001b[0m\n",
      "\u001b[32m2025-09-20 10:29:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 196, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:29:28\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 196, Fold 2/5] RMSE: 0.1407\u001b[0m\n",
      "\u001b[32m2025-09-20 10:29:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 196, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:29:46\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 196, Fold 3/5] RMSE: 0.1345\u001b[0m\n",
      "\u001b[32m2025-09-20 10:29:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 196, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:30:04\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 196, Fold 4/5] RMSE: 0.1504\u001b[0m\n",
      "\u001b[32m2025-09-20 10:30:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 196, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:30:23\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 196, Fold 5/5] RMSE: 0.1294\u001b[0m\n",
      "[I 2025-09-20 10:30:23,149] Trial 196 finished with value: 0.1408361599802551 and parameters: {'n_estimators': 1000, 'learning_rate': 0.06718598925994575, 'max_depth': 8, 'subsample': 0.9497494747423222, 'colsample_bytree': 0.7874755178032747}. Best is trial 169 with value: 0.13873005082072956.\n",
      "\u001b[32m2025-09-20 10:30:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 197] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 10:30:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 197, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:30:42\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 197, Fold 1/5] RMSE: 0.1485\u001b[0m\n",
      "\u001b[32m2025-09-20 10:30:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 197, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:31:00\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 197, Fold 2/5] RMSE: 0.1379\u001b[0m\n",
      "\u001b[32m2025-09-20 10:31:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 197, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:31:18\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 197, Fold 3/5] RMSE: 0.1344\u001b[0m\n",
      "\u001b[32m2025-09-20 10:31:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 197, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:31:36\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 197, Fold 4/5] RMSE: 0.1506\u001b[0m\n",
      "\u001b[32m2025-09-20 10:31:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 197, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:31:55\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 197, Fold 5/5] RMSE: 0.1296\u001b[0m\n",
      "[I 2025-09-20 10:31:55,216] Trial 197 finished with value: 0.14017952499761308 and parameters: {'n_estimators': 1000, 'learning_rate': 0.07446432986869182, 'max_depth': 8, 'subsample': 0.9343564718044254, 'colsample_bytree': 0.7806350100770951}. Best is trial 169 with value: 0.13873005082072956.\n",
      "\u001b[32m2025-09-20 10:31:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 198] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 10:31:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 198, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:32:04\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 198, Fold 1/5] RMSE: 0.1549\u001b[0m\n",
      "\u001b[32m2025-09-20 10:32:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 198, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:32:13\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 198, Fold 2/5] RMSE: 0.1439\u001b[0m\n",
      "\u001b[32m2025-09-20 10:32:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 198, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:32:23\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 198, Fold 3/5] RMSE: 0.1414\u001b[0m\n",
      "\u001b[32m2025-09-20 10:32:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 198, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:32:32\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 198, Fold 4/5] RMSE: 0.1553\u001b[0m\n",
      "\u001b[32m2025-09-20 10:32:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 198, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:32:41\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 198, Fold 5/5] RMSE: 0.1377\u001b[0m\n",
      "[I 2025-09-20 10:32:41,535] Trial 198 finished with value: 0.14665087283240458 and parameters: {'n_estimators': 1000, 'learning_rate': 0.08294722425657293, 'max_depth': 6, 'subsample': 0.9549079310615288, 'colsample_bytree': 0.7664598341750216}. Best is trial 169 with value: 0.13873005082072956.\n",
      "\u001b[32m2025-09-20 10:32:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 199] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 10:32:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 199, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:32:57\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 199, Fold 1/5] RMSE: 0.1517\u001b[0m\n",
      "\u001b[32m2025-09-20 10:32:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 199, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:33:14\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 199, Fold 2/5] RMSE: 0.1418\u001b[0m\n",
      "\u001b[32m2025-09-20 10:33:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 199, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:33:30\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 199, Fold 3/5] RMSE: 0.1365\u001b[0m\n",
      "\u001b[32m2025-09-20 10:33:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 199, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:33:46\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 199, Fold 4/5] RMSE: 0.1565\u001b[0m\n",
      "\u001b[32m2025-09-20 10:33:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 199, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:34:02\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 199, Fold 5/5] RMSE: 0.1345\u001b[0m\n",
      "[I 2025-09-20 10:34:02,602] Trial 199 finished with value: 0.14421964174069934 and parameters: {'n_estimators': 900, 'learning_rate': 0.03704313067018571, 'max_depth': 8, 'subsample': 0.9411698360915323, 'colsample_bytree': 0.7996966995823535}. Best is trial 169 with value: 0.13873005082072956.\n",
      "\u001b[32m2025-09-20 10:34:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 200] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 10:34:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 200, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:34:20\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 200, Fold 1/5] RMSE: 0.1479\u001b[0m\n",
      "\u001b[32m2025-09-20 10:34:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 200, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:34:39\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 200, Fold 2/5] RMSE: 0.1393\u001b[0m\n",
      "\u001b[32m2025-09-20 10:34:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 200, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:34:58\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 200, Fold 3/5] RMSE: 0.1345\u001b[0m\n",
      "\u001b[32m2025-09-20 10:34:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 200, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:35:16\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 200, Fold 4/5] RMSE: 0.1503\u001b[0m\n",
      "\u001b[32m2025-09-20 10:35:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 200, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:35:34\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 200, Fold 5/5] RMSE: 0.1300\u001b[0m\n",
      "[I 2025-09-20 10:35:34,406] Trial 200 finished with value: 0.14038625822165413 and parameters: {'n_estimators': 1000, 'learning_rate': 0.06946965603873599, 'max_depth': 8, 'subsample': 0.9253893676260594, 'colsample_bytree': 0.7754148590005683}. Best is trial 169 with value: 0.13873005082072956.\n",
      "\u001b[32m2025-09-20 10:35:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mTraining and logging the final champion model...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:35:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- Performing Deep Evaluation for Champion XGBoost Model ---\u001b[0m\n",
      "\u001b[32m2025-09-20 10:35:43\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mTest Set Performance Logged (Technical): RMSE=0.1225, R2=0.9539\u001b[0m\n",
      "\u001b[32m2025-09-20 10:35:43\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mTest Set Performance Logged (Business): Accuracy (±0.25)=96.07%, MAPE=1.58%\u001b[0m\n",
      "\u001b[32m2025-09-20 10:35:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mGenerating and logging evaluation plots...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:35:43\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mAll evaluation artifacts have been logged to MLflow.\u001b[0m\n",
      "\u001b[32m2025-09-20 10:35:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- Logging XGBoost-specific artifacts for XGBoost ---\u001b[0m\n",
      "\u001b[32m2025-09-20 10:35:43\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mLogged feature importance plot for type: weight\u001b[0m\n",
      "\u001b[32m2025-09-20 10:35:43\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mLogged feature importance plot for type: gain\u001b[0m\n",
      "\u001b[32m2025-09-20 10:35:44\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mLogged feature importance plot for type: cover\u001b[0m\n",
      "\u001b[32m2025-09-20 10:35:44\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mLogged feature importance plot for type: total_gain\u001b[0m\n",
      "\u001b[32m2025-09-20 10:35:44\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mLogged feature importance plot for type: total_cover\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dot: graph is too large for cairo-renderer bitmaps. Scaling by 0.537243 to fit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-20 10:35:46\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mLogged sample decision tree plot.\u001b[0m\n",
      "\u001b[32m2025-09-20 10:35:46\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mLogged interactive SVG decision tree plot.\u001b[0m\n",
      "\u001b[32m2025-09-20 10:35:46\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mLogged XGBoost model configuration.\u001b[0m\n",
      "\u001b[32m2025-09-20 10:35:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mLogging all available Optuna visualization plots...\u001b[0m\n",
      "\u001b[32m2025-09-20 10:35:47\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[33m\u001b[1mCould not generate Optuna plot 'plot_hypervolume_history'. Skipping. Error: plot_hypervolume_history() missing 1 required positional argument: 'reference_point'\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16951/3603380527.py:86: ExperimentalWarning:\n",
      "\n",
      "optuna.visualization._hypervolume_history.plot_hypervolume_history is experimental (supported from v3.3.0). The interface can change in the future.\n",
      "\n",
      "[W 2025-09-20 10:35:47,098] You need to set up the pruning feature to utilize `plot_intermediate_values()`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-20 10:35:48\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[33m\u001b[1mCould not generate Optuna plot 'plot_pareto_front'. Skipping. Error: `plot_pareto_front` function only supports 2 or 3 objective studies when using `targets` is `None`. Please use `targets` if your objective studies have more than 3 objectives.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16951/3603380527.py:86: ExperimentalWarning:\n",
      "\n",
      "optuna.visualization._terminator_improvement.plot_terminator_improvement is experimental (supported from v3.2.0). The interface can change in the future.\n",
      "\n",
      "/home/puneet/tools/miniconda3/envs/newAge/lib/python3.10/site-packages/optuna/visualization/_terminator_improvement.py:93: ExperimentalWarning:\n",
      "\n",
      "RegretBoundEvaluator is experimental (supported from v3.2.0). The interface can change in the future.\n",
      "\n",
      "/home/puneet/tools/miniconda3/envs/newAge/lib/python3.10/site-packages/optuna/visualization/_terminator_improvement.py:98: ExperimentalWarning:\n",
      "\n",
      "CrossValidationErrorEvaluator is experimental (supported from v3.2.0). The interface can change in the future.\n",
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 201/201 [00:06<00:00, 31.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-20 10:35:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mWrapping model in custom PyFunc and logging...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/puneet/tools/miniconda3/envs/newAge/lib/python3.10/site-packages/mlflow/types/utils.py:452: UserWarning:\n",
      "\n",
      "Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "\n",
      "2025/09/20 10:35:57 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "/home/puneet/tools/miniconda3/envs/newAge/lib/python3.10/site-packages/mlflow/pyfunc/__init__.py:3288: UserWarning:\n",
      "\n",
      "\u001b[1;33mAn input example was not provided when logging the model. To ensure the model signature functions correctly, specify the `input_example` parameter. See https://mlflow.org/docs/latest/model/signatures.html#model-input-example for more details about the benefits of using input_example.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-20 10:35:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- Run for XGBoost complete. Check the MLflow UI and Optuna Dashboard. ---\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'XGBoost_Zomato_Champion' already exists. Creating a new version of this model...\n",
      "Created version '9' of model 'XGBoost_Zomato_Champion'.\n"
     ]
    }
   ],
   "source": [
    "# # ===================================================================\n",
    "# # CELL 3: Execution - Train XGBoost GBT (Full Run)\n",
    "# # ===================================================================\n",
    "# # --- Define the search space for XGBoost ---\n",
    "def xgb_search_space(trial):\n",
    "    return {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 200, 1000, step=100),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.02, 0.2, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 8),\n",
    "        'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 1.0),\n",
    "        'tree_method': 'hist', 'device': 'cuda', 'random_state': 42\n",
    "    }\n",
    "\n",
    "# # --- LAUNCH THE DEFINITIVE EXPERIMENT FOR XGBOOST ---\n",
    "# # Delete the old study for a clean, long run\n",
    "# db_file_path = \"optuna_studies/XGBoost_study.db\"\n",
    "# if os.path.exists(db_file_path):\n",
    "#     os.remove(db_file_path)\n",
    "#     logger.info(f\"Removed old Optuna database at '{db_file_path}' for a fresh start.\")\n",
    "\n",
    "study_xgb = run_optimization_study_flexible(\n",
    "    model_name=\"XGBoost\", \n",
    "    model_class=xgb.XGBRegressor,\n",
    "    param_search_space=xgb_search_space,\n",
    "    X_train=X_train, y_train=y_train, \n",
    "    X_test=X_test, y_test=y_test,\n",
    "    preprocessor=preprocessor,\n",
    "    n_trials=100  # <<< The full, overnight run\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c1a1e2-b000-43cf-a933-fd754b3b40ed",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ea341e1e-dff5-4610-a262-cf7a6d1a3269",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-20T08:15:21.250951Z",
     "iopub.status.busy": "2025-09-20T08:15:21.249145Z",
     "iopub.status.idle": "2025-09-20T12:42:23.860851Z",
     "shell.execute_reply": "2025-09-20T12:42:23.848945Z",
     "shell.execute_reply.started": "2025-09-20T08:15:21.250814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-20 13:45:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- Defining feature sets for CatBoost run ---\u001b[0m\n",
      "\u001b[32m2025-09-20 13:45:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- Building a preprocessor compatible with CatBoost ---\u001b[0m\n",
      "\u001b[32m2025-09-20 13:45:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- Preparing data for CatBoost ---\u001b[0m\n",
      "\u001b[32m2025-09-20 13:45:21\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mData prepared for CatBoost. Dtype of 'location': object\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-20 13:45:21,951] Using an existing study with name 'Zomato_CatBoost_Optimization' instead of creating a new one.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0c89e7351f444168f7f8c49836c07ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-20 13:45:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 10] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 13:45:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 10, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 13:45:45\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 10, Fold 1/5] RMSE: 0.1692\u001b[0m\n",
      "\u001b[32m2025-09-20 13:45:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 10, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 13:46:04\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 10, Fold 2/5] RMSE: 0.1601\u001b[0m\n",
      "\u001b[32m2025-09-20 13:46:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 10, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 13:46:24\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 10, Fold 3/5] RMSE: 0.1554\u001b[0m\n",
      "\u001b[32m2025-09-20 13:46:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 10, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 13:46:44\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 10, Fold 4/5] RMSE: 0.1693\u001b[0m\n",
      "\u001b[32m2025-09-20 13:46:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 10, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 13:47:04\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 10, Fold 5/5] RMSE: 0.1520\u001b[0m\n",
      "[I 2025-09-20 13:47:04,613] Trial 10 finished with value: 0.16119071900943038 and parameters: {'iterations': 400, 'learning_rate': 0.1384586853179249, 'depth': 10, 'l2_leaf_reg': 6.631863886403775, 'random_strength': 3.7378991265271605e-06, 'bagging_temperature': 0.5290680705873223}. Best is trial 10 with value: 0.16119071900943038.\n",
      "\u001b[32m2025-09-20 13:47:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 11] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 13:47:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 11, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 13:49:25\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 11, Fold 1/5] RMSE: 0.1960\u001b[0m\n",
      "\u001b[32m2025-09-20 13:49:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 11, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 13:51:50\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 11, Fold 2/5] RMSE: 0.1889\u001b[0m\n",
      "\u001b[32m2025-09-20 13:51:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 11, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 13:54:13\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 11, Fold 3/5] RMSE: 0.1864\u001b[0m\n",
      "\u001b[32m2025-09-20 13:54:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 11, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 13:56:40\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 11, Fold 4/5] RMSE: 0.2079\u001b[0m\n",
      "\u001b[32m2025-09-20 13:56:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 11, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 13:59:12\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 11, Fold 5/5] RMSE: 0.1826\u001b[0m\n",
      "[I 2025-09-20 13:59:12,634] Trial 11 finished with value: 0.19237469944024654 and parameters: {'iterations': 1600, 'learning_rate': 0.041389171232204675, 'depth': 9, 'l2_leaf_reg': 2.396513192455893, 'random_strength': 0.010965187439370583, 'bagging_temperature': 0.14301713629552792}. Best is trial 10 with value: 0.16119071900943038.\n",
      "\u001b[32m2025-09-20 13:59:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 12] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 13:59:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 12, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 14:00:41\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 12, Fold 1/5] RMSE: 0.1885\u001b[0m\n",
      "\u001b[32m2025-09-20 14:00:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 12, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 14:02:08\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 12, Fold 2/5] RMSE: 0.1835\u001b[0m\n",
      "\u001b[32m2025-09-20 14:02:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 12, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 14:03:40\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 12, Fold 3/5] RMSE: 0.1762\u001b[0m\n",
      "\u001b[32m2025-09-20 14:03:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 12, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 14:05:11\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 12, Fold 4/5] RMSE: 0.1946\u001b[0m\n",
      "\u001b[32m2025-09-20 14:05:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 12, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 14:06:41\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 12, Fold 5/5] RMSE: 0.1724\u001b[0m\n",
      "[I 2025-09-20 14:06:41,441] Trial 12 finished with value: 0.18302013889266672 and parameters: {'iterations': 600, 'learning_rate': 0.1700568399596776, 'depth': 10, 'l2_leaf_reg': 8.896907938910688, 'random_strength': 5.001983922446269e-08, 'bagging_temperature': 0.552138991601766}. Best is trial 10 with value: 0.16119071900943038.\n",
      "\u001b[32m2025-09-20 14:06:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 13] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 14:06:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 13, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 14:07:47\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 13, Fold 1/5] RMSE: 0.2193\u001b[0m\n",
      "\u001b[32m2025-09-20 14:07:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 13, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 14:08:55\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 13, Fold 2/5] RMSE: 0.2143\u001b[0m\n",
      "\u001b[32m2025-09-20 14:08:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 13, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 14:10:03\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 13, Fold 3/5] RMSE: 0.2113\u001b[0m\n",
      "\u001b[32m2025-09-20 14:10:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 13, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 14:11:17\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 13, Fold 4/5] RMSE: 0.2238\u001b[0m\n",
      "\u001b[32m2025-09-20 14:11:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 13, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 14:12:29\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 13, Fold 5/5] RMSE: 0.2096\u001b[0m\n",
      "[I 2025-09-20 14:12:29,966] Trial 13 finished with value: 0.21567439459356916 and parameters: {'iterations': 1000, 'learning_rate': 0.037248643648928, 'depth': 8, 'l2_leaf_reg': 2.290474596394421, 'random_strength': 3.8327356631573055e-08, 'bagging_temperature': 0.8797939681816836}. Best is trial 10 with value: 0.16119071900943038.\n",
      "\u001b[32m2025-09-20 14:12:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 14] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 14:12:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 14, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 14:13:10\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 14, Fold 1/5] RMSE: 0.2600\u001b[0m\n",
      "\u001b[32m2025-09-20 14:13:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 14, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 14:13:49\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 14, Fold 2/5] RMSE: 0.2543\u001b[0m\n",
      "\u001b[32m2025-09-20 14:13:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 14, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 14:14:30\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 14, Fold 3/5] RMSE: 0.2531\u001b[0m\n",
      "\u001b[32m2025-09-20 14:14:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 14, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 14:15:10\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 14, Fold 4/5] RMSE: 0.2655\u001b[0m\n",
      "\u001b[32m2025-09-20 14:15:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 14, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 14:15:50\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 14, Fold 5/5] RMSE: 0.2438\u001b[0m\n",
      "[I 2025-09-20 14:15:50,477] Trial 14 finished with value: 0.25533131485015403 and parameters: {'iterations': 1600, 'learning_rate': 0.037518679353473736, 'depth': 4, 'l2_leaf_reg': 1.4196195549774793, 'random_strength': 0.0021448839053372624, 'bagging_temperature': 0.16328376668215017}. Best is trial 10 with value: 0.16119071900943038.\n",
      "\u001b[32m2025-09-20 14:15:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 15] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 14:15:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 15, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 14:16:00\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 15, Fold 1/5] RMSE: 0.2388\u001b[0m\n",
      "\u001b[32m2025-09-20 14:16:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 15, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 14:16:10\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 15, Fold 2/5] RMSE: 0.2290\u001b[0m\n",
      "\u001b[32m2025-09-20 14:16:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 15, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 14:16:20\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 15, Fold 3/5] RMSE: 0.2270\u001b[0m\n",
      "\u001b[32m2025-09-20 14:16:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 15, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 14:16:30\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 15, Fold 4/5] RMSE: 0.2409\u001b[0m\n",
      "\u001b[32m2025-09-20 14:16:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 15, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 14:16:40\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 15, Fold 5/5] RMSE: 0.2263\u001b[0m\n",
      "[I 2025-09-20 14:16:40,662] Trial 15 finished with value: 0.23241173187839675 and parameters: {'iterations': 400, 'learning_rate': 0.0936024902962745, 'depth': 6, 'l2_leaf_reg': 5.467233119104276, 'random_strength': 2.823877289934689e-09, 'bagging_temperature': 0.3067553341890075}. Best is trial 10 with value: 0.16119071900943038.\n",
      "\u001b[32m2025-09-20 14:16:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 16] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 14:16:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 16, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 14:19:44\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 16, Fold 1/5] RMSE: 0.1774\u001b[0m\n",
      "\u001b[32m2025-09-20 14:19:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 16, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 14:22:51\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 16, Fold 2/5] RMSE: 0.1723\u001b[0m\n",
      "\u001b[32m2025-09-20 14:22:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 16, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 14:25:59\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 16, Fold 3/5] RMSE: 0.1617\u001b[0m\n",
      "\u001b[32m2025-09-20 14:25:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 16, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 14:29:11\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 16, Fold 4/5] RMSE: 0.1786\u001b[0m\n",
      "\u001b[32m2025-09-20 14:29:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 16, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 14:32:23\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 16, Fold 5/5] RMSE: 0.1605\u001b[0m\n",
      "[I 2025-09-20 14:32:23,599] Trial 16 finished with value: 0.17011015705215676 and parameters: {'iterations': 2000, 'learning_rate': 0.10809645725638181, 'depth': 9, 'l2_leaf_reg': 3.9766517407957402, 'random_strength': 1.7240504630527228e-06, 'bagging_temperature': 0.3621443944619188}. Best is trial 10 with value: 0.16119071900943038.\n",
      "\u001b[32m2025-09-20 14:32:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 17] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 14:32:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 17, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 14:37:17\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 17, Fold 1/5] RMSE: 0.1744\u001b[0m\n",
      "\u001b[32m2025-09-20 14:37:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 17, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 14:42:20\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 17, Fold 2/5] RMSE: 0.1656\u001b[0m\n",
      "\u001b[32m2025-09-20 14:42:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 17, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 14:47:06\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 17, Fold 3/5] RMSE: 0.1602\u001b[0m\n",
      "\u001b[32m2025-09-20 14:47:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 17, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 14:52:10\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 17, Fold 4/5] RMSE: 0.1737\u001b[0m\n",
      "\u001b[32m2025-09-20 14:52:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 17, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 14:57:13\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 17, Fold 5/5] RMSE: 0.1544\u001b[0m\n",
      "[I 2025-09-20 14:57:13,461] Trial 17 finished with value: 0.16567515681370398 and parameters: {'iterations': 2000, 'learning_rate': 0.10908877856242492, 'depth': 10, 'l2_leaf_reg': 4.32768553998263, 'random_strength': 1.677390371056219e-06, 'bagging_temperature': 0.3287528462124263}. Best is trial 10 with value: 0.16119071900943038.\n",
      "\u001b[32m2025-09-20 14:57:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 18] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 14:57:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 18, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 14:57:33\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 18, Fold 1/5] RMSE: 0.1835\u001b[0m\n",
      "\u001b[32m2025-09-20 14:57:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 18, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 14:57:52\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 18, Fold 2/5] RMSE: 0.1735\u001b[0m\n",
      "\u001b[32m2025-09-20 14:57:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 18, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 14:58:12\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 18, Fold 3/5] RMSE: 0.1691\u001b[0m\n",
      "\u001b[32m2025-09-20 14:58:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 18, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 14:58:32\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 18, Fold 4/5] RMSE: 0.1813\u001b[0m\n",
      "\u001b[32m2025-09-20 14:58:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 18, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 14:58:53\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 18, Fold 5/5] RMSE: 0.1649\u001b[0m\n",
      "[I 2025-09-20 14:58:53,071] Trial 18 finished with value: 0.17446043303370556 and parameters: {'iterations': 400, 'learning_rate': 0.08805401772324646, 'depth': 10, 'l2_leaf_reg': 4.698865477025649, 'random_strength': 0.00021097674460261178, 'bagging_temperature': 0.7478910302799157}. Best is trial 10 with value: 0.16119071900943038.\n",
      "\u001b[32m2025-09-20 14:58:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 19] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 14:58:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 19, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 15:03:50\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 19, Fold 1/5] RMSE: 0.1747\u001b[0m\n",
      "\u001b[32m2025-09-20 15:03:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 19, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 15:08:47\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 19, Fold 2/5] RMSE: 0.1660\u001b[0m\n",
      "\u001b[32m2025-09-20 15:08:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 19, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 15:13:40\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 19, Fold 3/5] RMSE: 0.1581\u001b[0m\n",
      "\u001b[32m2025-09-20 15:13:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 19, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 15:18:37\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 19, Fold 4/5] RMSE: 0.1733\u001b[0m\n",
      "\u001b[32m2025-09-20 15:18:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 19, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 15:23:32\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 19, Fold 5/5] RMSE: 0.1541\u001b[0m\n",
      "[I 2025-09-20 15:23:32,925] Trial 19 finished with value: 0.16522372598592605 and parameters: {'iterations': 2000, 'learning_rate': 0.12442737023162205, 'depth': 10, 'l2_leaf_reg': 6.221311003634029, 'random_strength': 1.2548945018945574e-07, 'bagging_temperature': 0.2882390642797013}. Best is trial 10 with value: 0.16119071900943038.\n",
      "\u001b[32m2025-09-20 15:23:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 20] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 15:23:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 20, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 15:24:14\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 20, Fold 1/5] RMSE: 0.2641\u001b[0m\n",
      "\u001b[32m2025-09-20 15:24:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 20, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 15:24:54\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 20, Fold 2/5] RMSE: 0.2554\u001b[0m\n",
      "\u001b[32m2025-09-20 15:24:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 20, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 15:25:35\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 20, Fold 3/5] RMSE: 0.2542\u001b[0m\n",
      "\u001b[32m2025-09-20 15:25:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 20, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 15:26:16\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 20, Fold 4/5] RMSE: 0.2677\u001b[0m\n",
      "\u001b[32m2025-09-20 15:26:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 20, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 15:26:57\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 20, Fold 5/5] RMSE: 0.2538\u001b[0m\n",
      "[I 2025-09-20 15:26:57,184] Trial 20 finished with value: 0.25906696459677975 and parameters: {'iterations': 800, 'learning_rate': 0.02159008505735049, 'depth': 7, 'l2_leaf_reg': 6.722121067669658, 'random_strength': 1.2285222192461227e-09, 'bagging_temperature': 0.9845137997436362}. Best is trial 10 with value: 0.16119071900943038.\n",
      "\u001b[32m2025-09-20 15:26:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 21] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 15:26:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 21, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 15:28:02\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 21, Fold 1/5] RMSE: 0.1971\u001b[0m\n",
      "\u001b[32m2025-09-20 15:28:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 21, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 15:29:07\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 21, Fold 2/5] RMSE: 0.1894\u001b[0m\n",
      "\u001b[32m2025-09-20 15:29:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 21, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 15:30:11\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 21, Fold 3/5] RMSE: 0.1849\u001b[0m\n",
      "\u001b[32m2025-09-20 15:30:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 21, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 15:31:19\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 21, Fold 4/5] RMSE: 0.1967\u001b[0m\n",
      "\u001b[32m2025-09-20 15:31:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 21, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 15:32:27\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 21, Fold 5/5] RMSE: 0.1787\u001b[0m\n",
      "[I 2025-09-20 15:32:27,257] Trial 21 finished with value: 0.18937068477715505 and parameters: {'iterations': 1000, 'learning_rate': 0.12680556028125153, 'depth': 8, 'l2_leaf_reg': 9.020929728940894, 'random_strength': 9.078388393339214e-08, 'bagging_temperature': 0.22581623504251352}. Best is trial 10 with value: 0.16119071900943038.\n",
      "\u001b[32m2025-09-20 15:32:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 22] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 15:32:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 22, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 15:33:12\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 22, Fold 1/5] RMSE: 0.2222\u001b[0m\n",
      "\u001b[32m2025-09-20 15:33:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 22, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 15:33:56\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 22, Fold 2/5] RMSE: 0.2138\u001b[0m\n",
      "\u001b[32m2025-09-20 15:33:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 22, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 15:34:42\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 22, Fold 3/5] RMSE: 0.2154\u001b[0m\n",
      "\u001b[32m2025-09-20 15:34:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 22, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 15:35:28\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 22, Fold 4/5] RMSE: 0.2251\u001b[0m\n",
      "\u001b[32m2025-09-20 15:35:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 22, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 15:36:14\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 22, Fold 5/5] RMSE: 0.2067\u001b[0m\n",
      "[I 2025-09-20 15:36:14,173] Trial 22 finished with value: 0.21662284524428527 and parameters: {'iterations': 1200, 'learning_rate': 0.07363305215718446, 'depth': 6, 'l2_leaf_reg': 6.181787665035677, 'random_strength': 5.850561998528489e-05, 'bagging_temperature': 0.6491447389211882}. Best is trial 10 with value: 0.16119071900943038.\n",
      "\u001b[32m2025-09-20 15:36:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 23] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 15:36:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 23, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 15:36:54\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 23, Fold 1/5] RMSE: 0.1996\u001b[0m\n",
      "\u001b[32m2025-09-20 15:36:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 23, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 15:37:34\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 23, Fold 2/5] RMSE: 0.1908\u001b[0m\n",
      "\u001b[32m2025-09-20 15:37:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 23, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 15:38:13\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 23, Fold 3/5] RMSE: 0.1884\u001b[0m\n",
      "\u001b[32m2025-09-20 15:38:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 23, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 15:38:56\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 23, Fold 4/5] RMSE: 0.1985\u001b[0m\n",
      "\u001b[32m2025-09-20 15:38:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 23, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 15:39:36\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 23, Fold 5/5] RMSE: 0.1825\u001b[0m\n",
      "[I 2025-09-20 15:39:36,564] Trial 23 finished with value: 0.19195343977440954 and parameters: {'iterations': 600, 'learning_rate': 0.14890058878523887, 'depth': 8, 'l2_leaf_reg': 3.2144334042074525, 'random_strength': 1.1565431789026237e-07, 'bagging_temperature': 0.42992064125381196}. Best is trial 10 with value: 0.16119071900943038.\n",
      "\u001b[32m2025-09-20 15:39:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 24] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 15:39:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 24, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 15:44:02\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 24, Fold 1/5] RMSE: 0.1771\u001b[0m\n",
      "\u001b[32m2025-09-20 15:44:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 24, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 15:48:22\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 24, Fold 2/5] RMSE: 0.1670\u001b[0m\n",
      "\u001b[32m2025-09-20 15:48:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 24, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 15:52:46\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 24, Fold 3/5] RMSE: 0.1573\u001b[0m\n",
      "\u001b[32m2025-09-20 15:52:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 24, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 15:57:08\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 24, Fold 4/5] RMSE: 0.1728\u001b[0m\n",
      "\u001b[32m2025-09-20 15:57:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 24, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 16:01:38\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 24, Fold 5/5] RMSE: 0.1532\u001b[0m\n",
      "[I 2025-09-20 16:01:38,707] Trial 24 finished with value: 0.16550069087385155 and parameters: {'iterations': 1800, 'learning_rate': 0.19398628146157357, 'depth': 10, 'l2_leaf_reg': 9.802531660375898, 'random_strength': 1.6946376639652297e-05, 'bagging_temperature': 0.035384003347460835}. Best is trial 10 with value: 0.16119071900943038.\n",
      "\u001b[32m2025-09-20 16:01:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 25] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 16:01:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 25, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 16:03:28\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 25, Fold 1/5] RMSE: 0.1970\u001b[0m\n",
      "\u001b[32m2025-09-20 16:03:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 25, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 16:05:16\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 25, Fold 2/5] RMSE: 0.1945\u001b[0m\n",
      "\u001b[32m2025-09-20 16:05:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 25, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 16:07:10\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 25, Fold 3/5] RMSE: 0.1863\u001b[0m\n",
      "\u001b[32m2025-09-20 16:07:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 25, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 16:09:06\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 25, Fold 4/5] RMSE: 0.1976\u001b[0m\n",
      "\u001b[32m2025-09-20 16:09:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 25, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 16:11:05\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 25, Fold 5/5] RMSE: 0.1807\u001b[0m\n",
      "[I 2025-09-20 16:11:05,324] Trial 25 finished with value: 0.19121274453560044 and parameters: {'iterations': 1200, 'learning_rate': 0.053330348228547445, 'depth': 9, 'l2_leaf_reg': 3.1615221830076106, 'random_strength': 9.860590149047995e-09, 'bagging_temperature': 0.24274145887940535}. Best is trial 10 with value: 0.16119071900943038.\n",
      "\u001b[32m2025-09-20 16:11:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 26] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 16:11:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 26, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 16:15:46\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 26, Fold 1/5] RMSE: 0.1726\u001b[0m\n",
      "\u001b[32m2025-09-20 16:15:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 26, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 16:20:10\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 26, Fold 2/5] RMSE: 0.1664\u001b[0m\n",
      "\u001b[32m2025-09-20 16:20:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 26, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 16:24:20\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 26, Fold 3/5] RMSE: 0.1586\u001b[0m\n",
      "\u001b[32m2025-09-20 16:24:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 26, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 16:28:46\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 26, Fold 4/5] RMSE: 0.1739\u001b[0m\n",
      "\u001b[32m2025-09-20 16:28:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 26, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 16:33:38\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 26, Fold 5/5] RMSE: 0.1549\u001b[0m\n",
      "[I 2025-09-20 16:33:38,326] Trial 26 finished with value: 0.1652960335707805 and parameters: {'iterations': 1800, 'learning_rate': 0.1837340901339411, 'depth': 10, 'l2_leaf_reg': 9.750130366453991, 'random_strength': 5.491347223022827e-06, 'bagging_temperature': 0.10158668332202471}. Best is trial 10 with value: 0.16119071900943038.\n",
      "\u001b[32m2025-09-20 16:33:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 27] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 16:33:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 27, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 16:38:27\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 27, Fold 1/5] RMSE: 0.1732\u001b[0m\n",
      "\u001b[32m2025-09-20 16:38:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 27, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 16:42:57\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 27, Fold 2/5] RMSE: 0.1690\u001b[0m\n",
      "\u001b[32m2025-09-20 16:42:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 27, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 16:47:10\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 27, Fold 3/5] RMSE: 0.1621\u001b[0m\n",
      "\u001b[32m2025-09-20 16:47:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 27, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 16:51:42\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 27, Fold 4/5] RMSE: 0.1706\u001b[0m\n",
      "\u001b[32m2025-09-20 16:51:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 27, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 16:56:24\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 27, Fold 5/5] RMSE: 0.1536\u001b[0m\n",
      "[I 2025-09-20 16:56:24,637] Trial 27 finished with value: 0.1657090525393286 and parameters: {'iterations': 1800, 'learning_rate': 0.15904438160998524, 'depth': 10, 'l2_leaf_reg': 7.682031513338736, 'random_strength': 3.1054522864468094e-07, 'bagging_temperature': 0.11712620885607777}. Best is trial 10 with value: 0.16119071900943038.\n",
      "\u001b[32m2025-09-20 16:56:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 28] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 16:56:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 28, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 16:59:58\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 28, Fold 1/5] RMSE: 0.1769\u001b[0m\n",
      "\u001b[32m2025-09-20 16:59:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 28, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 17:03:33\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 28, Fold 2/5] RMSE: 0.1688\u001b[0m\n",
      "\u001b[32m2025-09-20 17:03:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 28, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 17:06:56\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 28, Fold 3/5] RMSE: 0.1589\u001b[0m\n",
      "\u001b[32m2025-09-20 17:06:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 28, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 17:10:12\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 28, Fold 4/5] RMSE: 0.1813\u001b[0m\n",
      "\u001b[32m2025-09-20 17:10:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 28, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 17:13:45\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 28, Fold 5/5] RMSE: 0.1592\u001b[0m\n",
      "[I 2025-09-20 17:13:45,575] Trial 28 finished with value: 0.16900623999082512 and parameters: {'iterations': 2000, 'learning_rate': 0.13116670409408546, 'depth': 9, 'l2_leaf_reg': 5.673930431732229, 'random_strength': 0.0005177544310607258, 'bagging_temperature': 0.24704219697809096}. Best is trial 10 with value: 0.16119071900943038.\n",
      "\u001b[32m2025-09-20 17:13:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 29] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 17:13:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 29, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 17:17:55\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 29, Fold 1/5] RMSE: 0.1783\u001b[0m\n",
      "\u001b[32m2025-09-20 17:17:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 29, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 17:21:54\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 29, Fold 2/5] RMSE: 0.1725\u001b[0m\n",
      "\u001b[32m2025-09-20 17:21:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 29, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 17:25:49\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 29, Fold 3/5] RMSE: 0.1625\u001b[0m\n",
      "\u001b[32m2025-09-20 17:25:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 29, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 17:29:47\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 29, Fold 4/5] RMSE: 0.1784\u001b[0m\n",
      "\u001b[32m2025-09-20 17:29:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 29, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 17:33:52\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 29, Fold 5/5] RMSE: 0.1611\u001b[0m\n",
      "[I 2025-09-20 17:33:52,364] Trial 29 finished with value: 0.17056958583198942 and parameters: {'iterations': 1600, 'learning_rate': 0.11293671988450583, 'depth': 10, 'l2_leaf_reg': 7.941840919223233, 'random_strength': 1.0955741014261603e-05, 'bagging_temperature': 0.4142741889794161}. Best is trial 10 with value: 0.16119071900943038.\n",
      "\u001b[32m2025-09-20 17:33:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 30] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 17:33:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 30, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 17:36:33\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 30, Fold 1/5] RMSE: 0.1839\u001b[0m\n",
      "\u001b[32m2025-09-20 17:36:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 30, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 17:39:22\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 30, Fold 2/5] RMSE: 0.1785\u001b[0m\n",
      "\u001b[32m2025-09-20 17:39:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 30, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 17:42:15\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 30, Fold 3/5] RMSE: 0.1710\u001b[0m\n",
      "\u001b[32m2025-09-20 17:42:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 30, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 17:45:08\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 30, Fold 4/5] RMSE: 0.1872\u001b[0m\n",
      "\u001b[32m2025-09-20 17:45:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 30, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 17:48:07\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 30, Fold 5/5] RMSE: 0.1716\u001b[0m\n",
      "[I 2025-09-20 17:48:07,206] Trial 30 finished with value: 0.17844366668644063 and parameters: {'iterations': 1800, 'learning_rate': 0.08357733302505378, 'depth': 9, 'l2_leaf_reg': 5.3758008607151355, 'random_strength': 6.112313969688988e-07, 'bagging_temperature': 0.0033087456834268447}. Best is trial 10 with value: 0.16119071900943038.\n",
      "\u001b[32m2025-09-20 17:48:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 31] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 17:48:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 31, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 17:49:43\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 31, Fold 1/5] RMSE: 0.1852\u001b[0m\n",
      "\u001b[32m2025-09-20 17:49:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 31, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 17:51:19\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 31, Fold 2/5] RMSE: 0.1779\u001b[0m\n",
      "\u001b[32m2025-09-20 17:51:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 31, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 17:52:58\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 31, Fold 3/5] RMSE: 0.1730\u001b[0m\n",
      "\u001b[32m2025-09-20 17:52:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 31, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 17:54:33\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 31, Fold 4/5] RMSE: 0.1856\u001b[0m\n",
      "\u001b[32m2025-09-20 17:54:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 31, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 17:56:16\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 31, Fold 5/5] RMSE: 0.1671\u001b[0m\n",
      "[I 2025-09-20 17:56:16,721] Trial 31 finished with value: 0.1777808219277302 and parameters: {'iterations': 1400, 'learning_rate': 0.19548071118368152, 'depth': 8, 'l2_leaf_reg': 9.96388212282143, 'random_strength': 1.3418541089963384e-08, 'bagging_temperature': 0.6262696023595227}. Best is trial 10 with value: 0.16119071900943038.\n",
      "\u001b[32m2025-09-20 17:56:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 32] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-20 17:56:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 32, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 18:01:34\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 32, Fold 1/5] RMSE: 0.1745\u001b[0m\n",
      "\u001b[32m2025-09-20 18:01:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 32, Fold 2/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 18:06:33\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 32, Fold 2/5] RMSE: 0.1628\u001b[0m\n",
      "\u001b[32m2025-09-20 18:06:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 32, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-20 18:11:21\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 32, Fold 3/5] RMSE: 0.1583\u001b[0m\n",
      "\u001b[32m2025-09-20 18:11:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 32, Fold 4/5] Training...\u001b[0m\n",
      "[W 2025-09-20 18:12:21,845] Trial 32 failed with parameters: {'iterations': 2000, 'learning_rate': 0.1594434300721664, 'depth': 10, 'l2_leaf_reg': 6.774989597718045, 'random_strength': 4.798410751620201e-06, 'bagging_temperature': 0.1878483835634101} because of the following error: KeyboardInterrupt('').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/puneet/tools/miniconda3/envs/newAge/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_16951/3603380527.py\", line 54, in objective\n",
      "    pipeline.fit(X_train_fold, y_train_fold)\n",
      "  File \"/home/puneet/tools/miniconda3/envs/newAge/lib/python3.10/site-packages/sklearn/base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/puneet/tools/miniconda3/envs/newAge/lib/python3.10/site-packages/sklearn/pipeline.py\", line 663, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/home/puneet/tools/miniconda3/envs/newAge/lib/python3.10/site-packages/catboost/core.py\", line 5873, in fit\n",
      "    return self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline,\n",
      "  File \"/home/puneet/tools/miniconda3/envs/newAge/lib/python3.10/site-packages/catboost/core.py\", line 2410, in _fit\n",
      "    self._train(\n",
      "  File \"/home/puneet/tools/miniconda3/envs/newAge/lib/python3.10/site-packages/catboost/core.py\", line 1790, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 5023, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 5072, in _catboost._CatBoost._train\n",
      "KeyboardInterrupt\n",
      "[W 2025-09-20 18:12:21,890] Trial 32 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 62\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124miterations\u001b[39m\u001b[38;5;124m'\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_int(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miterations\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m400\u001b[39m, \u001b[38;5;241m2000\u001b[39m, step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m),\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_float(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0.02\u001b[39m, \u001b[38;5;241m0.2\u001b[39m, log\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_state\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m42\u001b[39m\n\u001b[1;32m     56\u001b[0m     }\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# --- 5. We use the flexible factory function created in the last step ---\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# (No changes needed to the function itself, it's already defined)\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# --- 6. LAUNCH THE EXPERIMENT FOR CATBOOST ---\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m study_catboost \u001b[38;5;241m=\u001b[39m \u001b[43mrun_optimization_study_flexible\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCatBoost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCatBoostRegressor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparam_search_space\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatboost_search_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train_cat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train_cat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test_cat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_test_cat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreprocessor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreprocessor_catboost\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\n\u001b[1;32m     70\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[33], line 59\u001b[0m, in \u001b[0;36mrun_optimization_study_flexible\u001b[0;34m(model_name, model_class, param_search_space, X_train, y_train, X_test, y_test, preprocessor, n_trials)\u001b[0m\n\u001b[1;32m     56\u001b[0m             fold_scores\u001b[38;5;241m.\u001b[39mappend(rmse); logger\u001b[38;5;241m.\u001b[39msuccess(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  [Trial \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrial\u001b[38;5;241m.\u001b[39mnumber\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/5] RMSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrmse\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     57\u001b[0m         avg_rmse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(fold_scores); mlflow\u001b[38;5;241m.\u001b[39mlog_metric(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv_rmse\u001b[39m\u001b[38;5;124m\"\u001b[39m, avg_rmse); \u001b[38;5;28;01mreturn\u001b[39;00m avg_rmse\n\u001b[0;32m---> 59\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining and logging the final champion model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     61\u001b[0m best_params \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params\n",
      "File \u001b[0;32m~/tools/miniconda3/envs/newAge/lib/python3.10/site-packages/optuna/study/study.py:490\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    390\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    397\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    398\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    399\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \n\u001b[1;32m    401\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 490\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tools/miniconda3/envs/newAge/lib/python3.10/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/tools/miniconda3/envs/newAge/lib/python3.10/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial_id \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/tools/miniconda3/envs/newAge/lib/python3.10/site-packages/optuna/study/_optimize.py:258\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    254\u001b[0m     updated_state \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    257\u001b[0m ):\n\u001b[0;32m--> 258\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trial\u001b[38;5;241m.\u001b[39m_trial_id\n",
      "File \u001b[0;32m~/tools/miniconda3/envs/newAge/lib/python3.10/site-packages/optuna/study/_optimize.py:201\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[33], line 54\u001b[0m, in \u001b[0;36mrun_optimization_study_flexible.<locals>.objective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     52\u001b[0m X_train_fold, X_val_fold \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39miloc[train_idx], X_train\u001b[38;5;241m.\u001b[39miloc[val_idx]\n\u001b[1;32m     53\u001b[0m y_train_fold, y_val_fold \u001b[38;5;241m=\u001b[39m y_train\u001b[38;5;241m.\u001b[39miloc[train_idx], y_train\u001b[38;5;241m.\u001b[39miloc[val_idx]\n\u001b[0;32m---> 54\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_fold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m preds \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mpredict(X_val_fold); rmse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(mean_squared_error(y_val_fold, preds))\n\u001b[1;32m     56\u001b[0m fold_scores\u001b[38;5;241m.\u001b[39mappend(rmse); logger\u001b[38;5;241m.\u001b[39msuccess(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  [Trial \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrial\u001b[38;5;241m.\u001b[39mnumber\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/5] RMSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrmse\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/tools/miniconda3/envs/newAge/lib/python3.10/site-packages/sklearn/base.py:1365\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1358\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1361\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1362\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1363\u001b[0m     )\n\u001b[1;32m   1364\u001b[0m ):\n\u001b[0;32m-> 1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tools/miniconda3/envs/newAge/lib/python3.10/site-packages/sklearn/pipeline.py:663\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    658\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_metadata_for_step(\n\u001b[1;32m    659\u001b[0m             step_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    660\u001b[0m             step_params\u001b[38;5;241m=\u001b[39mrouted_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]],\n\u001b[1;32m    661\u001b[0m             all_params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    662\u001b[0m         )\n\u001b[0;32m--> 663\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/tools/miniconda3/envs/newAge/lib/python3.10/site-packages/catboost/core.py:5873\u001b[0m, in \u001b[0;36mCatBoostRegressor.fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, graph, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5871\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[1;32m   5872\u001b[0m     CatBoostRegressor\u001b[38;5;241m.\u001b[39m_check_is_compatible_loss(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m-> 5873\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5874\u001b[0m \u001b[43m                 \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5875\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5876\u001b[0m \u001b[43m                 \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cerr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tools/miniconda3/envs/newAge/lib/python3.10/site-packages/catboost/core.py:2410\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2407\u001b[0m allow_clear_pool \u001b[38;5;241m=\u001b[39m train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_clear_pool\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   2409\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m plot_wrapper(plot, plot_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining plots\u001b[39m\u001b[38;5;124m'\u001b[39m, [_get_train_dir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_params())]):\n\u001b[0;32m-> 2410\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meval_sets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minit_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m   2416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2418\u001b[0m \u001b[38;5;66;03m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[1;32m   2419\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_object\u001b[38;5;241m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[0;32m~/tools/miniconda3/envs/newAge/lib/python3.10/site-packages/catboost/core.py:1790\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[0;32m-> 1790\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[0;32m_catboost.pyx:5023\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:5072\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# CELL 4: Data Prep & Execution for CatBoost (FINAL)\n",
    "# ===================================================================\n",
    "import catboost as cb\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- 1. Define feature lists specifically for this run ---\n",
    "logger.info(\"--- Defining feature sets for CatBoost run ---\")\n",
    "binary_features = ['online_order', 'book_table']\n",
    "categorical_features = ['location', 'listed_in_type', 'listed_in_city', 'location_cluster']\n",
    "temp_X = df_master.drop(columns=['rate'] + cols_to_drop, errors='ignore')\n",
    "numerical_features = [col for col in temp_X.columns if col not in binary_features and col not in categorical_features]\n",
    "\n",
    "# --- 2. Create a CatBoost-Compatible Preprocessor ---\n",
    "logger.info(\"--- Building a preprocessor compatible with CatBoost ---\")\n",
    "preprocessor_catboost = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline(steps=[\n",
    "            ('power', PowerTransformer(method='yeo-johnson')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), numerical_features),\n",
    "        ('cat', 'passthrough', categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough', verbose_feature_names_out=False\n",
    ")\n",
    "preprocessor_catboost.set_output(transform=\"pandas\")\n",
    "\n",
    "\n",
    "# --- 3. Prepare Data (without .astype('category')) ---\n",
    "logger.info(\"--- Preparing data for CatBoost ---\")\n",
    "y = df_master['rate']\n",
    "X = df_master.drop(columns=['rate'] + cols_to_drop, errors='ignore')\n",
    "X_train_cat, X_test_cat, y_train_cat, y_test_cat = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "logger.success(f\"Data prepared for CatBoost. Dtype of 'location': {X_train_cat['location'].dtype}\")\n",
    "\n",
    "\n",
    "# --- 4. Define CatBoost Search Space ---\n",
    "def catboost_search_space(trial):\n",
    "    \"\"\"Defines the hyperparameter search space for CatBoost.\"\"\"\n",
    "    return {\n",
    "        'iterations': trial.suggest_int('iterations', 400, 2000, step=200),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.02, 0.2, log=True),\n",
    "        'depth': trial.suggest_int('depth', 4, 10),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1.0, 10.0, log=True),\n",
    "        # <<< FIX: 'colsample_bylevel' is NOT supported on GPU for regression. REMOVED. >>>\n",
    "        'random_strength': trial.suggest_float('random_strength', 1e-9, 10.0, log=True),\n",
    "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),\n",
    "        'task_type': 'GPU',\n",
    "        'devices': '0',\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "# --- 5. We use the flexible factory function created in the last step ---\n",
    "# (No changes needed to the function itself, it's already defined)\n",
    "\n",
    "# --- 6. LAUNCH THE EXPERIMENT FOR CATBOOST ---\n",
    "study_catboost = run_optimization_study_flexible(\n",
    "    model_name=\"CatBoost\",\n",
    "    model_class=cb.CatBoostRegressor,\n",
    "    param_search_space=catboost_search_space,\n",
    "    X_train=X_train_cat, y_train=y_train_cat,\n",
    "    X_test=X_test_cat, y_test=y_test_cat,\n",
    "    preprocessor=preprocessor_catboost,\n",
    "    n_trials=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51fda46-604d-4e58-a335-850c68b6d037",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b1bd1e0-f402-4075-99dc-1fcb693ae0eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-19T16:38:28.572160Z",
     "iopub.status.busy": "2025-09-19T16:38:28.571916Z",
     "iopub.status.idle": "2025-09-19T16:39:36.348994Z",
     "shell.execute_reply": "2025-09-19T16:39:36.348167Z",
     "shell.execute_reply.started": "2025-09-19T16:38:28.572143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-19 22:08:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- Preparing data for XGBoost Random Forest ---\u001b[0m\n",
      "\u001b[32m2025-09-19 22:08:28\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mData with 'category' dtype is ready for XGBoost RF.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-19 22:08:29,130] A new study created in RDB with name: Zomato_XGBoost_RF_Optimization\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "983700fd19c04fbf99732407e6a0a5bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-19 22:08:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- [Trial 0] Starting 5-Fold CV ---\u001b[0m\n",
      "\u001b[32m2025-09-19 22:08:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 0, Fold 1/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-19 22:08:32\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 0, Fold 1/5] RMSE: 0.3273\u001b[0m\n",
      "\u001b[32m2025-09-19 22:08:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 0, Fold 2/5] Training...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/puneet/tools/miniconda3/envs/newAge/lib/python3.10/site-packages/xgboost/core.py:705: UserWarning: [22:08:32] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1758008603490/work/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  return func(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-19 22:08:34\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 0, Fold 2/5] RMSE: 0.3129\u001b[0m\n",
      "\u001b[32m2025-09-19 22:08:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 0, Fold 3/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-19 22:08:36\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 0, Fold 3/5] RMSE: 0.3150\u001b[0m\n",
      "\u001b[32m2025-09-19 22:08:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 0, Fold 4/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-19 22:08:39\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 0, Fold 4/5] RMSE: 0.3251\u001b[0m\n",
      "\u001b[32m2025-09-19 22:08:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m  [Trial 0, Fold 5/5] Training...\u001b[0m\n",
      "\u001b[32m2025-09-19 22:08:41\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1m  [Trial 0, Fold 5/5] RMSE: 0.3164\u001b[0m\n",
      "[I 2025-09-19 22:08:41,534] Trial 0 finished with value: 0.31933213260335935 and parameters: {'num_parallel_tree': 100, 'subsample': 0.8118112136271917, 'colsample_bynode': 0.6065648170895152, 'max_depth': 5, 'min_child_weight': 9, 'reg_alpha': 0.0006885660430222964, 'reg_lambda': 1.0664771100701207e-08}. Best is trial 0 with value: 0.31933213260335935.\n",
      "\u001b[32m2025-09-19 22:08:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mTraining and logging the final champion model...\u001b[0m\n",
      "\u001b[32m2025-09-19 22:09:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- Performing Deep Evaluation for Champion XGBoost_RF Model ---\u001b[0m\n",
      "\u001b[32m2025-09-19 22:09:25\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mTest Set Performance Logged: {'test_rmse': 0.1953586544331808, 'test_mae': 0.12761205673807893, 'test_r2': 0.8829125621680374}\u001b[0m\n",
      "\u001b[32m2025-09-19 22:09:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mGenerating and logging evaluation plots...\u001b[0m\n",
      "\u001b[32m2025-09-19 22:09:25\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mAll evaluation artifacts have been logged to MLflow.\u001b[0m\n",
      "\u001b[32m2025-09-19 22:09:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- Logging XGBoost-specific artifacts for XGBoost_RF ---\u001b[0m\n",
      "\u001b[32m2025-09-19 22:09:26\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mLogged feature importance plot for type: weight\u001b[0m\n",
      "\u001b[32m2025-09-19 22:09:26\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mLogged feature importance plot for type: gain\u001b[0m\n",
      "\u001b[32m2025-09-19 22:09:26\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mLogged feature importance plot for type: cover\u001b[0m\n",
      "\u001b[32m2025-09-19 22:09:26\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mLogged feature importance plot for type: total_gain\u001b[0m\n",
      "\u001b[32m2025-09-19 22:09:26\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mLogged feature importance plot for type: total_cover\u001b[0m\n",
      "\u001b[32m2025-09-19 22:09:27\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mLogged sample decision tree plot.\u001b[0m\n",
      "\u001b[32m2025-09-19 22:09:27\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mLogged XGBoost model configuration.\u001b[0m\n",
      "\u001b[32m2025-09-19 22:09:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mLogging all available Optuna visualization plots...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-09-19 22:09:27,878] Param max_depth unique value length is less than 2.\n",
      "[W 2025-09-19 22:09:27,879] Param min_child_weight unique value length is less than 2.\n",
      "[W 2025-09-19 22:09:27,880] Param num_parallel_tree unique value length is less than 2.\n",
      "[W 2025-09-19 22:09:27,881] Param reg_alpha unique value length is less than 2.\n",
      "[W 2025-09-19 22:09:27,881] Param reg_lambda unique value length is less than 2.\n",
      "[W 2025-09-19 22:09:27,882] Param subsample unique value length is less than 2.\n",
      "[W 2025-09-19 22:09:27,883] Param colsample_bynode unique value length is less than 2.\n",
      "[W 2025-09-19 22:09:27,883] Param min_child_weight unique value length is less than 2.\n",
      "[W 2025-09-19 22:09:27,884] Param num_parallel_tree unique value length is less than 2.\n",
      "[W 2025-09-19 22:09:27,884] Param reg_alpha unique value length is less than 2.\n",
      "[W 2025-09-19 22:09:27,885] Param reg_lambda unique value length is less than 2.\n",
      "[W 2025-09-19 22:09:27,885] Param subsample unique value length is less than 2.\n",
      "[W 2025-09-19 22:09:27,886] Param colsample_bynode unique value length is less than 2.\n",
      "[W 2025-09-19 22:09:27,887] Param max_depth unique value length is less than 2.\n",
      "[W 2025-09-19 22:09:27,887] Param num_parallel_tree unique value length is less than 2.\n",
      "[W 2025-09-19 22:09:27,888] Param reg_alpha unique value length is less than 2.\n",
      "[W 2025-09-19 22:09:27,888] Param reg_lambda unique value length is less than 2.\n",
      "[W 2025-09-19 22:09:27,889] Param subsample unique value length is less than 2.\n",
      "[W 2025-09-19 22:09:27,889] Param colsample_bynode unique value length is less than 2.\n",
      "[W 2025-09-19 22:09:27,890] Param max_depth unique value length is less than 2.\n",
      "[W 2025-09-19 22:09:27,891] Param min_child_weight unique value length is less than 2.\n",
      "[W 2025-09-19 22:09:27,891] Param reg_alpha unique value length is less than 2.\n",
      "[W 2025-09-19 22:09:27,892] Param reg_lambda unique value length is less than 2.\n",
      "[W 2025-09-19 22:09:27,892] Param subsample unique value length is less than 2.\n",
      "[W 2025-09-19 22:09:27,893] Param colsample_bynode unique value length is less than 2.\n",
      "[W 2025-09-19 22:09:27,893] Param max_depth unique value length is less than 2.\n",
      "[W 2025-09-19 22:09:27,894] Param min_child_weight unique value length is less than 2.\n",
      "[W 2025-09-19 22:09:27,894] Param num_parallel_tree unique value length is less than 2.\n",
      "[W 2025-09-19 22:09:27,895] Param reg_lambda unique value length is less than 2.\n",
      "[W 2025-09-19 22:09:27,896] Param subsample unique value length is less than 2.\n",
      "[W 2025-09-19 22:09:27,897] Param colsample_bynode unique value length is less than 2.\n",
      "[W 2025-09-19 22:09:27,897] Param max_depth unique value length is less than 2.\n",
      "[W 2025-09-19 22:09:27,898] Param min_child_weight unique value length is less than 2.\n",
      "[W 2025-09-19 22:09:27,898] Param num_parallel_tree unique value length is less than 2.\n",
      "[W 2025-09-19 22:09:27,899] Param reg_alpha unique value length is less than 2.\n",
      "[W 2025-09-19 22:09:27,899] Param subsample unique value length is less than 2.\n",
      "[W 2025-09-19 22:09:27,900] Param colsample_bynode unique value length is less than 2.\n",
      "[W 2025-09-19 22:09:27,900] Param max_depth unique value length is less than 2.\n",
      "[W 2025-09-19 22:09:27,901] Param min_child_weight unique value length is less than 2.\n",
      "[W 2025-09-19 22:09:27,901] Param num_parallel_tree unique value length is less than 2.\n",
      "[W 2025-09-19 22:09:27,902] Param reg_alpha unique value length is less than 2.\n",
      "[W 2025-09-19 22:09:27,903] Param reg_lambda unique value length is less than 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-19 22:09:28\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[33m\u001b[1mCould not generate Optuna plot 'plot_hypervolume_history'. Skipping. Error: plot_hypervolume_history() missing 1 required positional argument: 'reference_point'\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16951/393399407.py:85: ExperimentalWarning:\n",
      "\n",
      "optuna.visualization._hypervolume_history.plot_hypervolume_history is experimental (supported from v3.3.0). The interface can change in the future.\n",
      "\n",
      "[W 2025-09-19 22:09:28,327] You need to set up the pruning feature to utilize `plot_intermediate_values()`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-19 22:09:28\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[33m\u001b[1mCould not generate Optuna plot 'plot_param_importances'. Skipping. Error: Cannot evaluate parameter importances with only a single trial.\u001b[0m\n",
      "\u001b[32m2025-09-19 22:09:28\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[33m\u001b[1mCould not generate Optuna plot 'plot_pareto_front'. Skipping. Error: `plot_pareto_front` function only supports 2 or 3 objective studies when using `targets` is `None`. Please use `targets` if your objective studies have more than 3 objectives.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16951/393399407.py:85: ExperimentalWarning:\n",
      "\n",
      "optuna.visualization._terminator_improvement.plot_terminator_improvement is experimental (supported from v3.2.0). The interface can change in the future.\n",
      "\n",
      "/home/puneet/tools/miniconda3/envs/newAge/lib/python3.10/site-packages/optuna/visualization/_terminator_improvement.py:93: ExperimentalWarning:\n",
      "\n",
      "RegretBoundEvaluator is experimental (supported from v3.2.0). The interface can change in the future.\n",
      "\n",
      "/home/puneet/tools/miniconda3/envs/newAge/lib/python3.10/site-packages/optuna/visualization/_terminator_improvement.py:98: ExperimentalWarning:\n",
      "\n",
      "CrossValidationErrorEvaluator is experimental (supported from v3.2.0). The interface can change in the future.\n",
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-19 22:09:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mWrapping model in custom PyFunc and logging...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/puneet/tools/miniconda3/envs/newAge/lib/python3.10/site-packages/mlflow/types/utils.py:452: UserWarning:\n",
      "\n",
      "Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "\n",
      "/home/puneet/tools/miniconda3/envs/newAge/lib/python3.10/site-packages/mlflow/pyfunc/__init__.py:3288: UserWarning:\n",
      "\n",
      "\u001b[1;33mAn input example was not provided when logging the model. To ensure the model signature functions correctly, specify the `input_example` parameter. See https://mlflow.org/docs/latest/model/signatures.html#model-input-example for more details about the benefits of using input_example.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-19 22:09:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- Run for XGBoost_RF complete. Check the MLflow UI and Optuna Dashboard. ---\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'XGBoost_RF_Zomato_Champion'.\n",
      "Created version '1' of model 'XGBoost_RF_Zomato_Champion'.\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# FINAL EXECUTION CELL: Train XGBoost configured as a Random Forest\n",
    "# ===================================================================\n",
    "# This cell is self-contained to ensure the correct function versions are used.\n",
    "\n",
    "# --- 1. Imports and Helper Functions (from previous cells) ---\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Ensure all helper functions are defined in this scope\n",
    "# This prevents using old versions from the notebook's memory.\n",
    "\n",
    "class DtypeEnforcingModel(mlflow.pyfunc.PythonModel):\n",
    "    def __init__(self, pipeline, categorical_features): self.pipeline = pipeline; self.categorical_features = categorical_features\n",
    "    def _enforce_dtypes(self, data: pd.DataFrame) -> pd.DataFrame:\n",
    "        data_copy = data.copy();\n",
    "        for col in self.categorical_features:\n",
    "            if col in data_copy.columns: data_copy[col] = data_copy[col].astype('category')\n",
    "        return data_copy\n",
    "    def predict(self, context, model_input: pd.DataFrame) -> np.ndarray:\n",
    "        processed_input = self._enforce_dtypes(model_input); return self.pipeline.predict(processed_input)\n",
    "\n",
    "# The definitive factory function with all fixes\n",
    "def run_optimization_study_flexible(\n",
    "    model_name: str, model_class, param_search_space,\n",
    "    X_train: pd.DataFrame, y_train: pd.Series,\n",
    "    X_test: pd.DataFrame, y_test: pd.Series,\n",
    "    preprocessor,\n",
    "    n_trials: int = 50\n",
    "):\n",
    "    optuna_db_path = \"optuna_studies\"; os.makedirs(optuna_db_path, exist_ok=True); storage_name = f\"sqlite:///{optuna_db_path}/{model_name}_study.db\"\n",
    "    study = optuna.create_study(direction='minimize', study_name=f\"Zomato_{model_name}_Optimization\", storage=storage_name, load_if_exists=True)\n",
    "    mlflow.set_experiment(f\"Zomato_Prediction_v1_{model_name}\"); cv_strategy = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    def objective(trial: optuna.Trial) -> float:\n",
    "        with mlflow.start_run(run_name=f\"trial_{trial.number}\", nested=True):\n",
    "            params = param_search_space(trial); mlflow.log_params(params)\n",
    "            \n",
    "            if model_name == \"CatBoost\":\n",
    "                model_instance = model_class(**params, cat_features=categorical_features, verbose=0)\n",
    "            elif \"XGBoost\" in model_name: \n",
    "                model_instance = model_class(**{**params, 'enable_categorical': True})\n",
    "            else:\n",
    "                model_instance = model_class(**params)\n",
    "\n",
    "            pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('regressor', model_instance)])\n",
    "            logger.info(f\"--- [Trial {trial.number}] Starting 5-Fold CV ---\")\n",
    "            fold_scores = []\n",
    "            for fold, (train_idx, val_idx) in enumerate(cv_strategy.split(X_train, y_train)):\n",
    "                logger.info(f\"  [Trial {trial.number}, Fold {fold+1}/5] Training...\")\n",
    "                X_train_fold, X_val_fold = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "                y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "                pipeline.fit(X_train_fold, y_train_fold)\n",
    "                preds = pipeline.predict(X_val_fold); rmse = np.sqrt(mean_squared_error(y_val_fold, preds))\n",
    "                fold_scores.append(rmse); logger.success(f\"  [Trial {trial.number}, Fold {fold+1}/5] RMSE: {rmse:.4f}\")\n",
    "            avg_rmse = np.mean(fold_scores); mlflow.log_metric(\"cv_rmse\", avg_rmse); return avg_rmse\n",
    "            \n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
    "    logger.info(\"Training and logging the final champion model...\")\n",
    "    best_params = study.best_params\n",
    "    with mlflow.start_run(run_name=f\"Champion_{model_name}\") as champion_run:\n",
    "        mlflow.log_params(best_params); mlflow.log_metric(\"best_cv_rmse_from_optuna\", study.best_value)\n",
    "        \n",
    "        if model_name == \"CatBoost\": final_model = model_class(**best_params, cat_features=categorical_features, verbose=0)\n",
    "        elif \"XGBoost\" in model_name: final_model = model_class(**{**best_params, 'enable_categorical': True})\n",
    "        else: final_model = model_class(**best_params)\n",
    "\n",
    "        final_pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('regressor', final_model)])\n",
    "        final_pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        evaluate_and_log_champion(final_pipeline, model_name, X_test, y_test)\n",
    "        \n",
    "        # <<< FIX #2: ENABLE ARTIFACTS FOR RF --- >>>\n",
    "        # Use 'in' to catch both \"XGBoost\" and \"XGBoost_RF\"\n",
    "        if \"XGBoost\" in model_name:\n",
    "            log_xgboost_artifacts(final_pipeline, model_name)\n",
    "        # <<< --- END FIX #2 --- >>>\n",
    "        \n",
    "        logger.info(\"Logging all available Optuna visualization plots...\")\n",
    "        plot_functions = [\"plot_contour\", \"plot_edf\", \"plot_hypervolume_history\", \"plot_intermediate_values\", \"plot_optimization_history\", \"plot_parallel_coordinate\", \"plot_param_importances\", \"plot_pareto_front\", \"plot_rank\", \"plot_slice\", \"plot_terminator_improvement\", \"plot_timeline\"]\n",
    "        for plot_func_name in plot_functions:\n",
    "            try:\n",
    "                plot_func = getattr(optuna.visualization, plot_func_name); fig = plot_func(study); mlflow.log_figure(fig, f\"optuna_{plot_func_name}.html\")\n",
    "            except (ValueError, TypeError) as e: logger.warning(f\"Could not generate Optuna plot '{plot_func_name}'. Skipping. Error: {e}\")\n",
    "            except Exception as e: logger.error(f\"An unexpected error occurred while generating plot '{plot_func_name}'. Skipping. Error: {e}\")\n",
    "            \n",
    "        logger.info(\"Wrapping model in custom PyFunc and logging...\")\n",
    "        wrapped_model = DtypeEnforcingModel(pipeline=final_pipeline, categorical_features=categorical_features)\n",
    "        signature = infer_signature(X_train, final_pipeline.predict(X_train))\n",
    "        mlflow.pyfunc.log_model(python_model=wrapped_model, signature=signature, registered_model_name=f\"{model_name}_Zomato_Champion\")\n",
    "        \n",
    "    logger.info(f\"--- Run for {model_name} complete. Check the MLflow UI and Optuna Dashboard. ---\")\n",
    "    return study\n",
    "\n",
    "# --- 2. Prepare data specifically for XGBoost (with 'category' dtype) ---\n",
    "logger.info(\"--- Preparing data for XGBoost Random Forest ---\")\n",
    "y = df_master['rate']\n",
    "X = df_master.drop(columns=['rate'] + cols_to_drop, errors='ignore')\n",
    "for col in categorical_features:\n",
    "    if col in X.columns:\n",
    "        X[col] = X[col].astype('category')\n",
    "X_train_xgb, X_test_xgb, y_train_xgb, y_test_xgb = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "logger.success(f\"Data with 'category' dtype is ready for XGBoost RF.\")\n",
    "\n",
    "# --- 3. Create the XGBoost-Compatible Preprocessor ---\n",
    "preprocessor_xgb = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline(steps=[\n",
    "            ('power', PowerTransformer(method='yeo-johnson')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), numerical_features),\n",
    "        ('cat', 'passthrough', categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough', verbose_feature_names_out=False\n",
    ")\n",
    "preprocessor_xgb.set_output(transform=\"pandas\")\n",
    "\n",
    "\n",
    "# --- 4. Define the search space for XGBoost configured as a Random Forest ---\n",
    "def xgb_rf_search_space(trial):\n",
    "    \"\"\"\n",
    "    Defines a more computationally feasible hyperparameter search space\n",
    "    for an XGBoost Random Forest.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'n_estimators': 1,\n",
    "        'learning_rate': 1.0,\n",
    "        # Constrain the forest size to a more reasonable number\n",
    "        'num_parallel_tree': trial.suggest_int('num_parallel_tree', 100, 600, step=50), \n",
    "        \n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 0.95),\n",
    "        'colsample_bynode': trial.suggest_float('colsample_bynode', 0.6, 0.95),\n",
    "        \n",
    "        # <<< CRITICAL FIX: Limit the max_depth to prevent memory explosion >>>\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 5), \n",
    "        \n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "        'tree_method': 'hist',\n",
    "        'device': 'cuda',\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "    # <<< --- END FIX #1 --- >>>\n",
    "\n",
    "study_xgb_rf = run_optimization_study_flexible(\n",
    "    model_name=\"XGBoost_RF\", \n",
    "    model_class=xgb.XGBRegressor,\n",
    "    param_search_space=xgb_rf_search_space,\n",
    "    X_train=X_train_xgb, y_train=y_train_xgb, \n",
    "    X_test=X_test_xgb, y_test=y_test_xgb,\n",
    "    preprocessor=preprocessor_xgb,\n",
    "    n_trials=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3a1b52-def6-4be6-a385-d7c5f1c19617",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2aecdc57-c893-41b0-a2cb-7467929a88b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-19T19:29:37.320372Z",
     "iopub.status.busy": "2025-09-19T19:29:37.319476Z",
     "iopub.status.idle": "2025-09-19T19:30:23.216753Z",
     "shell.execute_reply": "2025-09-19T19:30:23.215893Z",
     "shell.execute_reply.started": "2025-09-19T19:29:37.320309Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-20 00:59:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mFetching champion model parameters from MLflow Run ID: 6e9df2f0d7ac41f5b7d8fab3996deb1d\u001b[0m\n",
      "\u001b[32m2025-09-20 00:59:37\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mSuccessfully loaded and parsed Champion Hyperparameters: {'max_depth': 8, 'colsample_bytree': 0.7738353609663036, 'n_estimators': 1000, 'subsample': 0.9216008186899227, 'learning_rate': 0.06813553414880555}\u001b[0m\n",
      "\u001b[32m2025-09-20 00:59:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mRe-creating data and preprocessor to ensure correct dtypes...\u001b[0m\n",
      "\u001b[32m2025-09-20 00:59:37\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mSelf-contained data prepared. Dtype of 'location': category\u001b[0m\n",
      "\u001b[32m2025-09-20 00:59:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- Starting run for Robustness_Check_70_30_Split with test_size=0.3 ---\u001b[0m\n",
      "\u001b[32m2025-09-20 00:59:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mCreating a new 70%/30% data split...\u001b[0m\n",
      "\u001b[32m2025-09-20 00:59:37\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mNew split created. Training samples: 31630, Testing samples: 13557\u001b[0m\n",
      "\u001b[32m2025-09-20 00:59:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mBuilding and training a new model from scratch on the new split...\u001b[0m\n",
      "\u001b[32m2025-09-20 00:59:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mEvaluating the newly trained model...\u001b[0m\n",
      "\u001b[32m2025-09-20 00:59:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- Performing Deep Evaluation for Champion XGBoost_70_30_Split Model ---\u001b[0m\n",
      "\u001b[32m2025-09-20 00:59:57\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mTest Set Performance Logged: {'test_rmse': 0.13593044103980934, 'test_mae': 0.06030927582862827, 'test_r2': 0.9431167702499327}\u001b[0m\n",
      "\u001b[32m2025-09-20 00:59:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mGenerating and logging evaluation plots...\u001b[0m\n",
      "\u001b[32m2025-09-20 00:59:57\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mAll evaluation artifacts have been logged to MLflow.\u001b[0m\n",
      "\u001b[32m2025-09-20 00:59:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- Logging XGBoost-specific artifacts for XGBoost_70_30_Split ---\u001b[0m\n",
      "\u001b[32m2025-09-20 00:59:57\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mLogged feature importance plot for type: weight\u001b[0m\n",
      "\u001b[32m2025-09-20 00:59:58\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mLogged feature importance plot for type: gain\u001b[0m\n",
      "\u001b[32m2025-09-20 00:59:58\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mLogged feature importance plot for type: cover\u001b[0m\n",
      "\u001b[32m2025-09-20 00:59:58\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mLogged feature importance plot for type: total_gain\u001b[0m\n",
      "\u001b[32m2025-09-20 00:59:58\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mLogged feature importance plot for type: total_cover\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dot: graph is too large for cairo-renderer bitmaps. Scaling by 0.456689 to fit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-20 01:00:00\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mLogged sample decision tree plot.\u001b[0m\n",
      "\u001b[32m2025-09-20 01:00:00\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mLogged interactive SVG decision tree plot.\u001b[0m\n",
      "\u001b[32m2025-09-20 01:00:00\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mLogged XGBoost model configuration.\u001b[0m\n",
      "\u001b[32m2025-09-20 01:00:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- Starting run for Robustness_Check_50_50_Split with test_size=0.5 ---\u001b[0m\n",
      "\u001b[32m2025-09-20 01:00:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mCreating a new 50%/50% data split...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:00:00\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mNew split created. Training samples: 22593, Testing samples: 22594\u001b[0m\n",
      "\u001b[32m2025-09-20 01:00:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mBuilding and training a new model from scratch on the new split...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:00:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mEvaluating the newly trained model...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:00:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- Performing Deep Evaluation for Champion XGBoost_50_50_Split Model ---\u001b[0m\n",
      "\u001b[32m2025-09-20 01:00:19\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mTest Set Performance Logged: {'test_rmse': 0.16786080043382615, 'test_mae': 0.0787481193468571, 'test_r2': 0.9153725088316106}\u001b[0m\n",
      "\u001b[32m2025-09-20 01:00:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mGenerating and logging evaluation plots...\u001b[0m\n",
      "\u001b[32m2025-09-20 01:00:19\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mAll evaluation artifacts have been logged to MLflow.\u001b[0m\n",
      "\u001b[32m2025-09-20 01:00:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- Logging XGBoost-specific artifacts for XGBoost_50_50_Split ---\u001b[0m\n",
      "\u001b[32m2025-09-20 01:00:20\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mLogged feature importance plot for type: weight\u001b[0m\n",
      "\u001b[32m2025-09-20 01:00:20\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mLogged feature importance plot for type: gain\u001b[0m\n",
      "\u001b[32m2025-09-20 01:00:20\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mLogged feature importance plot for type: cover\u001b[0m\n",
      "\u001b[32m2025-09-20 01:00:21\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mLogged feature importance plot for type: total_gain\u001b[0m\n",
      "\u001b[32m2025-09-20 01:00:21\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mLogged feature importance plot for type: total_cover\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dot: graph is too large for cairo-renderer bitmaps. Scaling by 0.340932 to fit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-20 01:00:23\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mLogged sample decision tree plot.\u001b[0m\n",
      "\u001b[32m2025-09-20 01:00:23\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mLogged interactive SVG decision tree plot.\u001b[0m\n",
      "\u001b[32m2025-09-20 01:00:23\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[32m\u001b[1mLogged XGBoost model configuration.\u001b[0m\n",
      "\u001b[32m2025-09-20 01:00:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- Sensitivity Analysis Complete. Check the MLflow UI. ---\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# CELL 6: Model Robustness Analysis (FINAL, SELF-CONTAINED)\n",
    "# ===================================================================\n",
    "import mlflow\n",
    "import xgboost as xgb\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
    "\n",
    "# --- 1. Define the Run ID of your definitive 100-trial Champion Model ---\n",
    "CHAMPION_RUN_ID = \"6e9df2f0d7ac41f5b7d8fab3996deb1d\" # Your correct Run ID\n",
    "logger.info(f\"Fetching champion model parameters from MLflow Run ID: {CHAMPION_RUN_ID}\")\n",
    "\n",
    "# --- 2. Fetch the Champion Hyperparameters from MLflow ---\n",
    "try:\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    champion_run_data = client.get_run(CHAMPION_RUN_ID).data\n",
    "    champion_params = {k: v for k, v in champion_run_data.params.items()}\n",
    "    int_params = ['n_estimators', 'max_depth', 'random_state']\n",
    "    for p in int_params:\n",
    "        if p in champion_params: champion_params[p] = int(champion_params[p])\n",
    "    float_params = ['learning_rate', 'subsample', 'colsample_bytree']\n",
    "    for p in float_params:\n",
    "        if p in champion_params: champion_params[p] = float(champion_params[p])\n",
    "    champion_params.pop('tree_method', None); champion_params.pop('device', None)\n",
    "    logger.success(f\"Successfully loaded and parsed Champion Hyperparameters: {champion_params}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to fetch or parse parameters from MLflow. Error: {e}\"); raise\n",
    "\n",
    "# --- 3. RE-CREATE ALL NECESSARY OBJECTS FROM SCRATCH TO AVOID STATE ISSUES ---\n",
    "logger.info(\"Re-creating data and preprocessor to ensure correct dtypes...\")\n",
    "# Define feature lists\n",
    "binary_features = ['online_order', 'book_table']\n",
    "categorical_features = ['location', 'listed_in_type', 'listed_in_city', 'location_cluster']\n",
    "temp_X_for_cols = df_master.drop(columns=['rate'] + cols_to_drop, errors='ignore')\n",
    "numerical_features = [col for col in temp_X_for_cols.columns if col not in binary_features and col not in categorical_features]\n",
    "# Create the XGBoost-Compatible Preprocessor\n",
    "preprocessor_xgb = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline(steps=[('power', PowerTransformer(method='yeo-johnson')), ('scaler', StandardScaler())]), numerical_features),\n",
    "        ('cat', 'passthrough', categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough', verbose_feature_names_out=False\n",
    ")\n",
    "preprocessor_xgb.set_output(transform=\"pandas\")\n",
    "# Prepare X and y AND SET THE CORRECT DTYPE\n",
    "y_sens = df_master['rate']\n",
    "X_sens = df_master.drop(columns=['rate'] + cols_to_drop, errors='ignore')\n",
    "for col in categorical_features:\n",
    "    if col in X_sens.columns:\n",
    "        X_sens[col] = X_sens[col].astype('category')\n",
    "logger.success(f\"Self-contained data prepared. Dtype of 'location': {X_sens['location'].dtype}\")\n",
    "\n",
    "\n",
    "# --- 4. Define the splits we want to test ---\n",
    "splits_to_test = { \"70_30_Split\": 0.30, \"50_50_Split\": 0.50 }\n",
    "\n",
    "# --- 5. Loop, Re-split, Re-train, and Evaluate for each scenario ---\n",
    "for split_name, test_size in splits_to_test.items():\n",
    "    run_name = f\"Robustness_Check_{split_name}\"\n",
    "    logger.info(f\"--- Starting run for {run_name} with test_size={test_size} ---\")\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        mlflow.log_params(champion_params)\n",
    "        mlflow.log_param(\"original_champion_run_id\", CHAMPION_RUN_ID)\n",
    "        mlflow.log_param(\"test_split_ratio\", test_size)\n",
    "        \n",
    "        logger.info(f\"Creating a new {1-test_size:.0%}/{test_size:.0%} data split...\")\n",
    "        X_resplit_train, X_resplit_test, y_resplit_train, y_resplit_test = train_test_split(\n",
    "            X_sens, y_sens, test_size=test_size, random_state=42 # Use the correctly-typed X_sens\n",
    "        )\n",
    "        logger.success(f\"New split created. Training samples: {len(y_resplit_train)}, Testing samples: {len(y_resplit_test)}\")\n",
    "        \n",
    "        logger.info(\"Building and training a new model from scratch on the new split...\")\n",
    "        final_model = xgb.XGBRegressor(\n",
    "            **champion_params,\n",
    "            tree_method='hist', device='cuda', enable_categorical=True\n",
    "        )\n",
    "        # Use the self-contained preprocessor_xgb\n",
    "        final_pipeline = Pipeline(steps=[('preprocessor', preprocessor_xgb), ('regressor', final_model)])\n",
    "        final_pipeline.fit(X_resplit_train, y_resplit_train)\n",
    "        \n",
    "        logger.info(\"Evaluating the newly trained model...\")\n",
    "        evaluate_and_log_champion(final_pipeline, f\"XGBoost_{split_name}\", X_resplit_test, y_resplit_test)\n",
    "        log_xgboost_artifacts(final_pipeline, f\"XGBoost_{split_name}\")\n",
    "\n",
    "logger.info(\"--- Sensitivity Analysis Complete. Check the MLflow UI. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "81ca32b6-220f-4ee7-8935-a97920a100ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-19T19:40:18.705614Z",
     "iopub.status.busy": "2025-09-19T19:40:18.705318Z",
     "iopub.status.idle": "2025-09-19T19:40:19.357426Z",
     "shell.execute_reply": "2025-09-19T19:40:19.356828Z",
     "shell.execute_reply.started": "2025-09-19T19:40:18.705596Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-20 01:10:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- Fetching sensitivity analysis results from MLflow ---\u001b[0m\n",
      "\u001b[32m2025-09-20 01:10:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- Preparing data for visualization ---\u001b[0m\n",
      "\n",
      "--- Consolidated Results ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16951/3227436002.py:72: FutureWarning:\n",
      "\n",
      "A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_name</th>\n",
       "      <th>training_samples</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R-squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Champion_XGBoost</td>\n",
       "      <td>36149</td>\n",
       "      <td>0.1232</td>\n",
       "      <td>0.0532</td>\n",
       "      <td>0.9534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Robustness_Check_70_30_Split</td>\n",
       "      <td>31630</td>\n",
       "      <td>0.1359</td>\n",
       "      <td>0.0603</td>\n",
       "      <td>0.9431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Robustness_Check_50_50_Split</td>\n",
       "      <td>22593</td>\n",
       "      <td>0.1679</td>\n",
       "      <td>0.0787</td>\n",
       "      <td>0.9154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       run_name  training_samples    RMSE     MAE  R-squared\n",
       "0              Champion_XGBoost             36149  0.1232  0.0532     0.9534\n",
       "1  Robustness_Check_70_30_Split             31630  0.1359  0.0603     0.9431\n",
       "2  Robustness_Check_50_50_Split             22593  0.1679  0.0787     0.9154"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-20 01:10:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- Generating robustness plots ---\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# FINAL CELL: Analysis & Visualization of Model Robustness\n",
    "# ===================================================================\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- 1. Fetch the Data from MLflow ---\n",
    "logger.info(\"--- Fetching sensitivity analysis results from MLflow ---\")\n",
    "\n",
    "EXPERIMENT_NAME = \"Zomato_Prediction_v1_XGBoost\"\n",
    "\n",
    "# The Run ID from your screenshot for the 80/20 split champion\n",
    "CHAMPION_RUN_ID = \"6e9df2f0d7ac41f5b7d8fab3996deb1d\"\n",
    "\n",
    "# We will find the other two runs by name\n",
    "ROBUSTNESS_RUN_NAMES = [\n",
    "    \"Robustness_Check_70_30_Split\", \n",
    "    \"Robustness_Check_50_50_Split\"\n",
    "]\n",
    "\n",
    "experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "\n",
    "# Fetch the main champion run by its unique ID\n",
    "# Search for its name to get the correct column structure\n",
    "champion_run_df = mlflow.search_runs(\n",
    "    experiment_ids=[experiment.experiment_id],\n",
    "    filter_string=f\"attributes.run_name = 'Champion_XGBoost'\",\n",
    "    order_by=[\"start_time DESC\"],\n",
    "    max_results=1\n",
    ")\n",
    "\n",
    "# Fetch the other runs by name\n",
    "list_of_robustness_runs = []\n",
    "for run_name in ROBUSTNESS_RUN_NAMES:\n",
    "    run_df = mlflow.search_runs(\n",
    "        experiment_ids=[experiment.experiment_id],\n",
    "        filter_string=f\"attributes.run_name = '{run_name}'\",\n",
    "        order_by=[\"start_time DESC\"],\n",
    "        max_results=1\n",
    "    )\n",
    "    if not run_df.empty:\n",
    "        list_of_robustness_runs.append(run_df)\n",
    "\n",
    "# Combine all results into a single DataFrame\n",
    "runs_df = pd.concat([champion_run_df] + list_of_robustness_runs, ignore_index=True)\n",
    "\n",
    "\n",
    "# --- 2. Prepare the Data for Plotting ---\n",
    "logger.info(\"--- Preparing data for visualization ---\")\n",
    "\n",
    "# <<< --- START OF FINAL FIX --- >>>\n",
    "# The DataFrame column is named 'tags.mlflow.runName'.\n",
    "results_df = runs_df[[\n",
    "    \"tags.mlflow.runName\", # Correct column name for the run name\n",
    "    \"params.test_split_ratio\", \n",
    "    \"metrics.test_rmse\", \n",
    "    \"metrics.test_mae\", \n",
    "    \"metrics.test_r2\"\n",
    "]].copy()\n",
    "\n",
    "results_df.rename(columns={\n",
    "    \"tags.mlflow.runName\": \"run_name\", # Rename the tag to the simpler name\n",
    "    \"params.test_split_ratio\": \"test_split_ratio\",\n",
    "    \"metrics.test_rmse\": \"RMSE\",\n",
    "    \"metrics.test_mae\": \"MAE\",\n",
    "    \"metrics.test_r2\": \"R-squared\"\n",
    "}, inplace=True)\n",
    "# <<< --- END OF FINAL FIX --- >>>\n",
    "\n",
    "results_df['test_split_ratio'].fillna(0.20, inplace=True)\n",
    "results_df['test_split_ratio'] = results_df['test_split_ratio'].astype(float)\n",
    "\n",
    "total_samples = len(df_master)\n",
    "results_df['training_samples'] = ((1 - results_df['test_split_ratio']) * total_samples).astype(int)\n",
    "\n",
    "results_df.sort_values(by='training_samples', ascending=False, inplace=True)\n",
    "\n",
    "print(\"\\n--- Consolidated Results ---\")\n",
    "display(results_df[['run_name', 'training_samples', 'RMSE', 'MAE', 'R-squared']].round(4))\n",
    "\n",
    "\n",
    "# --- 3. Create the Stunning Visualizations ---\n",
    "logger.info(\"--- Generating robustness plots ---\")\n",
    "metrics_to_plot = [\"RMSE\", \"MAE\", \"R-squared\"]\n",
    "for metric in metrics_to_plot:\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    sns.lineplot(data=results_df, x='training_samples', y=metric, marker='o', markersize=10, ax=ax, label=metric)\n",
    "    \n",
    "    for index, row in results_df.iterrows():\n",
    "        ax.text(row['training_samples'], row[metric], f\" {row[metric]:.4f}\", \n",
    "                horizontalalignment='left', verticalalignment='bottom', fontsize=12)\n",
    "\n",
    "    ax.set_title(f\"Model Performance ({metric}) vs. Training Set Size\", fontsize=16, pad=20)\n",
    "    ax.set_xlabel(\"Number of Training Samples\", fontsize=14)\n",
    "    ax.set_ylabel(metric, fontsize=14)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "    \n",
    "    if metric in [\"RMSE\", \"MAE\"]:\n",
    "        ax.invert_yaxis()\n",
    "        ax.set_ylabel(f\"{metric} (Lower is Better)\", fontsize=14)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6bf12b9a-67ae-425f-93ad-efca00a57456",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-19T19:47:53.260756Z",
     "iopub.status.busy": "2025-09-19T19:47:53.260390Z",
     "iopub.status.idle": "2025-09-19T19:47:53.421234Z",
     "shell.execute_reply": "2025-09-19T19:47:53.420302Z",
     "shell.execute_reply.started": "2025-09-19T19:47:53.260706Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-20 01:17:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1m--- Starting Explainable AI (XAI) analysis with SHAP ---\u001b[0m\n",
      "\u001b[32m2025-09-20 01:17:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[1mLoading champion pyfunc model from MLflow Run ID: 6e9df2f0d7ac41f5b7d8fab3996deb1d\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3b094d53b1b43a7887a86199e3b3026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-20 01:17:53\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[31m\u001b[1mFailed to load model from MLflow. Please check the Run ID. Error: Failed to download artifacts from path 'champion_model', please ensure that the path is correct.\u001b[0m\n"
     ]
    },
    {
     "ename": "MlflowException",
     "evalue": "Failed to download artifacts from path 'champion_model', please ensure that the path is correct.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 26\u001b[0m\n\u001b[1;32m     22\u001b[0m logged_model_uri \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mruns:/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCHAMPION_RUN_ID\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/champion_model\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# <<< --- START OF FIX --- >>>\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Load the model as a generic PyFunc, which is how it was saved.\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m loaded_pyfunc \u001b[38;5;241m=\u001b[39m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogged_model_uri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Access the underlying pipeline from our custom wrapper\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# The _model_impl attribute gives us our DtypeEnforcingModel instance\u001b[39;00m\n\u001b[1;32m     30\u001b[0m loaded_pipeline \u001b[38;5;241m=\u001b[39m loaded_pyfunc\u001b[38;5;241m.\u001b[39m_model_impl\u001b[38;5;241m.\u001b[39mpipeline\n",
      "File \u001b[0;32m~/tools/miniconda3/envs/newAge/lib/python3.10/site-packages/mlflow/tracing/provider.py:508\u001b[0m, in \u001b[0;36mtrace_disabled.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    507\u001b[0m     is_func_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 508\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     enable()\n",
      "File \u001b[0;32m~/tools/miniconda3/envs/newAge/lib/python3.10/site-packages/mlflow/pyfunc/__init__.py:1132\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model_uri, suppress_warnings, dst_path, model_config)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         entity_list\u001b[38;5;241m.\u001b[39mappend(Entity(job\u001b[38;5;241m=\u001b[39mjob_entity))\n\u001b[1;32m   1130\u001b[0m     lineage_header_info \u001b[38;5;241m=\u001b[39m LineageHeaderInfo(entities\u001b[38;5;241m=\u001b[39mentity_list) \u001b[38;5;28;01mif\u001b[39;00m entity_list \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1132\u001b[0m local_path \u001b[38;5;241m=\u001b[39m \u001b[43m_download_artifact_from_uri\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[43m    \u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdst_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlineage_header_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineage_header_info\u001b[49m\n\u001b[1;32m   1134\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m suppress_warnings:\n\u001b[1;32m   1137\u001b[0m     model_requirements \u001b[38;5;241m=\u001b[39m _get_pip_requirements_from_model_path(local_path)\n",
      "File \u001b[0;32m~/tools/miniconda3/envs/newAge/lib/python3.10/site-packages/mlflow/tracking/artifact_utils.py:124\u001b[0m, in \u001b[0;36m_download_artifact_from_uri\u001b[0;34m(artifact_uri, output_path, lineage_header_info, tracking_uri)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(repo, ModelsArtifactRepository):\n\u001b[1;32m    119\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m repo\u001b[38;5;241m.\u001b[39mdownload_artifacts(\n\u001b[1;32m    120\u001b[0m             artifact_path\u001b[38;5;241m=\u001b[39martifact_path,\n\u001b[1;32m    121\u001b[0m             dst_path\u001b[38;5;241m=\u001b[39moutput_path,\n\u001b[1;32m    122\u001b[0m             lineage_header_info\u001b[38;5;241m=\u001b[39mlineage_header_info,\n\u001b[1;32m    123\u001b[0m         )\n\u001b[0;32m--> 124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrepo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_artifacts\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artifact_uri\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    127\u001b[0m         \u001b[38;5;66;03m# When a Model ID like string is passed, suggest using 'models:/{artifact_uri}' instead.\u001b[39;00m\n",
      "File \u001b[0;32m~/tools/miniconda3/envs/newAge/lib/python3.10/site-packages/mlflow/store/artifact/runs_artifact_repo.py:226\u001b[0m, in \u001b[0;36mRunsArtifactRepository.download_artifacts\u001b[0;34m(self, artifact_path, dst_path)\u001b[0m\n\u001b[1;32m    224\u001b[0m path \u001b[38;5;241m=\u001b[39m run_out_path \u001b[38;5;129;01mor\u001b[39;00m model_out_path\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 226\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to download artifacts from path \u001b[39m\u001b[38;5;132;01m{\u001b[39;00martifact_path\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    228\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease ensure that the path is correct.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    229\u001b[0m         error_code\u001b[38;5;241m=\u001b[39mRESOURCE_DOES_NOT_EXIST,\n\u001b[1;32m    230\u001b[0m     )\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m path\n",
      "\u001b[0;31mMlflowException\u001b[0m: Failed to download artifacts from path 'champion_model', please ensure that the path is correct."
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# FINAL CELL: Explainable AI (XAI) with SHAP\n",
    "# ===================================================================\n",
    "\n",
    "# --- 1. Installation (run this once if you haven't already) ---\n",
    "# !pip install shap\n",
    "\n",
    "import shap\n",
    "import mlflow\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "logger.info(\"--- Starting Explainable AI (XAI) analysis with SHAP ---\")\n",
    "\n",
    "# --- 2. Load the Definitive Champion Model from MLflow ---\n",
    "CHAMPION_RUN_ID = \"6e9df2f0d7ac41f5b7d8fab3996deb1d\" \n",
    "logger.info(f\"Loading champion pyfunc model from MLflow Run ID: {CHAMPION_RUN_ID}\")\n",
    "\n",
    "try:\n",
    "    logged_model_uri = f\"runs:/{CHAMPION_RUN_ID}/champion_model\"\n",
    "    \n",
    "    # <<< --- START OF FIX --- >>>\n",
    "    # Load the model as a generic PyFunc, which is how it was saved.\n",
    "    loaded_pyfunc = mlflow.pyfunc.load_model(logged_model_uri)\n",
    "    \n",
    "    # Access the underlying pipeline from our custom wrapper\n",
    "    # The _model_impl attribute gives us our DtypeEnforcingModel instance\n",
    "    loaded_pipeline = loaded_pyfunc._model_impl.pipeline\n",
    "    # <<< --- END OF FIX --- >>>\n",
    "    \n",
    "    logger.success(\"Champion pipeline loaded successfully from pyfunc wrapper.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to load model from MLflow. Please check the Run ID. Error: {e}\")\n",
    "    raise\n",
    "\n",
    "# --- 3. Prepare Data for Explanation ---\n",
    "logger.info(\"Preparing data with correct 'category' dtypes for explanation...\")\n",
    "y = df_master['rate']\n",
    "X = df_master.drop(columns=['rate'] + cols_to_drop, errors='ignore')\n",
    "for col in categorical_features:\n",
    "    if col in X.columns: X[col] = X[col].astype('category')\n",
    "X_train_xgb, X_test_xgb, y_train_xgb, y_test_xgb = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "preprocessor = loaded_pipeline.named_steps['preprocessor']\n",
    "xgb_model = loaded_pipeline.named_steps['regressor']\n",
    "X_test_processed = preprocessor.transform(X_test_xgb)\n",
    "logger.success(\"Test data has been preprocessed for SHAP analysis.\")\n",
    "\n",
    "\n",
    "# --- 4. Create Explainer and Calculate SHAP Values ---\n",
    "logger.info(\"Creating SHAP TreeExplainer...\")\n",
    "explainer = shap.TreeExplainer(xgb_model)\n",
    "logger.info(\"Calculating SHAP values for the test set... (this may take a moment)\")\n",
    "shap_values = explainer.shap_values(X_test_processed)\n",
    "logger.success(\"SHAP values calculated successfully.\")\n",
    "\n",
    "\n",
    "# --- 5. Log All XAI Artifacts to a New MLflow Run ---\n",
    "XAI_RUN_NAME = f\"XAI_Analysis_{CHAMPION_RUN_ID[:8]}\"\n",
    "with mlflow.start_run(run_name=XAI_RUN_NAME):\n",
    "    logger.info(f\"Logging XAI artifacts to new MLflow run: '{XAI_RUN_NAME}'\")\n",
    "    mlflow.set_tag(\"Analysis Type\", \"SHAP Explainability\")\n",
    "    mlflow.set_tag(\"Champion Run ID\", CHAMPION_RUN_ID)\n",
    "    \n",
    "    shap.summary_plot(shap_values, X_test_processed, show=False)\n",
    "    plt.title(\"SHAP Summary Plot\", fontsize=16); plt.tight_layout()\n",
    "    mlflow.log_figure(plt.gcf(), \"shap_summary_plot.png\"); plt.close()\n",
    "    logger.success(\"Logged SHAP summary plot.\")\n",
    "    \n",
    "    force_plot_html_path = \"shap_force_plot_first_prediction.html\"\n",
    "    shap.save_html(force_plot_html_path, shap.force_plot(explainer.expected_value, shap_values[0,:], X_test_processed.iloc[0,:]))\n",
    "    mlflow.log_artifact(force_plot_html_path, \"interactive_plots\")\n",
    "    logger.success(\"Logged interactive SHAP force plot.\")\n",
    "    \n",
    "    shap_values_path = \"shap_values.npy\"\n",
    "    np.save(shap_values_path, shap_values)\n",
    "    mlflow.log_artifact(shap_values_path)\n",
    "    logger.success(\"Logged raw SHAP values array.\")\n",
    "\n",
    "logger.info(\"--- XAI Analysis Complete. Check the MLflow UI. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c69179-6e12-4fcc-a781-49ced8925342",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
